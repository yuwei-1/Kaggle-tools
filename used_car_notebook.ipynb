{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import seaborn as sns\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import catboost as cb\n",
    "import optuna\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "import pprint\n",
    "from copy import deepcopy\n",
    "from typing import *\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "from catboost import CatBoostClassifier\n",
    "from functools import reduce\n",
    "from sklearn.preprocessing import TargetEncoder\n",
    "from ktools.preprocessing.categorical_denoiser_prepreprocesser import CategoricalDenoiserPreprocessor\n",
    "from ktools.metrics.fast_matthew_correlation_coefficient import fast_matthews_corr_coeff\n",
    "from ktools.preprocessing.categorical_string_label_error_imputator import CategoricalLabelErrorImputator\n",
    "from ktools.preprocessing.categorical_features_embedder import SortMainCategories\n",
    "from ktools.preprocessing.kaggle_dataset_manager import KaggleDatasetManager\n",
    "from ktools.utils.data_science_pipeline_settings import DataSciencePipelineSettings\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from ktools.fitting.cross_validate_then_test_sklearn_model import CrossValidateTestSklearnModel\n",
    "from sklearn.metrics import root_mean_squared_error, r2_score\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def update(df):\n",
    "    \n",
    "#     t = 100\n",
    "    \n",
    "#     cat_c = ['brand','model','fuel_type','engine','transmission','ext_col','int_col','accident','clean_title']\n",
    "#     re_ = ['model','engine','transmission','ext_col','int_col']\n",
    "    \n",
    "#     for col in re_:\n",
    "#         df.loc[df[col].value_counts(dropna=False)[df[col]].values < t, col] = \"noise\"\n",
    "        \n",
    "#     for col in cat_c:\n",
    "#         df[col] = df[col].fillna('missing')\n",
    "#         df[col] = df[col].astype('category')\n",
    "        \n",
    "#     return df\n",
    "\n",
    "# train  = update(train)\n",
    "# # test   = update(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvertToLower:\n",
    "    @staticmethod\n",
    "    def transform(original_settings : DataSciencePipelineSettings):\n",
    "        settings = deepcopy(original_settings)\n",
    "        for col_name in settings.categorical_col_names:\n",
    "            settings.combined_df[col_name] = settings.combined_df[col_name].str.lower()\n",
    "        return settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UsedCarSpecificConverter:\n",
    "    @staticmethod\n",
    "    def transform(original_settings : DataSciencePipelineSettings):\n",
    "        settings = deepcopy(original_settings)\n",
    "        def find_pattern(pattern, text):\n",
    "            match = re.search(pattern, text)\n",
    "            if match:\n",
    "                return match.group(1)\n",
    "            else:\n",
    "                return None\n",
    "            \n",
    "        def transmission(text):\n",
    "            if 'a/t' in text or 'at' in text or 'automatic' in text:\n",
    "                return 'automatic transmission'\n",
    "            elif 'm/t' in text or 'mt' in text or 'manual' in text:\n",
    "                return 'manual transmission'\n",
    "            elif 'cvt' in text:\n",
    "                return 'continuously variable transmission'\n",
    "            else:\n",
    "                return 'other'\n",
    "\n",
    "        def camshafts(text):\n",
    "            if 'dohc' in text:\n",
    "                # double overhead camshaft\n",
    "                return 'dohc'\n",
    "            elif 'sohc' in text:\n",
    "                #single overhead camshaft\n",
    "                return 'sohc'\n",
    "            elif 'ohv' in text:\n",
    "                # overhead valve\n",
    "                return 'ohv'\n",
    "            elif 'vtec' in text:\n",
    "                # variable valve timing and lift electronic control\n",
    "                return 'vtec'\n",
    "            else:\n",
    "                return 'other'\n",
    "\n",
    "        def injection(text):\n",
    "            if 'ddi' in text:\n",
    "                #direct diesel injection\n",
    "                return 'ddi'\n",
    "            elif 'gdi' in text:\n",
    "                #gasoline direct injection\n",
    "                return 'gdi'\n",
    "            elif 'mpfi' in text:\n",
    "                # multi-point fuel injection\n",
    "                return 'mpfi'\n",
    "            elif 'pdi' in text:\n",
    "                # port fuel injection\n",
    "                return 'pdi'\n",
    "            elif 'tfsi' in text or 'tsi' in text:\n",
    "                # turbo stratified injection\n",
    "                return 'tfsi'\n",
    "            elif 'gtdi' in text:\n",
    "                # gasoline turbocharged direct injection\n",
    "                return 'gtdi'\n",
    "            elif 'sidi' in text:\n",
    "                # spark ignition direct injection\n",
    "                return 'sidi'\n",
    "            else:\n",
    "                return 'other'\n",
    "            \n",
    "        pattern = r'(\\d*\\.?\\d+)\\s*hp'\n",
    "        settings.combined_df['horsepower'] = settings.combined_df['engine'].apply(lambda x : find_pattern(pattern, x)).astype('float64')\n",
    "        pattern = r'(\\d*\\.?\\d+)\\s*(l|liter)'\n",
    "        settings.combined_df['liters'] = settings.combined_df['engine'].apply(lambda x : find_pattern(pattern, x)).astype('float64')\n",
    "        pattern = r'(\\d*\\.?\\d+)\\s*cylinder'\n",
    "        settings.combined_df['cylinders'] = settings.combined_df['engine'].apply(lambda x : find_pattern(pattern, x)).astype('float64')\n",
    "        pattern = r'(\\d*\\.?\\d+)\\s*(-speed|speed)'\n",
    "        settings.combined_df['speed'] = settings.combined_df['transmission'].apply(lambda x : find_pattern(pattern, x)).astype('float64')\n",
    "        \n",
    "        settings.combined_df['injection'] = settings.combined_df['engine'].apply(lambda x : injection(x)).astype('object')\n",
    "        settings.combined_df['camshaft'] = settings.combined_df['engine'].apply(lambda x : camshafts(x)).astype('object')\n",
    "        settings.combined_df['transmission_clean'] = settings.combined_df['transmission'].apply(lambda x : transmission(x)).astype('object')\n",
    "        settings.combined_df.loc[(settings.combined_df['model'].str.contains('model y|model x|model s|model 3', regex=True)), 'fuel_type'] = 'electric'\n",
    "        settings.combined_df.loc[(settings.combined_df['model'].str.contains('electric')), 'fuel_type'] = 'electric'\n",
    "\n",
    "\n",
    "        expensive_ext_color = ['blue caelum','dark sapphire','bianco monocerus','c / c',\n",
    "                               'ice','tempest','beluga black','bianco icarus metallic','blu eleos',\n",
    "                               'shadow black','nero noctis','sandstone metallic','lizard green','balloon white','onyx',\n",
    "                               'donington grey metallic','china blue','diamond white','rosso corsa',\n",
    "                                'granite','rosso mars metallic',\n",
    "                                'carpathian grey','kemora gray metallic','grigio nimbus','dash','bianco isis','python green',\n",
    "                                'fountain blue','custom color','vega blue','designo magno matte',\n",
    "                                'brands hatch gray metallic',\n",
    "                                'rift metallic','gentian blue metallic',\n",
    "                                'arancio borealis','blue',\n",
    "                                'aventurine green metallic',\n",
    "                                'apex blue','daytona gray pearl effect',\n",
    "                                'daytona gray pearl effect w/ black roof','matte white',\n",
    "                                'carpathian grey premium metallic','blue metallic','santorini black metallic',\n",
    "                                'quartzite grey metallic','carrara white metallic','black',\n",
    "                                'kinetic blue',\n",
    "                                'nero daytona']\n",
    "\n",
    "        expensive_int_color = ['dark auburn',\n",
    "                            'hotspur',\n",
    "                            'cobalt blue',\n",
    "                            'beluga hide',\n",
    "                            'linen',\n",
    "                            'beluga',\n",
    "                            'black / brown',\n",
    "                            'nero ade',\n",
    "                            'sahara tan',\n",
    "                            'portland']\n",
    "        \n",
    "        \n",
    "        \n",
    "        settings.combined_df['expensive_ext_col'] = settings.combined_df['ext_col'].isin(expensive_ext_color).astype(int)\n",
    "        settings.combined_df['expensive_int_col'] = settings.combined_df['int_col'].isin(expensive_int_color).astype(int)\n",
    "        settings.combined_df['twin_turbo'] = settings.combined_df['engine'].str.contains('twin turbo').astype(int)\n",
    "        settings.combined_df['turbo'] = settings.combined_df['engine'].str.contains('turbo').astype(int)\n",
    "        settings.combined_df['length_model'] = settings.combined_df['model'].apply(lambda x : len(x))\n",
    "        settings.combined_df['length_ext_col'] = settings.combined_df['ext_col'].apply(lambda x : len(x))\n",
    "        settings.combined_df['length_int_col'] = settings.combined_df['int_col'].apply(lambda x : len(x))\n",
    "        \n",
    "        clean_colors = ['ext_col', 'int_col']\n",
    "        string_imputator = CategoricalLabelErrorImputator(verbose=True)\n",
    "        settings.combined_df[['basic_ext_color', 'basic_int_color']] = string_imputator.impute(settings.combined_df[clean_colors],\n",
    "                                                                                                                    clean_colors,\n",
    "                                                                                                                    1500)\n",
    "        \n",
    "        settings.combined_df['basic_ext_color'] = settings.combined_df['basic_ext_color'].astype('object')\n",
    "        settings.combined_df['basic_int_color'] = settings.combined_df['basic_int_color'].astype('object')\n",
    "        # threshold = 2.5e6\n",
    "        # print(\"num removed: \", (settings.combined_df['price'] > threshold).sum())\n",
    "        # settings.combined_df = settings.combined_df[(settings.combined_df['price'] < threshold) | (settings.combined_df['price'].isna())]\n",
    "        \n",
    "        # settings.training_col_names += ['horsepower', \n",
    "        #                                 'injection',\n",
    "        #                                 'camshaft', \n",
    "        #                                 'cylinders', \n",
    "        #                                 'expensive_ext_col', \n",
    "        #                                 'expensive_int_col', \n",
    "        #                                 'twin_turbo', \n",
    "        #                                 'turbo',\n",
    "        #                                 'transmission_clean',\n",
    "        #                                 'speed',\n",
    "        #                                 'basic_ext_color',\n",
    "        #                                 'basic_int_color',\n",
    "        #                                 'liters',\n",
    "        #                                 'length_model',\n",
    "        #                                 'length_ext_col',\n",
    "        #                                 'length_int_col'\n",
    "        #                                 ]\n",
    "        \n",
    "        re_ = ['model','engine','transmission','ext_col','int_col']\n",
    "        for col in re_:\n",
    "            settings.combined_df.loc[settings.combined_df[col].value_counts(dropna=False)[settings.combined_df[col]].values < 100, col] = \"noise\"\n",
    "        \n",
    "        # settings.categorical_col_names += ['injection',\n",
    "        #                                    'camshaft',\n",
    "        #                                    'transmission_clean',\n",
    "        #                                    'basic_ext_color',\n",
    "        #                                    'basic_int_color']\n",
    "        \n",
    "        return settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicUsedCarSpecificConverter:\n",
    "    @staticmethod\n",
    "    def transform(original_settings : DataSciencePipelineSettings):\n",
    "        settings = deepcopy(original_settings)\n",
    "        def find_pattern(pattern, text):\n",
    "            match = re.search(pattern, text)\n",
    "            if match:\n",
    "                return match.group(1)\n",
    "            else:\n",
    "                return None\n",
    "\n",
    "        pattern = r'(\\d*\\.?\\d+)\\s*hp'\n",
    "        settings.combined_df['horsepower'] = settings.combined_df['engine'].apply(lambda x : find_pattern(pattern, x)).astype('float64')\n",
    "        pattern = r'(\\d*\\.?\\d+)\\s*(l|liter)'\n",
    "        settings.combined_df['liters'] = settings.combined_df['engine'].apply(lambda x : find_pattern(pattern, x)).astype('float64')\n",
    "        pattern = r'(\\d*\\.?\\d+)\\s*cylinder'\n",
    "        settings.combined_df['cylinders'] = settings.combined_df['engine'].apply(lambda x : find_pattern(pattern, x)).astype('float64')\n",
    "        pattern = r'(\\d*\\.?\\d+)\\s*(-speed|speed)'\n",
    "        settings.combined_df['speed'] = settings.combined_df['transmission'].apply(lambda x : find_pattern(pattern, x)).astype('float64')\n",
    "\n",
    "        settings.training_col_names += ['horsepower',\n",
    "                                        'liters',\n",
    "                                        'cylinders',\n",
    "                                        'speed'\n",
    "                                        ]\n",
    "        return settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BackPackerMinimalProcessing:\n",
    "    @staticmethod\n",
    "    def transform(original_settings : DataSciencePipelineSettings):\n",
    "\n",
    "        settings = deepcopy(original_settings)\n",
    "        settings.update()\n",
    "        def update(df):\n",
    "            t = 100\n",
    "            re_ = ['model','engine','transmission','ext_col','int_col']\n",
    "            for col in re_:\n",
    "                df.loc[df[col].value_counts(dropna=False)[df[col]].values < t, col] = \"noise\"\n",
    "            return df\n",
    "        \n",
    "        settings.train_df = update(settings.train_df)\n",
    "        settings.test_df = update(settings.test_df)\n",
    "        settings.combined_df = pd.concat([settings.train_df, settings.test_df], keys=['train', 'test'])\n",
    "        return settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SergeyConverter:\n",
    "    @staticmethod\n",
    "    def transform(original_settings : DataSciencePipelineSettings):\n",
    "        settings = deepcopy(original_settings)\n",
    "        fuel_type_dict = {\n",
    "            'Gasoline': 0,\n",
    "            'Hybrid': 1,\n",
    "            'E85 Flex Fuel': 2,\n",
    "            'uknown': 3,\n",
    "            'Diesel': 4,\n",
    "            'dash': 5,\n",
    "            'Plug-In Hybrid': 6,\n",
    "            'not supported': 7\n",
    "        }\n",
    "\n",
    "        accident_dict = {\n",
    "            'None reported': 0,\n",
    "            'At least 1 accident or damage reported': 1,\n",
    "            'uknown': 2\n",
    "        }\n",
    "\n",
    "        clean_title_dict = {\n",
    "            'Yes': 0,\n",
    "            'uknown': 1\n",
    "        }\n",
    "\n",
    "        expensive_ext_color = ['Blue Caelum', 'Dark Sapphire', 'Bianco Monocerus', 'C / C', 'Ice',\n",
    "            'Tempest', 'Beluga Black', 'Bianco Icarus Metallic', \n",
    "            'BLU ELEOS', 'Shadow Black', 'Nero Noctis', 'Sandstone Metallic',\n",
    "            'Lizard Green', 'Balloon White', 'Onyx', 'Donington Grey Metallic',\n",
    "            'China Blue', 'Diamond White', 'Rosso Corsa', 'Granite',\n",
    "            'Rosso Mars Metallic', 'Carpathian Grey', 'Kemora Gray Metallic',\n",
    "            'Grigio Nimbus', 'dash', 'Bianco Isis', 'Python Green', 'Fountain Blue',\n",
    "            'Custom Color', 'Vega Blue', 'Designo Magno Matte',\n",
    "            'Brands Hatch Gray Metallic', 'Rift Metallic', 'Gentian Blue Metallic',\n",
    "            'Arancio Borealis', 'BLUE', 'Aventurine Green Metallic', 'Apex Blue',\n",
    "            'Daytona Gray Pearl Effect', 'Daytona Gray Pearl Effect w/ Black Roof',\n",
    "            'Matte White', 'Carpathian Grey Premium Metallic', 'Blue Metallic',\n",
    "            'Santorini Black Metallic', 'Quartzite Grey Metallic',\n",
    "            'Carrara White Metallic', 'BLACK', 'Kinetic Blue', 'Nero Daytona']\n",
    "\n",
    "        expensive_int_color = ['Dark Auburn', 'Hotspur', 'Cobalt Blue', 'Beluga Hide', 'Linen',\n",
    "                            'Beluga', 'Black / Brown', 'Nero Ade', 'Sahara Tan', 'Portland']\n",
    "\n",
    "        expensive_hp = [443.0, 473.0, 493.0, 502.0, 521.0, 542.0, 543.0, 571.0, 572.0, 573.0, 580.0,\n",
    "                        591.0, 602.0, 611.0, 616.0, 620.0, 624.0, 640.0, 641.0, 651.0, 710.0, 715.0, 760.0, 788.0, 797.0]\n",
    "\n",
    "\n",
    "\n",
    "        def encode_columns(df):\n",
    "            df['fuel_type_encoded'] = df['fuel_type'].map(fuel_type_dict)\n",
    "            df['accident_encoded'] = df['accident'].map(accident_dict)\n",
    "            df['clean_title_encoded'] = df['clean_title'].map(clean_title_dict)\n",
    "            df['expensive_color_ext_encoded'] = df.ext_col.isin(expensive_ext_color).astype(int)\n",
    "            df['expensive_color_int_encoded'] = df.int_col.isin(expensive_int_color).astype(int)\n",
    "            df['expensive_hp'] = df['engine'].str.extract(r'(\\d+\\.?\\d*)HP').astype(float).isin(expensive_hp).astype(int)\n",
    "            df['cylinder'] = df['engine'].str.extract(r'(\\d+\\.?\\d*) Cylinder').astype(float)              \n",
    "            df['got_V'] = df['model'].str.extract(r'(\\d+\\.?\\d*) V').notna().astype(int)\n",
    "            return df\n",
    "        settings.combined_df = encode_columns(settings.combined_df)\n",
    "        settings.training_col_names += ['expensive_color_ext_encoded',\n",
    "                                        'expensive_color_int_encoded']\n",
    "        return settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FillNullValues:\n",
    "    @staticmethod\n",
    "    def transform(original_settings : DataSciencePipelineSettings, numeric_fill=-1, category_fill='missing'):\n",
    "        settings = deepcopy(original_settings)\n",
    "        for col_name in settings.training_col_names:\n",
    "            if pd.api.types.is_numeric_dtype(settings.combined_df[col_name]):\n",
    "                settings.combined_df[col_name] = settings.combined_df[col_name].fillna(numeric_fill)\n",
    "            else:\n",
    "                settings.combined_df[col_name] = settings.combined_df[col_name].fillna(category_fill)\n",
    "        return settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvertObjectToCategorical:\n",
    "    @staticmethod\n",
    "    def transform(original_settings : DataSciencePipelineSettings):\n",
    "        settings = deepcopy(original_settings)\n",
    "        cat_cols = settings.categorical_col_names\n",
    "        settings.combined_df[cat_cols] = settings.combined_df[cat_cols].astype('category')\n",
    "        return settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogTransformTarget:\n",
    "    @staticmethod\n",
    "    def transform(original_settings : DataSciencePipelineSettings):\n",
    "        settings = deepcopy(original_settings)\n",
    "        target = settings.target_col_name\n",
    "        settings.combined_df['log_' + target] = np.log(settings.combined_df[target] + 1)\n",
    "        settings.target_col_name = 'log_' + target\n",
    "        settings.logged = True\n",
    "        return settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv_path = \"data/used_car_prices/train_combined.csv\"\n",
    "test_csv_path = \"data/used_car_prices/test.csv\"\n",
    "target_col_name = \"price\"\n",
    "\n",
    "settings = DataSciencePipelineSettings(train_csv_path,\n",
    "                                        test_csv_path,\n",
    "                                        target_col_name)\n",
    "\n",
    "full_transforms = [ConvertToLower.transform, BackPackerMinimalProcessing.transform, FillNullValues.transform, ConvertObjectToCategorical.transform, LogTransformTarget.transform]\n",
    "# basic_transforms = [ConvertToLower.transform, FillNullValues.transform, ConvertObjectToCategorical.transform, LogTransformTarget.transform]\n",
    "\n",
    "full_settings = reduce(lambda acc, func: func(acc), full_transforms, settings)\n",
    "# basic_settings = reduce(lambda acc, func: func(acc), basic_transforms, settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df, test_df = basic_settings.update()\n",
    "\n",
    "# data_manager = KaggleDatasetManager(train_df,\n",
    "#                                     basic_settings.training_col_names,\n",
    "#                                     basic_settings.target_col_name,\n",
    "#                                     0.9,\n",
    "#                                     0.1,\n",
    "#                                     0)\n",
    "\n",
    "# (X_train, \n",
    "# X_valid, \n",
    "# X_test, \n",
    "# y_train, \n",
    "# y_valid,\n",
    "# y_test) = data_manager.dataset_partition()\n",
    "\n",
    "\n",
    "# # model = XGBRegressor(**{}, \n",
    "# #                     verbosity=0,\n",
    "# #                     eval_metric='logloss',\n",
    "# #                     tree_method='hist',\n",
    "# #                     enable_categorical=True)\n",
    "\n",
    "# model = ()\n",
    "\n",
    "# num_splits = 10\n",
    "# eval_metrics = {\"r2\" : r2_score, \"rmse\" : lambda y, yhat : root_mean_squared_error(np.exp(y), np.exp(yhat))}\n",
    "# skf = KFold(n_splits=num_splits)\n",
    "\n",
    "# model, cv_scores, test_scores = CrossValidateTestSklearnModel(model,\n",
    "#                               eval_metrics,\n",
    "#                               skf,\n",
    "#                               num_splits).evaluate(X_train,\n",
    "#                                                    y_train,\n",
    "#                                                    X_test,\n",
    "#                                                    y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final Model r2: 0.638607\n",
    "\n",
    "10-fold cross validation r2:  0.6376903986890982\n",
    "\n",
    "Final Model rmse: 70167.345097\n",
    "\n",
    "10-fold cross validation rmse:  73703.32201325778"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {'learning_rate': 0.017521301504983752,\n",
    "                'max_depth': 42,\n",
    "                'reg_alpha': 0.06876635751774487, \n",
    "                'reg_lambda': 9.738899198284985,\n",
    "                'num_leaves': 131,\n",
    "                'subsample': 0.2683765421728044,\n",
    "                'colsample_bytree': 0.44346036599709887,\n",
    "                'n_estimators': 1000,\n",
    "                'random_state': 42}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from typing import Dict\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from copy import deepcopy\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "# from ktools.fitting.i_sklearn_model import ISklearnModel\n",
    "# import lightgbm as lgb\n",
    "# from lightgbm import log_evaluation, early_stopping\n",
    "\n",
    "\n",
    "# class CrossValidateTestSklearnModel:\n",
    "\n",
    "#     def __init__(self,\n",
    "#                  sklearn_model_instance : ISklearnModel,\n",
    "#                  evaluation_metrics : Dict[str, callable],\n",
    "#                  kfold_object = None,\n",
    "#                  num_splits : int = 5) -> None:\n",
    "#         self.model = sklearn_model_instance\n",
    "#         self._evaluation_metrics = evaluation_metrics\n",
    "#         self._metric_names = list(evaluation_metrics.keys())\n",
    "#         self._kf = kfold_object\n",
    "#         self._num_metrics = len(self._metric_names)\n",
    "#         self._num_splits = num_splits\n",
    "#         self._model_list = []\n",
    "\n",
    "#     def _fit_then_predict(self, X, y, X_test, y_test):\n",
    "#         # model = deepcopy(self.model).fit(X, y)\n",
    "        \n",
    "#         train_data = lgb.Dataset(X, label=y)\n",
    "#         val_data = lgb.Dataset(X_test, label=y_test, reference=train_data)\n",
    "#         model = lgb.train(model_params,\n",
    "#                     train_data,\n",
    "#                     valid_sets=[train_data, val_data],\n",
    "#                     valid_names=['train', 'valid'],\n",
    "#                     callbacks=callbacks    \n",
    "#                     )\n",
    "#         y_pred = model.predict(X_test)\n",
    "#         return y_pred, model\n",
    "\n",
    "#     def evaluate(self,\n",
    "#                  X_train, y_train,\n",
    "#                  X_test, y_test):\n",
    "\n",
    "#         cv_results = np.zeros((self._num_splits, self._num_metrics))\n",
    "#         cv_scores = None\n",
    "\n",
    "#         if self._kf is not None:\n",
    "#             for i, (train_index, val_index) in enumerate(self._kf.split(X_train, y_train)):\n",
    "#                 X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "#                 y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "#                 y_pred, model = self._fit_then_predict(X_train_fold,\n",
    "#                                                        y_train_fold,\n",
    "#                                                        X_val_fold,\n",
    "#                                                        y_val_fold)\n",
    "#                 self._model_list += [model]\n",
    "\n",
    "#                 for j, metric in enumerate(self._metric_names):\n",
    "#                     score = self._evaluation_metrics[metric](np.array(y_val_fold), np.array(y_pred))\n",
    "#                     cv_results[i][j] = score\n",
    "            \n",
    "#             cv_scores = pd.DataFrame(columns=self._metric_names, data=cv_results)\n",
    "#             cv_scores.describe()\n",
    "\n",
    "#         y_pred, self.model = self._fit_then_predict(X_train,\n",
    "#                                                      y_train,\n",
    "#                                                      X_test,\n",
    "#                                                      y_test)\n",
    "#         test_scores = {}\n",
    "#         for j, metric in enumerate(self._metric_names):\n",
    "#             score = self._evaluation_metrics[metric](np.array(y_test), np.array(y_pred))\n",
    "#             test_scores[metric] = score\n",
    "#             print(f\"Final Model {metric}: {score:.6f}\")\n",
    "#             print(f\"{self._num_splits}-fold cross validation {metric}: \", cv_results[:,j].mean())\n",
    "        \n",
    "#         return self._model_list, cv_scores, test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = full_settings.update()\n",
    "X = train_df.drop(['price', 'log_price'], axis=1)\n",
    "y = train_df['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuwei-1/anaconda3/envs/ktools_2/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[150]\ttrain's l2: 5.05793e+09\tvalid's l2: 6.90248e+09\n",
      "[300]\ttrain's l2: 4.83999e+09\tvalid's l2: 6.87395e+09\n",
      "[450]\ttrain's l2: 4.69867e+09\tvalid's l2: 6.86895e+09\n",
      "[600]\ttrain's l2: 4.57539e+09\tvalid's l2: 6.86855e+09\n",
      "Early stopping, best iteration is:\n",
      "[506]\ttrain's l2: 4.65092e+09\tvalid's l2: 6.86412e+09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuwei-1/anaconda3/envs/ktools_2/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[150]\ttrain's l2: 5.09179e+09\tvalid's l2: 4.05412e+09\n",
      "[300]\ttrain's l2: 4.87031e+09\tvalid's l2: 4.01722e+09\n",
      "[450]\ttrain's l2: 4.72347e+09\tvalid's l2: 4.0292e+09\n",
      "Early stopping, best iteration is:\n",
      "[294]\ttrain's l2: 4.87767e+09\tvalid's l2: 4.01674e+09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuwei-1/anaconda3/envs/ktools_2/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[150]\ttrain's l2: 5.21987e+09\tvalid's l2: 3.06837e+09\n",
      "[300]\ttrain's l2: 5.00229e+09\tvalid's l2: 3.06955e+09\n",
      "Early stopping, best iteration is:\n",
      "[211]\ttrain's l2: 5.11259e+09\tvalid's l2: 3.05561e+09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuwei-1/anaconda3/envs/ktools_2/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[150]\ttrain's l2: 5.17415e+09\tvalid's l2: 7.74212e+09\n",
      "[300]\ttrain's l2: 4.9534e+09\tvalid's l2: 7.71269e+09\n",
      "[450]\ttrain's l2: 4.81124e+09\tvalid's l2: 7.71342e+09\n",
      "Early stopping, best iteration is:\n",
      "[269]\ttrain's l2: 4.98812e+09\tvalid's l2: 7.70838e+09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuwei-1/anaconda3/envs/ktools_2/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[150]\ttrain's l2: 5.07989e+09\tvalid's l2: 6.97472e+09\n",
      "[300]\ttrain's l2: 4.8594e+09\tvalid's l2: 6.92943e+09\n",
      "[450]\ttrain's l2: 4.7136e+09\tvalid's l2: 6.95073e+09\n",
      "Early stopping, best iteration is:\n",
      "[261]\ttrain's l2: 4.90501e+09\tvalid's l2: 6.9266e+09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuwei-1/anaconda3/envs/ktools_2/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[150]\ttrain's l2: 5.35802e+09\tvalid's l2: 2.04103e+09\n",
      "[300]\ttrain's l2: 5.13168e+09\tvalid's l2: 1.99151e+09\n",
      "[450]\ttrain's l2: 4.98074e+09\tvalid's l2: 2.00218e+09\n",
      "Early stopping, best iteration is:\n",
      "[342]\ttrain's l2: 5.08433e+09\tvalid's l2: 1.9886e+09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuwei-1/anaconda3/envs/ktools_2/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[150]\ttrain's l2: 5.02718e+09\tvalid's l2: 5.33621e+09\n",
      "[300]\ttrain's l2: 4.81341e+09\tvalid's l2: 5.30043e+09\n",
      "[450]\ttrain's l2: 4.67121e+09\tvalid's l2: 5.30896e+09\n",
      "Early stopping, best iteration is:\n",
      "[314]\ttrain's l2: 4.79857e+09\tvalid's l2: 5.29754e+09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuwei-1/anaconda3/envs/ktools_2/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[150]\ttrain's l2: 5.22515e+09\tvalid's l2: 3.96986e+09\n",
      "[300]\ttrain's l2: 5.00129e+09\tvalid's l2: 3.9326e+09\n",
      "[450]\ttrain's l2: 4.85167e+09\tvalid's l2: 3.94089e+09\n",
      "Early stopping, best iteration is:\n",
      "[256]\ttrain's l2: 5.05257e+09\tvalid's l2: 3.92941e+09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuwei-1/anaconda3/envs/ktools_2/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[150]\ttrain's l2: 5.15185e+09\tvalid's l2: 5.60105e+09\n",
      "[300]\ttrain's l2: 4.93268e+09\tvalid's l2: 5.5506e+09\n",
      "[450]\ttrain's l2: 4.79175e+09\tvalid's l2: 5.54449e+09\n",
      "Early stopping, best iteration is:\n",
      "[388]\ttrain's l2: 4.84842e+09\tvalid's l2: 5.54318e+09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuwei-1/anaconda3/envs/ktools_2/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[150]\ttrain's l2: 5.01427e+09\tvalid's l2: 5.2856e+09\n",
      "[300]\ttrain's l2: 4.79999e+09\tvalid's l2: 5.24873e+09\n",
      "[450]\ttrain's l2: 4.65762e+09\tvalid's l2: 5.26385e+09\n",
      "Early stopping, best iteration is:\n",
      "[293]\ttrain's l2: 4.80704e+09\tvalid's l2: 5.24728e+09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuwei-1/anaconda3/envs/ktools_2/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[150]\ttrain's l2: 5.11284e+09\tvalid's l2: 5.60351e+09\n",
      "[300]\ttrain's l2: 4.89986e+09\tvalid's l2: 5.51753e+09\n",
      "[450]\ttrain's l2: 4.75628e+09\tvalid's l2: 5.51483e+09\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[82], line 61\u001b[0m\n\u001b[1;32m     54\u001b[0m skf \u001b[38;5;241m=\u001b[39m KFold(n_splits\u001b[38;5;241m=\u001b[39mnum_splits, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m     56\u001b[0m cvt \u001b[38;5;241m=\u001b[39m CrossValidateTestSklearnModel(model,\n\u001b[1;32m     57\u001b[0m                               eval_metrics,\n\u001b[1;32m     58\u001b[0m                               skf,\n\u001b[1;32m     59\u001b[0m                               num_splits)\n\u001b[0;32m---> 61\u001b[0m modellist, cv_scores, test_scores \u001b[38;5;241m=\u001b[39m \u001b[43mcvt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/projects/Kaggle-tools/ktools/fitting/cross_validate_then_test_sklearn_model.py:53\u001b[0m, in \u001b[0;36mCrossValidateTestSklearnModel.evaluate\u001b[0;34m(self, X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[1;32m     50\u001b[0m     cv_scores \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metric_names, data\u001b[38;5;241m=\u001b[39mcv_results)\n\u001b[1;32m     51\u001b[0m     cv_scores\u001b[38;5;241m.\u001b[39mdescribe()\n\u001b[0;32m---> 53\u001b[0m y_pred, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_then_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                             \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                             \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m test_scores \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j, metric \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metric_names):\n",
      "File \u001b[0;32m~/Documents/projects/Kaggle-tools/ktools/fitting/cross_validate_then_test_sklearn_model.py:25\u001b[0m, in \u001b[0;36mCrossValidateTestSklearnModel._fit_then_predict\u001b[0;34m(self, X, y, X_test)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fit_then_predict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, X_test):\n\u001b[0;32m---> 25\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m y_pred, model\n",
      "File \u001b[0;32m~/Documents/projects/Kaggle-tools/ktools/fitting/lgbm_model.py:23\u001b[0m, in \u001b[0;36mLGBMModel.fit\u001b[0;34m(self, X, y, val_size, random_state)\u001b[0m\n\u001b[1;32m     21\u001b[0m train_data \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mDataset(X_train, label\u001b[38;5;241m=\u001b[39my_train)\n\u001b[1;32m     22\u001b[0m val_data \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mDataset(X_valid, label\u001b[38;5;241m=\u001b[39my_valid, reference\u001b[38;5;241m=\u001b[39mtrain_data)\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mlgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_lgb_param_grid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_data\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mvalid_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_callbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m                        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n",
      "File \u001b[0;32m~/anaconda3/envs/ktools_2/lib/python3.10/site-packages/lightgbm/engine.py:276\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, feature_name, categorical_feature, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m callbacks_before_iter:\n\u001b[1;32m    269\u001b[0m     cb(callback\u001b[38;5;241m.\u001b[39mCallbackEnv(model\u001b[38;5;241m=\u001b[39mbooster,\n\u001b[1;32m    270\u001b[0m                             params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m    271\u001b[0m                             iteration\u001b[38;5;241m=\u001b[39mi,\n\u001b[1;32m    272\u001b[0m                             begin_iteration\u001b[38;5;241m=\u001b[39minit_iteration,\n\u001b[1;32m    273\u001b[0m                             end_iteration\u001b[38;5;241m=\u001b[39minit_iteration \u001b[38;5;241m+\u001b[39m num_boost_round,\n\u001b[1;32m    274\u001b[0m                             evaluation_result_list\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m--> 276\u001b[0m \u001b[43mbooster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    278\u001b[0m evaluation_result_list: List[_LGBM_BoosterEvalMethodResultType] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    279\u001b[0m \u001b[38;5;66;03m# check evaluation result.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ktools_2/lib/python3.10/site-packages/lightgbm/basic.py:3891\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   3889\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__set_objective_to_none:\n\u001b[1;32m   3890\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot update due to null objective function.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 3891\u001b[0m _safe_call(\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLGBM_BoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3892\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3893\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mis_finished\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   3894\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__is_predicted_cur_iter \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__num_dataset)]\n\u001b[1;32m   3895\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m is_finished\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# data_manager = KaggleDatasetManager(train_df,\n",
    "#                                     full_settings.training_col_names,\n",
    "#                                     full_settings.target_col_name,\n",
    "#                                     0.9,\n",
    "#                                     0.1,\n",
    "#                                     0)\n",
    "\n",
    "# (X_train, \n",
    "# X_valid, \n",
    "# X_test, \n",
    "# y_train, \n",
    "# y_valid,\n",
    "# y_test) = data_manager.dataset_partition()\n",
    "\n",
    "\n",
    "# model = XGBRegressor(**{}, \n",
    "#                     verbosity=0,\n",
    "#                     eval_metric='rmse',\n",
    "#                     tree_method='hist',\n",
    "#                     enable_categorical=True)\n",
    "\n",
    "from ktools.fitting.lgbm_model import LGBMModel\n",
    "\n",
    "\n",
    "# model = LGBMModel({    'learning_rate': 0.017521301504983752,\n",
    "#     'max_depth': 42,\n",
    "#     'reg_alpha': 0.06876635751774487, \n",
    "#     'reg_lambda': 9.738899198284985,\n",
    "#     'num_leaves': 131,\n",
    "#     'subsample': 0.2683765421728044,\n",
    "#     'colsample_bytree': 0.44346036599709887,\n",
    "#     'n_estimators': 1000,\n",
    "#     'random_state': 42})\n",
    "\n",
    "model = LGBMModel({'num_leaves': 426,\n",
    " 'max_depth': 20,\n",
    " 'learning_rate': 0.011353178352988012,\n",
    " 'n_estimators': 884,\n",
    " 'subsample': 0.5772552201954328,\n",
    " 'colsample_bytree': 0.9164865430101521,\n",
    " 'reg_alpha': 1.48699088003429e-06,\n",
    " 'reg_lambda': 0.41539458543414265,\n",
    " 'min_data_in_leaf': 73,\n",
    " 'feature_fraction': 0.751673655170548,\n",
    " 'bagging_fraction': 0.5120415391590843,\n",
    " 'bagging_freq': 2,\n",
    " 'min_child_weight': 0.017236362383443497,\n",
    " 'cat_smooth': 54.81317407769262,\n",
    " 'verbose' : -1})\n",
    "\n",
    "\n",
    "num_splits = 10\n",
    "eval_metrics = {\"r2\" : r2_score, \"rmse\" : lambda y, yhat : root_mean_squared_error(y, yhat)}\n",
    "skf = KFold(n_splits=num_splits, shuffle=True, random_state=42)\n",
    "\n",
    "cvt = CrossValidateTestSklearnModel(model,\n",
    "                              eval_metrics,\n",
    "                              skf,\n",
    "                              num_splits)\n",
    "\n",
    "modellist, cv_scores, test_scores = cvt.evaluate(X,\n",
    "                                                 y,\n",
    "                                                 X,\n",
    "                                                 y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r2</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.149905</td>\n",
       "      <td>71865.903981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.129084</td>\n",
       "      <td>78258.335918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.141249</td>\n",
       "      <td>73935.313046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.199779</td>\n",
       "      <td>61444.646637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.162315</td>\n",
       "      <td>70246.510424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.163560</td>\n",
       "      <td>68580.791613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.134637</td>\n",
       "      <td>78478.903372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.163526</td>\n",
       "      <td>70860.189380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.172488</td>\n",
       "      <td>70498.970832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.133301</td>\n",
       "      <td>79482.435314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         r2          rmse\n",
       "0  0.149905  71865.903981\n",
       "1  0.129084  78258.335918\n",
       "2  0.141249  73935.313046\n",
       "3  0.199779  61444.646637\n",
       "4  0.162315  70246.510424\n",
       "5  0.163560  68580.791613\n",
       "6  0.134637  78478.903372\n",
       "7  0.163526  70860.189380\n",
       "8  0.172488  70498.970832\n",
       "9  0.133301  79482.435314"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('/Users/yuwei-1/Documents/projects/Kaggle-tools/data/used_car_prices/sample_submission.csv', index_col=0)\n",
    "# sub['price'] = np.exp(cvt.model.predict(test_df[full_settings.training_col_names])) - 1\n",
    "# sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, mdl in enumerate(modellist):\n",
    "    sub[f'price_{i}'] = mdl.predict(test_df[full_settings.training_col_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>price_0</th>\n",
       "      <th>price_1</th>\n",
       "      <th>price_2</th>\n",
       "      <th>price_3</th>\n",
       "      <th>price_4</th>\n",
       "      <th>price_5</th>\n",
       "      <th>price_6</th>\n",
       "      <th>price_7</th>\n",
       "      <th>price_8</th>\n",
       "      <th>price_9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>188533</th>\n",
       "      <td>18345.165615</td>\n",
       "      <td>17430.847781</td>\n",
       "      <td>18253.846302</td>\n",
       "      <td>20071.999728</td>\n",
       "      <td>18525.575144</td>\n",
       "      <td>18385.070618</td>\n",
       "      <td>18211.265040</td>\n",
       "      <td>17764.622467</td>\n",
       "      <td>19093.842606</td>\n",
       "      <td>17626.489251</td>\n",
       "      <td>18088.097213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188534</th>\n",
       "      <td>79120.161055</td>\n",
       "      <td>75521.639139</td>\n",
       "      <td>81660.250486</td>\n",
       "      <td>76325.226222</td>\n",
       "      <td>74766.842719</td>\n",
       "      <td>83339.456723</td>\n",
       "      <td>82790.000427</td>\n",
       "      <td>76794.423556</td>\n",
       "      <td>77001.147962</td>\n",
       "      <td>81801.094759</td>\n",
       "      <td>81201.528554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188535</th>\n",
       "      <td>54667.929227</td>\n",
       "      <td>60505.932659</td>\n",
       "      <td>52311.905126</td>\n",
       "      <td>53426.997306</td>\n",
       "      <td>56908.938123</td>\n",
       "      <td>54086.369324</td>\n",
       "      <td>55524.911828</td>\n",
       "      <td>54578.046401</td>\n",
       "      <td>51453.646276</td>\n",
       "      <td>54941.687299</td>\n",
       "      <td>52940.857934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188536</th>\n",
       "      <td>31480.856848</td>\n",
       "      <td>29528.303174</td>\n",
       "      <td>31440.834176</td>\n",
       "      <td>32948.076766</td>\n",
       "      <td>35249.955166</td>\n",
       "      <td>32076.795088</td>\n",
       "      <td>30490.405012</td>\n",
       "      <td>30985.736485</td>\n",
       "      <td>32980.863207</td>\n",
       "      <td>29646.546113</td>\n",
       "      <td>29461.053299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188537</th>\n",
       "      <td>29701.401953</td>\n",
       "      <td>29731.452448</td>\n",
       "      <td>29072.467456</td>\n",
       "      <td>30774.457125</td>\n",
       "      <td>29941.858085</td>\n",
       "      <td>30248.735942</td>\n",
       "      <td>29387.729177</td>\n",
       "      <td>29262.812778</td>\n",
       "      <td>30177.839242</td>\n",
       "      <td>28644.281951</td>\n",
       "      <td>29772.385328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314218</th>\n",
       "      <td>30720.193571</td>\n",
       "      <td>32004.250406</td>\n",
       "      <td>28135.660743</td>\n",
       "      <td>32641.403654</td>\n",
       "      <td>31469.502690</td>\n",
       "      <td>34898.698723</td>\n",
       "      <td>31554.652620</td>\n",
       "      <td>30125.286082</td>\n",
       "      <td>31352.918466</td>\n",
       "      <td>28801.817045</td>\n",
       "      <td>26217.745279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314219</th>\n",
       "      <td>53239.669271</td>\n",
       "      <td>55130.557371</td>\n",
       "      <td>49380.177069</td>\n",
       "      <td>52588.636045</td>\n",
       "      <td>51068.424637</td>\n",
       "      <td>53134.141745</td>\n",
       "      <td>54035.126300</td>\n",
       "      <td>54901.437714</td>\n",
       "      <td>51267.601381</td>\n",
       "      <td>57594.238215</td>\n",
       "      <td>53296.352234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314220</th>\n",
       "      <td>20085.596915</td>\n",
       "      <td>19169.563608</td>\n",
       "      <td>20056.591920</td>\n",
       "      <td>21303.632521</td>\n",
       "      <td>20252.431235</td>\n",
       "      <td>19976.080156</td>\n",
       "      <td>20311.538289</td>\n",
       "      <td>19658.523726</td>\n",
       "      <td>20204.352044</td>\n",
       "      <td>20016.881978</td>\n",
       "      <td>19906.373673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314221</th>\n",
       "      <td>15467.033823</td>\n",
       "      <td>14443.093903</td>\n",
       "      <td>15878.179644</td>\n",
       "      <td>17433.046985</td>\n",
       "      <td>15757.256253</td>\n",
       "      <td>15860.185645</td>\n",
       "      <td>15103.931419</td>\n",
       "      <td>15259.776670</td>\n",
       "      <td>15673.812722</td>\n",
       "      <td>14060.305593</td>\n",
       "      <td>15200.749397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314222</th>\n",
       "      <td>42003.546320</td>\n",
       "      <td>39344.464125</td>\n",
       "      <td>47886.178805</td>\n",
       "      <td>40885.157491</td>\n",
       "      <td>36373.496373</td>\n",
       "      <td>40600.426543</td>\n",
       "      <td>40172.140440</td>\n",
       "      <td>45337.772398</td>\n",
       "      <td>41424.708068</td>\n",
       "      <td>37380.601809</td>\n",
       "      <td>50630.517147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>125690 rows  11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               price       price_0       price_1       price_2       price_3  \\\n",
       "id                                                                             \n",
       "188533  18345.165615  17430.847781  18253.846302  20071.999728  18525.575144   \n",
       "188534  79120.161055  75521.639139  81660.250486  76325.226222  74766.842719   \n",
       "188535  54667.929227  60505.932659  52311.905126  53426.997306  56908.938123   \n",
       "188536  31480.856848  29528.303174  31440.834176  32948.076766  35249.955166   \n",
       "188537  29701.401953  29731.452448  29072.467456  30774.457125  29941.858085   \n",
       "...              ...           ...           ...           ...           ...   \n",
       "314218  30720.193571  32004.250406  28135.660743  32641.403654  31469.502690   \n",
       "314219  53239.669271  55130.557371  49380.177069  52588.636045  51068.424637   \n",
       "314220  20085.596915  19169.563608  20056.591920  21303.632521  20252.431235   \n",
       "314221  15467.033823  14443.093903  15878.179644  17433.046985  15757.256253   \n",
       "314222  42003.546320  39344.464125  47886.178805  40885.157491  36373.496373   \n",
       "\n",
       "             price_4       price_5       price_6       price_7       price_8  \\\n",
       "id                                                                             \n",
       "188533  18385.070618  18211.265040  17764.622467  19093.842606  17626.489251   \n",
       "188534  83339.456723  82790.000427  76794.423556  77001.147962  81801.094759   \n",
       "188535  54086.369324  55524.911828  54578.046401  51453.646276  54941.687299   \n",
       "188536  32076.795088  30490.405012  30985.736485  32980.863207  29646.546113   \n",
       "188537  30248.735942  29387.729177  29262.812778  30177.839242  28644.281951   \n",
       "...              ...           ...           ...           ...           ...   \n",
       "314218  34898.698723  31554.652620  30125.286082  31352.918466  28801.817045   \n",
       "314219  53134.141745  54035.126300  54901.437714  51267.601381  57594.238215   \n",
       "314220  19976.080156  20311.538289  19658.523726  20204.352044  20016.881978   \n",
       "314221  15860.185645  15103.931419  15259.776670  15673.812722  14060.305593   \n",
       "314222  40600.426543  40172.140440  45337.772398  41424.708068  37380.601809   \n",
       "\n",
       "             price_9  \n",
       "id                    \n",
       "188533  18088.097213  \n",
       "188534  81201.528554  \n",
       "188535  52940.857934  \n",
       "188536  29461.053299  \n",
       "188537  29772.385328  \n",
       "...              ...  \n",
       "314218  26217.745279  \n",
       "314219  53296.352234  \n",
       "314220  19906.373673  \n",
       "314221  15200.749397  \n",
       "314222  50630.517147  \n",
       "\n",
       "[125690 rows x 11 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['price'] = sub.drop(columns=['price']).mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['price'].to_csv('submissions/used_cars/used_car_submission_v14.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "188533    18345.165615\n",
       "188534    79120.161055\n",
       "188535    54667.929227\n",
       "188536    31480.856848\n",
       "188537    29701.401953\n",
       "              ...     \n",
       "314218    30720.193571\n",
       "314219    53239.669271\n",
       "314220    20085.596915\n",
       "314221    15467.033823\n",
       "314222    42003.546320\n",
       "Name: price, Length: 125690, dtype: float64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ktools",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
