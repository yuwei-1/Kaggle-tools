{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pytorch-tabnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, root_mean_squared_error, root_mean_squared_log_error, mean_absolute_error\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from functools import reduce\n",
    "from dataclasses import dataclass\n",
    "import os\n",
    "from scipy.stats import ks_2samp\n",
    "from typing import *\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x):\n",
    "    return x\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataSciencePipelineSettings:\n",
    "    train_csv_path : str\n",
    "    test_csv_path : str\n",
    "    target_col_name : str\n",
    "    original_csv_path : str = None\n",
    "    original_csv_processing : callable = func\n",
    "    sample_submission_path : str = None\n",
    "    training_col_names : List[str] = None\n",
    "    categorical_col_names : List[str] = None\n",
    "    training_data_percentage : float = 0.8\n",
    "    category_occurrence_threshold : int = 300\n",
    "    logged : bool = False\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.train_df, self.test_df = self._load_csv_paths()\n",
    "        self.training_col_names, self.categorical_col_names = self._get_column_info()\n",
    "        self.combined_df = self._combine_datasets()\n",
    "\n",
    "    def _load_csv_paths(self):\n",
    "        train_df = self._smart_drop_index(pd.read_csv(self.train_csv_path))\n",
    "        test_df = self._smart_drop_index(pd.read_csv(self.test_csv_path))\n",
    "        if self.original_csv_path is not None:\n",
    "            train_df = train_df.assign(source=0)\n",
    "            test_df = test_df.assign(source=0)\n",
    "            original_df = self._smart_drop_index(pd.read_csv(self.original_csv_path)).assign(source=1)\n",
    "            original_df = self.original_csv_processing(original_df)\n",
    "\n",
    "            pd.testing.assert_index_equal(train_df.columns.sort_values(), original_df.columns.sort_values(), check_exact=True)\n",
    "            pd.testing.assert_series_equal(train_df.dtypes.sort_index(), original_df.dtypes.sort_index(), check_exact=True)\n",
    "            train_df = pd.concat([train_df, original_df], axis=0).reset_index(drop=True)\n",
    "\n",
    "        return train_df, test_df\n",
    "    \n",
    "    def _get_column_info(self):\n",
    "        cat_col_names = [col_name for col_name in self.train_df.columns if self.train_df[col_name].dtype == 'object']\n",
    "        training_features = list(self.train_df.drop(columns=self.target_col_name).columns)\n",
    "        return training_features, cat_col_names\n",
    "    \n",
    "    def _combine_datasets(self):\n",
    "        combined_df = pd.concat([self.train_df, self.test_df], keys=['train', 'test'])\n",
    "        return combined_df\n",
    "    \n",
    "    def update(self):\n",
    "        self.train_df = self.combined_df.loc['train'].copy()\n",
    "        self.test_df = self.combined_df.loc['test'].copy()\n",
    "        return self.train_df, self.test_df        \n",
    "\n",
    "    @staticmethod\n",
    "    def _smart_drop_index(df):\n",
    "        try:\n",
    "            differences = df.iloc[:, 0].diff().dropna()\n",
    "            if differences.nunique() == 1:\n",
    "                df = df.drop(columns=df.columns[0])\n",
    "        except:\n",
    "            pass\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier, TabNetRegressor\n",
    "\n",
    "\n",
    "class TabNetModel():\n",
    "\n",
    "    def __init__(self,\n",
    "                 cat_idcs : List[int],\n",
    "                 cat_dims : List[int],\n",
    "                 cat_emb_dims : List[int] = None,\n",
    "                 eval_metric : List[str] = None,\n",
    "                 batch_size : int = 1024,\n",
    "                 virtual_batch_size : int = 128,\n",
    "                 num_workers : int = 0,\n",
    "                 drop_last : bool = False,\n",
    "                 max_epochs : int = 200,\n",
    "                 patience : int = 50,\n",
    "                 random_state=129,\n",
    "                 verbose=0,\n",
    "                 seed=0,\n",
    "                 task : str = \"regression\",\n",
    "                 **tabnet_params) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        cat_emb_dims = cat_emb_dims if cat_emb_dims is not None else [int(math.sqrt(x)) for x in cat_dims]\n",
    "        self._batch_size = batch_size\n",
    "        self._virtual_batch_size = virtual_batch_size\n",
    "        self._num_workers = num_workers\n",
    "        self._drop_last = drop_last\n",
    "        self._max_epochs = max_epochs\n",
    "        self._patience = patience\n",
    "        self._random_state = random_state\n",
    "        self._verbose = verbose\n",
    "        self._seed = seed\n",
    "        self._task = task\n",
    "\n",
    "        if task == \"binary\":\n",
    "            self.model = TabNetClassifier(\n",
    "                                        cat_idxs=cat_idcs,\n",
    "                                        cat_dims=cat_dims,\n",
    "                                        cat_emb_dim=cat_emb_dims,\n",
    "                                        verbose=verbose,\n",
    "                                        seed=seed,\n",
    "                                        **tabnet_params\n",
    "                                        )\n",
    "            self._eval_metric = eval_metric if eval_metric is not None else ['auc']\n",
    "\n",
    "        elif task == \"regression\":\n",
    "            self.model = TabNetRegressor(\n",
    "                                        cat_idxs=cat_idcs,\n",
    "                                        cat_dims=cat_dims,\n",
    "                                        cat_emb_dim=cat_emb_dims,\n",
    "                                        verbose=verbose,\n",
    "                                        seed=seed,\n",
    "                                        **tabnet_params\n",
    "                                        )\n",
    "            self._eval_metric = eval_metric if eval_metric is not None else ['rmse']\n",
    "    \n",
    "    def fit(self, X, y, validation_set = None, val_size=0.05):\n",
    "        if validation_set is None:\n",
    "            X_train, X_valid, y_train, y_valid = train_test_split(X, \n",
    "                                                                  y, \n",
    "                                                                  test_size=val_size, \n",
    "                                                                  random_state=self._random_state)\n",
    "        else:\n",
    "            X_train, y_train = X, y\n",
    "            X_valid, y_valid = validation_set\n",
    "\n",
    "        X_train, X_valid, y_train, y_valid = X_train.values, X_valid.values, y_train.values.squeeze(), y_valid.values.squeeze()\n",
    "        self.model.fit(\n",
    "                        X_train=X_train, y_train=y_train,\n",
    "                        eval_set=[(X_valid, y_valid)],\n",
    "                        eval_name=['val'],\n",
    "                        eval_metric=self._eval_metric,  \n",
    "                        batch_size=self._batch_size,\n",
    "                        virtual_batch_size=self._virtual_batch_size,\n",
    "                        num_workers=self._num_workers,\n",
    "                        drop_last=self._drop_last,\n",
    "                        max_epochs=self._max_epochs,\n",
    "                        patience = self._patience,\n",
    "                    )\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X : pd.DataFrame):\n",
    "        X = X.values\n",
    "        if self._task == \"regression\":\n",
    "            y_pred = self.model.predict(X)\n",
    "        elif self._task == \"binary\":\n",
    "            y_pred = self.model.predict_proba(X)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from typing import Any, Dict, List, Tuple, Callable\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "\n",
    "class CrossValidationExecutor:\n",
    "\n",
    "    def __init__(self,\n",
    "                 sklearn_model_instance,\n",
    "                 evaluation_metric : Callable,\n",
    "                 kfold_object,\n",
    "                 use_test_as_valid=True,\n",
    "                 num_classes=None,\n",
    "                 verbose=1) -> None:\n",
    "        \n",
    "        self.model = sklearn_model_instance\n",
    "        self._evaluation_metric = evaluation_metric\n",
    "        self._kf = kfold_object\n",
    "        self._num_splits = kfold_object.get_n_splits()\n",
    "        self._use_test_as_valid = use_test_as_valid\n",
    "        self._num_classes = num_classes\n",
    "        self._verbose = verbose\n",
    "\n",
    "    def run(self, X, y, additional_data=None, local_transform_list=[lambda x : x], output_transform_list=[lambda x : x]) -> Tuple[Tuple[float], np.ndarray, List[Any]]:\n",
    "        if additional_data is not None:\n",
    "            X_add, y_add = additional_data\n",
    "            pd.testing.assert_index_equal(X.columns, X_add.columns, check_exact=True)\n",
    "            pd.testing.assert_series_equal(X.dtypes, X_add.dtypes, check_exact=True)\n",
    "            pd.testing.assert_index_equal(y.columns, y_add.columns, check_exact=True)\n",
    "            pd.testing.assert_series_equal(y.dtypes, y_add.dtypes, check_exact=True)\n",
    "\n",
    "        cv_results = []\n",
    "        model_list = []\n",
    "        oof_predictions = np.zeros(y.shape[0]) if self._num_classes is None else np.zeros((y.shape[0], self._num_classes))\n",
    "        metric_predictions = np.zeros(y.shape[0]) if self._num_classes is None else np.zeros((y.shape[0], self._num_classes))\n",
    "\n",
    "        for i, (train_index, val_index) in enumerate(self._kf.split(X, y)):\n",
    "            \n",
    "            X_train, X_test = X.iloc[train_index], X.iloc[val_index]\n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "            if additional_data is not None:\n",
    "                X_train = pd.concat([X_train, X_add], axis=0)\n",
    "                y_train = pd.concat([y_train, y_add], axis=0)\n",
    "\n",
    "            X_train, y_train = reduce(lambda acc, func: func(acc), local_transform_list, (X_train, y_train))\n",
    "            validation_set = None\n",
    "            if self._use_test_as_valid:\n",
    "                validation_set = [X_test, y_test]\n",
    "\n",
    "            model = deepcopy(self.model).fit(X_train, y_train, validation_set=validation_set)\n",
    "            model_list += [model]\n",
    "            y_pred = model.predict(X_test)\n",
    "            y_pred_processed = reduce(lambda acc, func: func(acc), output_transform_list, y_pred)\n",
    "            \n",
    "            cv_results += [self._evaluation_metric(y_test, y_pred_processed)]\n",
    "            oof_predictions[val_index] = y_pred\n",
    "            metric_predictions[val_index] = y_pred_processed\n",
    "\n",
    "            if self._verbose > 1:\n",
    "                print(f\"The CV results of the current fold is {cv_results[-1]}\")\n",
    "\n",
    "        oof_score = self._evaluation_metric(y, metric_predictions)\n",
    "        mean_cv_score = np.mean(cv_results)\n",
    "        score_tuple = (oof_score, mean_cv_score)\n",
    "\n",
    "        if self._verbose > 0:\n",
    "            print(\"#\"*100)\n",
    "            print(\"OOF prediction score : \", oof_score)\n",
    "            print(f\"Mean {self._num_splits}-cv results : {mean_cv_score} +- {np.std(cv_results)}\")\n",
    "            print(\"#\"*100)\n",
    "\n",
    "        return score_tuple, oof_predictions, model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogTransformTarget():\n",
    "    @staticmethod\n",
    "    def transform(original_settings : DataSciencePipelineSettings):\n",
    "        settings = deepcopy(original_settings)\n",
    "        settings.combined_df[settings.target_col_name] = np.log1p(settings.combined_df[settings.target_col_name])\n",
    "        return settings\n",
    "\n",
    "class FillNullValues():\n",
    "    @staticmethod\n",
    "    def transform(original_settings : DataSciencePipelineSettings, numeric_fill=-1, category_fill='missing'):\n",
    "        settings = deepcopy(original_settings)\n",
    "        for col_name in settings.training_col_names:\n",
    "            if pd.api.types.is_numeric_dtype(settings.combined_df[col_name]):\n",
    "                settings.combined_df[col_name] = settings.combined_df[col_name].fillna(numeric_fill)\n",
    "            else:\n",
    "                settings.combined_df[col_name] = settings.combined_df[col_name].fillna(category_fill)\n",
    "        return settings\n",
    "    \n",
    "class ConvertObjectToCategorical():\n",
    "    @staticmethod\n",
    "    def transform(original_settings : DataSciencePipelineSettings):\n",
    "        settings = deepcopy(original_settings)\n",
    "        cat_cols = settings.categorical_col_names\n",
    "        settings.combined_df[cat_cols] = settings.combined_df[cat_cols].astype('category')\n",
    "        return settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = DataSciencePipelineSettings(train_csv_path,\n",
    "                                        test_csv_path,\n",
    "                                        target_col_name\n",
    "                                        )\n",
    "transforms = [\n",
    "            LogTransformTarget.transform,\n",
    "            FillNullValues.transform,\n",
    "            # CreateYuweiFeatures.transform,\n",
    "            ConvertObjectToCategorical.transform,\n",
    "            ]\n",
    "\n",
    "settings = reduce(lambda acc, func: func(acc), transforms, settings)\n",
    "settings.update()\n",
    "\n",
    "train, test_df = settings.update()\n",
    "test_df.drop(columns=[target_col_name], inplace=True)\n",
    "X, y = train.drop(columns=target_col_name), train[[target_col_name]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_idcs = [i for i in X.columns if X.columns[i].dtype == 'category']\n",
    "cat_dims = [test_df.max()[i] for i in cat_idcs]\n",
    "cat_dims = [int(x) for x in cat_dims]\n",
    "\n",
    "params = {\"cat_idcs\" : cat_idcs, \"cat_dims\" : cat_dims, \"task\" : \"binary\", \"patience\" : 5, \"n_d\" : 16, \"n_a\" : 16, \"verbose\" : 1, \"eval_metric\" : ['accuracy']}\n",
    "\n",
    "kf = KFold(5, shuffle=True, random_state=42)\n",
    "\n",
    "cve = CrossValidationExecutor(TabNetModel(**params),\n",
    "                              accuracy_score,\n",
    "                              kf,\n",
    "                              verbose=2\n",
    "                              ).fit(X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ktools_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
