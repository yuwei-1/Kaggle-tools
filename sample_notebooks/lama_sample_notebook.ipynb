{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "import os\n",
    "import random\n",
    "from typing import Any, List, Union\n",
    "import torch\n",
    "from abc import ABC, abstractmethod\n",
    "from lightautoml.automl.presets.tabular_presets import TabularAutoML, TabularUtilizedAutoML\n",
    "from lightautoml.tasks import Task\n",
    "from dataclasses import dataclass\n",
    "from copy import deepcopy\n",
    "from functools import reduce\n",
    "import os\n",
    "import random\n",
    "from typing import Any, List, Union\n",
    "import torch\n",
    "from abc import ABC, abstractmethod\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x):\n",
    "    return x\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataSciencePipelineSettings:\n",
    "    train_csv_path : str\n",
    "    test_csv_path : str\n",
    "    target_col_name : str\n",
    "    original_csv_path : str = None\n",
    "    original_csv_processing : callable = func\n",
    "    sample_submission_path : str = None\n",
    "    training_col_names : List[str] = None\n",
    "    categorical_col_names : List[str] = None\n",
    "    training_data_percentage : float = 0.8\n",
    "    category_occurrence_threshold : int = 300\n",
    "    logged : bool = False\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.train_df, self.test_df = self._load_csv_paths()\n",
    "        self.training_col_names, self.categorical_col_names = self._get_column_info()\n",
    "        self.combined_df = self._combine_datasets()\n",
    "\n",
    "    def _load_csv_paths(self):\n",
    "        train_df = self._smart_drop_index(pd.read_csv(self.train_csv_path))\n",
    "        test_df = self._smart_drop_index(pd.read_csv(self.test_csv_path))\n",
    "        if self.original_csv_path is not None:\n",
    "            train_df = train_df.assign(source=0)\n",
    "            test_df = test_df.assign(source=0)\n",
    "            original_df = self._smart_drop_index(pd.read_csv(self.original_csv_path)).assign(source=1)\n",
    "            original_df = self.original_csv_processing(original_df)\n",
    "\n",
    "            pd.testing.assert_index_equal(train_df.columns.sort_values(), original_df.columns.sort_values(), check_exact=True)\n",
    "            pd.testing.assert_series_equal(train_df.dtypes.sort_index(), original_df.dtypes.sort_index(), check_exact=True)\n",
    "            train_df = pd.concat([train_df, original_df], axis=0).reset_index(drop=True)\n",
    "\n",
    "        return train_df, test_df\n",
    "    \n",
    "    def _get_column_info(self):\n",
    "        cat_col_names = [col_name for col_name in self.train_df.columns if self.train_df[col_name].dtype == 'object']\n",
    "        training_features = list(self.train_df.drop(columns=self.target_col_name).columns)\n",
    "        return training_features, cat_col_names\n",
    "    \n",
    "    def _combine_datasets(self):\n",
    "        combined_df = pd.concat([self.train_df, self.test_df], keys=['train', 'test'])\n",
    "        return combined_df\n",
    "    \n",
    "    def update(self):\n",
    "        self.train_df = self.combined_df.loc['train'].copy()\n",
    "        self.test_df = self.combined_df.loc['test'].copy()\n",
    "        return self.train_df, self.test_df        \n",
    "\n",
    "    @staticmethod\n",
    "    def _smart_drop_index(df):\n",
    "        try:\n",
    "            differences = df.iloc[:, 0].diff().dropna()\n",
    "            if differences.nunique() == 1:\n",
    "                df = df.drop(columns=df.columns[0])\n",
    "        except:\n",
    "            pass\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FillNullValues():\n",
    "    @staticmethod\n",
    "    def transform(original_settings : DataSciencePipelineSettings, numeric_fill=-1, category_fill='missing'):\n",
    "        settings = deepcopy(original_settings)\n",
    "        for col_name in settings.training_col_names:\n",
    "            if pd.api.types.is_numeric_dtype(settings.combined_df[col_name]):\n",
    "                settings.combined_df[col_name] = settings.combined_df[col_name].fillna(numeric_fill)\n",
    "            else:\n",
    "                settings.combined_df[col_name] = settings.combined_df[col_name].fillna(category_fill)\n",
    "        return settings\n",
    "    \n",
    "\n",
    "class ConvertObjectToCategorical():\n",
    "    @staticmethod\n",
    "    def transform(original_settings : DataSciencePipelineSettings):\n",
    "        settings = deepcopy(original_settings)\n",
    "        cat_cols = settings.categorical_col_names\n",
    "        settings.combined_df[cat_cols] = settings.combined_df[cat_cols].astype('category')\n",
    "        return settings\n",
    "    \n",
    "class LogTransformTarget():\n",
    "    @staticmethod\n",
    "    def transform(original_settings : DataSciencePipelineSettings):\n",
    "        settings = deepcopy(original_settings)\n",
    "        settings.combined_df[settings.target_col_name] = np.log1p(settings.combined_df[settings.target_col_name])\n",
    "        return settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv_path = \"/Users/yuwei-1/Documents/projects/Kaggle-tools/data/insurance/train.csv\"\n",
    "test_csv_path = \"/Users/yuwei-1/Documents/projects/Kaggle-tools/data/insurance/test.csv\"\n",
    "target_col_name = \"Premium Amount\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IAutomlWrapper(ABC):\n",
    "\n",
    "    def __init__(self,\n",
    "                 train_csv_path : str,\n",
    "                 test_csv_path : str,\n",
    "                 target_col_name : str,\n",
    "                 kfold_object,\n",
    "                 data_transforms : List[Any] = [FillNullValues.transform,\n",
    "                                                ConvertObjectToCategorical.transform],\n",
    "                 model_name : Union[str, None] = None,\n",
    "                 random_state : int = 42,\n",
    "                 save_predictions : bool = True,\n",
    "                 save_path : str = \"\"\n",
    "                 ) -> None:\n",
    "        \n",
    "        self._train_csv_path = train_csv_path\n",
    "        self._test_csv_path = test_csv_path\n",
    "        self._target_col_name = target_col_name\n",
    "        self._kfold_object = kfold_object\n",
    "        self._data_transforms = data_transforms\n",
    "        self._random_state = random_state\n",
    "        self._save_predictions = save_predictions\n",
    "        self._save_path = save_path\n",
    "        self._set_random_seeds()\n",
    "        self._set_model_name_and_save_paths(model_name)\n",
    "        self.train_df, self.test_df = self._data_setup()\n",
    "        self.model = self._model_setup()\n",
    "\n",
    "    def _set_random_seeds(self):\n",
    "        np.random.seed(self._random_state)\n",
    "        random.seed(self._random_state)\n",
    "        torch.manual_seed(self._random_state)\n",
    "\n",
    "    def _data_setup(self):\n",
    "        settings = DataSciencePipelineSettings(self._train_csv_path,\n",
    "                                               self._test_csv_path,\n",
    "                                               self._target_col_name,\n",
    "                                               )\n",
    "\n",
    "        settings = reduce(lambda acc, func: func(acc), self._data_transforms, settings)\n",
    "        train_df, test_df = settings.update()\n",
    "        test_df.drop(columns=[self._target_col_name], inplace=True)\n",
    "        return train_df, test_df\n",
    "\n",
    "    @abstractmethod\n",
    "    def _set_model_name_and_save_paths(self, model_name):\n",
    "        self._model_name = model_name\n",
    "        self._oof_save_path = os.path.join(self._save_path, f\"{model_name}_oof.csv\")\n",
    "        self._test_save_path = os.path.join(self._save_path, f\"{model_name}_test.csv\")\n",
    "\n",
    "    @abstractmethod\n",
    "    def _model_setup(self):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def fit(self):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def predict(self, df : Union[pd.DataFrame, None] = None):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KToolsLAMAWrapper(IAutomlWrapper):\n",
    "\n",
    "    def __init__(self,\n",
    "                 train_csv_path : str,\n",
    "                 test_csv_path : str,\n",
    "                 target_col_name : str,\n",
    "                 kfold_object,\n",
    "                 task : str = \"regression\",\n",
    "                 metric : str = \"rmse\",\n",
    "                 time_limit : float = 3600,\n",
    "                 verbosity : int = 2,\n",
    "                 lama_models : List[List[str]] = [['lgb', 'lgb_tuned', 'cb', 'cb_tuned']],\n",
    "                 data_transforms : List[Any] = [FillNullValues.transform,\n",
    "                                                ConvertObjectToCategorical.transform],\n",
    "                 model_name : Union[str, None] = None,\n",
    "                 random_state : int = 42,\n",
    "                 save_predictions : bool = True,\n",
    "                 save_path : str = \"\"\n",
    "                 ) -> None:\n",
    "        self._task = task\n",
    "        self._metric = metric\n",
    "        self._time_limit = time_limit\n",
    "        self._verbosity = verbosity\n",
    "        self._lama_models = lama_models\n",
    "\n",
    "        super().__init__(train_csv_path,\n",
    "                         test_csv_path,\n",
    "                         target_col_name,\n",
    "                         kfold_object,\n",
    "                         data_transforms,\n",
    "                         model_name,\n",
    "                         random_state,\n",
    "                         save_predictions,\n",
    "                         save_path\n",
    "                         )\n",
    "    \n",
    "    def _set_model_name_and_save_paths(self, model_name):\n",
    "        self._model_name = model_name if model_name is not None else '_'.join(self._lama_models[0])\n",
    "        self._oof_save_path = os.path.join(self._save_path, f\"{model_name}_lama_oof.csv\")\n",
    "        self._test_save_path = os.path.join(self._save_path, f\"{model_name}_lama_test.csv\")\n",
    "\n",
    "    def _model_setup(self) -> TabularAutoML:\n",
    "\n",
    "        task = Task(self._task, metric=self._metric)\n",
    "        predictor = TabularAutoML(\n",
    "            task = task,\n",
    "            timeout = self._time_limit,\n",
    "            general_params={\"use_algos\": self._lama_models})\n",
    "\n",
    "        return predictor\n",
    "    \n",
    "    def fit(self):\n",
    "        X, y = self.train_df.drop(columns=self._target_col_name), self.train_df[[self._target_col_name]]\n",
    "        roles = {'target' : self._target_col_name}\n",
    "        oof_pred = self.model.fit_predict(self.train_df, \n",
    "                                          roles = roles, \n",
    "                                          verbose = 2,\n",
    "                                          cv_iter=list(self._kfold_object.split(X, y))\n",
    "                                          )\n",
    "        self.oof_pred = pd.Series(oof_pred.data)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, df : Union[pd.DataFrame, None] = None):\n",
    "        if df is not None:\n",
    "            all_y_preds = self.model.predict(df)\n",
    "            all_y_preds = pd.Series(all_y_preds.data)\n",
    "            if self._save_predictions: all_y_preds.to_csv(self._test_save_path)\n",
    "        else:\n",
    "            all_y_preds = self.oof_pred\n",
    "            if self._save_predictions: all_y_preds.to_csv(self._oof_save_path)\n",
    "        return all_y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(5, shuffle=True, random_state=42)\n",
    "ktools_ag_model = KToolsLAMAWrapper(train_csv_path,\n",
    "                                        test_csv_path,\n",
    "                                        target_col_name,\n",
    "                                        kf,\n",
    "                                        data_transforms = [\n",
    "                                                           LogTransformTarget.transform,\n",
    "                                                           FillNullValues.transform, \n",
    "                                                           ConvertObjectToCategorical.transform],\n",
    "                                        eval_metric=\"root_mean_squared_error\",\n",
    "                                        problem_type=\"regression\",\n",
    "                                        time_limit=3600,\n",
    "                                        save_predictions=False,\n",
    "                                        save_path=\"/kaggle/working/\"\n",
    "                                        ).fit()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
