{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "import os\n",
    "import random\n",
    "from typing import Any, Dict, List, Union\n",
    "from autogluon.tabular import TabularPredictor\n",
    "import torch\n",
    "# from ktools.utils.data_science_pipeline_settings import DataSciencePipelineSettings\n",
    "# from ktools.preprocessing.basic_feature_transformers import *\n",
    "from copy import deepcopy\n",
    "from dataclasses import dataclass\n",
    "from typing import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x):\n",
    "    return x\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataSciencePipelineSettings:\n",
    "    train_csv_path : str\n",
    "    test_csv_path : str\n",
    "    target_col_name : str\n",
    "    original_csv_path : str = None\n",
    "    original_csv_processing : callable = func\n",
    "    sample_submission_path : str = None\n",
    "    training_col_names : List[str] = None\n",
    "    categorical_col_names : List[str] = None\n",
    "    training_data_percentage : float = 0.8\n",
    "    category_occurrence_threshold : int = 300\n",
    "    logged : bool = False\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.train_df, self.test_df = self._load_csv_paths()\n",
    "        self.training_col_names, self.categorical_col_names = self._get_column_info()\n",
    "        self.combined_df = self._combine_datasets()\n",
    "\n",
    "    def _load_csv_paths(self):\n",
    "        train_df = self._smart_drop_index(pd.read_csv(self.train_csv_path))\n",
    "        test_df = self._smart_drop_index(pd.read_csv(self.test_csv_path))\n",
    "        if self.original_csv_path is not None:\n",
    "            train_df = train_df.assign(source=0)\n",
    "            test_df = test_df.assign(source=0)\n",
    "            original_df = self._smart_drop_index(pd.read_csv(self.original_csv_path)).assign(source=1)\n",
    "            original_df = self.original_csv_processing(original_df)\n",
    "\n",
    "            pd.testing.assert_index_equal(train_df.columns.sort_values(), original_df.columns.sort_values(), check_exact=True)\n",
    "            pd.testing.assert_series_equal(train_df.dtypes.sort_index(), original_df.dtypes.sort_index(), check_exact=True)\n",
    "            train_df = pd.concat([train_df, original_df], axis=0).reset_index(drop=True)\n",
    "\n",
    "        return train_df, test_df\n",
    "    \n",
    "    def _get_column_info(self):\n",
    "        cat_col_names = [col_name for col_name in self.train_df.columns if self.train_df[col_name].dtype == 'object']\n",
    "        training_features = list(self.train_df.drop(columns=self.target_col_name).columns)\n",
    "        return training_features, cat_col_names\n",
    "    \n",
    "    def _combine_datasets(self):\n",
    "        combined_df = pd.concat([self.train_df, self.test_df], keys=['train', 'test'])\n",
    "        return combined_df\n",
    "    \n",
    "    def update(self):\n",
    "        self.train_df = self.combined_df.loc['train'].copy()\n",
    "        self.test_df = self.combined_df.loc['test'].copy()\n",
    "        return self.train_df, self.test_df        \n",
    "\n",
    "    @staticmethod\n",
    "    def _smart_drop_index(df):\n",
    "        try:\n",
    "            differences = df.iloc[:, 0].diff().dropna()\n",
    "            if differences.nunique() == 1:\n",
    "                df = df.drop(columns=df.columns[0])\n",
    "        except:\n",
    "            pass\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FillNullValues():\n",
    "    @staticmethod\n",
    "    def transform(original_settings : DataSciencePipelineSettings, numeric_fill=-1, category_fill='missing'):\n",
    "        settings = deepcopy(original_settings)\n",
    "        for col_name in settings.training_col_names:\n",
    "            if pd.api.types.is_numeric_dtype(settings.combined_df[col_name]):\n",
    "                settings.combined_df[col_name] = settings.combined_df[col_name].fillna(numeric_fill)\n",
    "            else:\n",
    "                settings.combined_df[col_name] = settings.combined_df[col_name].fillna(category_fill)\n",
    "        return settings\n",
    "    \n",
    "\n",
    "class ConvertObjectToCategorical():\n",
    "    @staticmethod\n",
    "    def transform(original_settings : DataSciencePipelineSettings):\n",
    "        settings = deepcopy(original_settings)\n",
    "        cat_cols = settings.categorical_col_names\n",
    "        settings.combined_df[cat_cols] = settings.combined_df[cat_cols].astype('category')\n",
    "        return settings\n",
    "    \n",
    "class LogTransformTarget():\n",
    "    @staticmethod\n",
    "    def transform(original_settings : DataSciencePipelineSettings):\n",
    "        settings = deepcopy(original_settings)\n",
    "        settings.combined_df[settings.target_col_name] = np.log1p(settings.combined_df[settings.target_col_name])\n",
    "        return settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv_path = \"/Users/yuwei-1/Documents/projects/Kaggle-tools/data/insurance/train.csv\"\n",
    "test_csv_path = \"/Users/yuwei-1/Documents/projects/Kaggle-tools/data/insurance/test.csv\"\n",
    "target_col_name = \"Premium Amount\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KToolsAutogluonWrapper:\n",
    "\n",
    "    def __init__(self,\n",
    "                 train_csv_path : str,\n",
    "                 test_csv_path : str,\n",
    "                 target_col_name : str,\n",
    "                 kfold_object,\n",
    "                 data_transforms : List[Any] = [FillNullValues.transform,\n",
    "                                                ConvertObjectToCategorical.transform],\n",
    "                 included_model_types : List[str] = ['CAT', 'GBM', 'XGB'],\n",
    "                 ag_name : str = None,\n",
    "                 eval_metric : str = \"accuracy\",\n",
    "                 problem_type : str = \"binary\",\n",
    "                 time_limit : float = 3600*11,\n",
    "                 random_state : int = 42,\n",
    "                 autogluon_kwargs : Dict[str, Any] = {\"verbosity\":2,\n",
    "                                                      \"num_cpus\":4,\n",
    "                                                      \"num_gpus\":2},\n",
    "                 save_predictions : bool = True,\n",
    "                 save_path : str = \"\"\n",
    "                 ) -> None:\n",
    "        self._train_csv_path = train_csv_path\n",
    "        self._test_csv_path = test_csv_path\n",
    "        self._target_col_name = target_col_name\n",
    "        self._kfold_object = kfold_object\n",
    "        self._data_transforms = data_transforms\n",
    "        self._included_model_types = included_model_types\n",
    "        self.ag_name = ag_name if ag_name is not None else '_'.join(included_model_types)\n",
    "        self._eval_metric = eval_metric\n",
    "        self._problem_type = problem_type\n",
    "        self._time_limit = time_limit\n",
    "        self._random_state = random_state\n",
    "        self._autogluon_kwargs = autogluon_kwargs\n",
    "        self._oof_save_path = os.path.join(save_path, f\"{self.ag_name}_oof.csv\")\n",
    "        self._test_save_path = os.path.join(save_path, f\"{self.ag_name}_test.csv\")\n",
    "        self._save_predictions = save_predictions\n",
    "        self._set_random_seeds()\n",
    "        self.train_df, self.test_df, self.model = self._setup()\n",
    "\n",
    "\n",
    "    def _set_random_seeds(self):\n",
    "        np.random.seed(self._random_state)\n",
    "        random.seed(self._random_state)\n",
    "        torch.manual_seed(self._random_state)\n",
    "\n",
    "    def _setup(self):\n",
    "        \n",
    "        kfold_col_name = \"fold\"\n",
    "        settings = DataSciencePipelineSettings(self._train_csv_path,\n",
    "                                               self._test_csv_path,\n",
    "                                               self._target_col_name,\n",
    "                                               )\n",
    "\n",
    "        settings = reduce(lambda acc, func: func(acc), self._data_transforms, settings)\n",
    "        train_df, test_df = settings.update()\n",
    "        test_df.drop(columns=[self._target_col_name], inplace=True)\n",
    "        X, y = train_df.drop(columns=self._target_col_name), train_df[[self._target_col_name]]\n",
    "\n",
    "        split = self._kfold_object.split(X, y)\n",
    "        for i, (_, val_index) in enumerate(split):\n",
    "            train_df.loc[val_index, kfold_col_name] = i\n",
    "\n",
    "        predictor = TabularPredictor(label=self._target_col_name,\n",
    "                                     eval_metric=self._eval_metric,\n",
    "                                     problem_type=self._problem_type,\n",
    "                                     groups=kfold_col_name\n",
    "                                     )\n",
    "        \n",
    "        return train_df, test_df, predictor\n",
    "\n",
    "    def fit(self):\n",
    "        self.model = self.model.fit(self.train_df,\n",
    "                                    presets='best_quality',\n",
    "                                    time_limit=self._time_limit,\n",
    "                                    included_model_types=self._included_model_types,\n",
    "                                    **self._autogluon_kwargs\n",
    "                                    )\n",
    "        return self\n",
    "    \n",
    "    def predict(self, df : Union[pd.DataFrame, None] = None):\n",
    "        if df is not None:\n",
    "            all_y_preds = self.model.predict_multi(df)\n",
    "            all_y_preds = pd.DataFrame.from_dict(all_y_preds)\n",
    "            if self._save_predictions: all_y_preds.to_csv(self._test_csv_path)\n",
    "        else:\n",
    "            all_y_preds = self.model.predict_multi()\n",
    "            all_y_preds = pd.DataFrame.from_dict(all_y_preds)\n",
    "            if self._save_predictions: all_y_preds.to_csv(self._oof_save_path)\n",
    "\n",
    "        return all_y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(5, shuffle=True, random_state=42)\n",
    "ktools_ag_model = KToolsAutogluonWrapper(train_csv_path,\n",
    "                                        test_csv_path,\n",
    "                                        target_col_name,\n",
    "                                        kf,\n",
    "                                        data_transforms = [\n",
    "                                                           LogTransformTarget.transform,\n",
    "                                                           FillNullValues.transform, \n",
    "                                                           ConvertObjectToCategorical.transform],\n",
    "                                        eval_metric=\"root_mean_squared_error\",\n",
    "                                        problem_type=\"regression\",\n",
    "                                        time_limit=3600,\n",
    "                                   #      autogluon_kwargs={ \"verbosity\": 2,\"num_cpus\": 1},\n",
    "                                        save_predictions=False,\n",
    "                                        save_path=\"/kaggle/working/\"\n",
    "                                        ).fit()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
