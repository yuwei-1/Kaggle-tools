{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5d01f1e",
   "metadata": {},
   "source": [
    "## Import Standard Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd6b1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import List, Optional, Tuple, Callable, Union, Any, Dict, Type\n",
    "from dataclasses import dataclass\n",
    "from abc import ABC, abstractmethod\n",
    "from copy import deepcopy\n",
    "from enum import Enum\n",
    "\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.trial import Trial\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cat\n",
    "from catboost import Pool\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e48043",
   "metadata": {},
   "source": [
    "## Configuration Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f23d466",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DatasetConfig:\n",
    "    \"\"\"Configuration for dataset column information\"\"\"\n",
    "    training_col_names: List[str]\n",
    "    target_col_name: str\n",
    "    numerical_col_names: List[str]\n",
    "    categorical_col_names: List[str]\n",
    "    name: Optional[str] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca465228",
   "metadata": {},
   "source": [
    "## Base Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266d9ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseKtoolsModel(ABC):\n",
    "    \"\"\"Base class for all models\"\"\"\n",
    "    def __init__(self) -> None:\n",
    "        self._fitted = False\n",
    "        self.model = None\n",
    "\n",
    "    @abstractmethod\n",
    "    def fit(\n",
    "        self,\n",
    "        X,\n",
    "        y,\n",
    "        validation_set: Optional[Tuple] = None,\n",
    "        weights: Optional[np.ndarray] = None,\n",
    "    ) -> \"BaseKtoolsModel\":\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def predict(self, X) -> np.ndarray:\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    def fitted(self) -> bool:\n",
    "        return self._fitted\n",
    "\n",
    "\n",
    "class BasePreprocessor(ABC):\n",
    "    \"\"\"Base class for all preprocessors\"\"\"\n",
    "    name = \"base-preprocessor\"\n",
    "\n",
    "    def __init__(self, config: DatasetConfig):\n",
    "        self._fitted = False\n",
    "        self.config = config\n",
    "\n",
    "    @abstractmethod\n",
    "    def fit(self, data: pd.DataFrame) -> \"BasePreprocessor\":\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def transform(self, data: pd.DataFrame) -> pd.DataFrame:\n",
    "        pass\n",
    "\n",
    "    def fit_transform(self, data: pd.DataFrame) -> pd.DataFrame:\n",
    "        return self.fit(data).transform(data)\n",
    "\n",
    "    @property\n",
    "    def fitted(self) -> bool:\n",
    "        return self._fitted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b27a810",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0309c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_task(y: Union[np.ndarray, pd.Series]) -> str:\n",
    "    \"\"\"Infer the task type from target values\"\"\"\n",
    "    if isinstance(y, pd.Series):\n",
    "        y = y.to_numpy()\n",
    "    y = y.flatten()\n",
    "\n",
    "    nuniques = np.unique(y).shape[0]\n",
    "    has_floats = np.any(y % 1 != 0)\n",
    "\n",
    "    if has_floats:\n",
    "        print(\"Target contains float values. Inferring regression task.\")\n",
    "        return \"regression\"\n",
    "    elif nuniques == 2:\n",
    "        print(\"Target contains two unique values. Inferring binary classification task.\")\n",
    "        return \"binary_classification\"\n",
    "    elif nuniques > 2:\n",
    "        print(\"Target contains more than two unique values. Inferring multiclass classification task.\")\n",
    "        return \"multiclass_classification\"\n",
    "\n",
    "    raise ValueError(\n",
    "        \"Unable to infer task type from target values. Is there only one target value?\"\n",
    "    )\n",
    "\n",
    "\n",
    "NestedDict = dict[str, \"NestedDict | Any\"]\n",
    "TrialSampler = Callable[[Trial], Any]\n",
    "\n",
    "\n",
    "def load_optuna_grid(\n",
    "    path: str,\n",
    "    model_type: str,\n",
    "    extra_samplers: Dict[str, TrialSampler] | None = None,\n",
    ") -> Callable[[Trial], Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Load an Optuna parameter grid from a YAML file.\n",
    "\n",
    "    Args:\n",
    "        path: Path to the YAML file containing parameter grids.\n",
    "        model_type: Key in the YAML file for the model's parameter grid.\n",
    "        extra_samplers: Additional tunable parameters as Optuna callables.\n",
    "            Each callable takes a Trial and returns a sampled value.\n",
    "            Example: {\"weight\": lambda t: t.suggest_float(\"weight\", 0.5, 2.0)}\n",
    "\n",
    "    Returns:\n",
    "        A callable that takes an Optuna Trial and returns sampled parameters.\n",
    "    \"\"\"\n",
    "    with open(path, \"r\") as f:\n",
    "        param_grid: NestedDict = yaml.safe_load(f)\n",
    "    param_grid = param_grid.get(model_type, {})\n",
    "    if len(param_grid) == 0:\n",
    "        raise ValueError(f\"No parameter grid found for model type: {model_type}\")\n",
    "\n",
    "    def param_grid_getter(trial: Trial) -> Dict[str, Any]:\n",
    "        unpacked = {}\n",
    "        for param_name, param_info in param_grid.items():\n",
    "            dtype = param_info.get(\"type\")\n",
    "            if dtype == \"int\":\n",
    "                unpacked[param_name] = trial.suggest_int(\n",
    "                    param_name,\n",
    "                    param_info[\"low\"],\n",
    "                    param_info[\"high\"],\n",
    "                )\n",
    "            elif dtype == \"float\":\n",
    "                unpacked[param_name] = trial.suggest_float(\n",
    "                    param_name,\n",
    "                    param_info[\"low\"],\n",
    "                    param_info[\"high\"],\n",
    "                    log=param_info.get(\"log\", False),\n",
    "                )\n",
    "            elif dtype == \"categorical\":\n",
    "                unpacked[param_name] = trial.suggest_categorical(\n",
    "                    param_name,\n",
    "                    param_info[\"choices\"],\n",
    "                )\n",
    "            elif dtype == \"fixed\":\n",
    "                unpacked[param_name] = trial.set_user_attr(\n",
    "                    param_name, param_info[\"value\"]\n",
    "                )\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported parameter type: {dtype}\")\n",
    "\n",
    "        if extra_samplers:\n",
    "            for param_name, sampler in extra_samplers.items():\n",
    "                unpacked[param_name] = sampler(trial)\n",
    "\n",
    "        return unpacked\n",
    "\n",
    "    return param_grid_getter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f2aa23",
   "metadata": {},
   "source": [
    "## Preprocessing Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6e8270",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoricalEncoder(BasePreprocessor):\n",
    "    \"\"\"Encoder for categorical features\"\"\"\n",
    "    name = \"categorical-encoder\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        config: DatasetConfig,\n",
    "        handle_unknown: str = \"use_encoded_value\",\n",
    "        unknown_value: int = -2,\n",
    "        encoded_missing_value: int = -1,\n",
    "        **encoder_kwargs,\n",
    "    ) -> None:\n",
    "        super().__init__(config)\n",
    "        self.encode_missing_value = encoded_missing_value\n",
    "        self.encoder = OrdinalEncoder(\n",
    "            handle_unknown=handle_unknown,\n",
    "            unknown_value=unknown_value,\n",
    "            encoded_missing_value=encoded_missing_value,\n",
    "            **encoder_kwargs,\n",
    "        )\n",
    "\n",
    "    def fit(self, data: pd.DataFrame) -> \"CategoricalEncoder\":\n",
    "        self.encoder.fit(data[self.config.categorical_col_names])\n",
    "        self._fitted = True\n",
    "        return self\n",
    "\n",
    "    def transform(self, data: pd.DataFrame) -> pd.DataFrame:\n",
    "        copy = data.copy()\n",
    "        mask = copy[self.config.categorical_col_names].isna()\n",
    "        copy[self.config.categorical_col_names] = self.encoder.transform(\n",
    "            copy[self.config.categorical_col_names]\n",
    "        ).astype(int)\n",
    "        copy[self.config.categorical_col_names] = (\n",
    "            copy[self.config.categorical_col_names]\n",
    "            .where(~mask, self.encode_missing_value)\n",
    "            .astype(\"category\")\n",
    "        )\n",
    "        return copy\n",
    "\n",
    "\n",
    "class StandardScale(BasePreprocessor):\n",
    "    \"\"\"Standard scaler for numerical features\"\"\"\n",
    "    name = \"standard-scaler\"\n",
    "\n",
    "    def __init__(self, config: DatasetConfig) -> None:\n",
    "        super().__init__(config)\n",
    "        self.scaler = StandardScaler()\n",
    "\n",
    "    def fit(self, data: pd.DataFrame) -> \"StandardScale\":\n",
    "        self.scaler.fit(data[self.config.numerical_col_names])\n",
    "        self._fitted = True\n",
    "        return self\n",
    "\n",
    "    def transform(self, data: pd.DataFrame) -> pd.DataFrame:\n",
    "        copy = data.copy()\n",
    "        copy[self.config.numerical_col_names] = self.scaler.transform(\n",
    "            copy[self.config.numerical_col_names]\n",
    "        )\n",
    "        return copy\n",
    "\n",
    "\n",
    "class PreprocessingPipeline:\n",
    "    \"\"\"Pipeline for preprocessing steps\"\"\"\n",
    "    def __init__(self, preprocessors: List[BasePreprocessor]) -> None:\n",
    "        self.preprocessors = preprocessors\n",
    "\n",
    "    def train_pipe(self, data: pd.DataFrame) -> pd.DataFrame:\n",
    "        for preprocessor in self.preprocessors:\n",
    "            data = preprocessor.fit_transform(data)\n",
    "        return data\n",
    "\n",
    "    def inference_pipe(self, data: pd.DataFrame) -> pd.DataFrame:\n",
    "        for preprocessor in self.preprocessors:\n",
    "            data = preprocessor.transform(data)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6a6aba",
   "metadata": {},
   "source": [
    "## Model Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033ce8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DefaultObjective(Enum):\n",
    "    \"\"\"Default objectives for different tasks\"\"\"\n",
    "    regression = \"regression\"\n",
    "    binary_classification = \"binary\"\n",
    "    multiclass_classification = \"multiclass\"\n",
    "\n",
    "\n",
    "class LGBMModel(BaseKtoolsModel):\n",
    "    \"\"\"LightGBM model wrapper\"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_boost_round: int = 100,\n",
    "        early_stopping_rounds: Union[int, None] = 20,\n",
    "        random_state: int = 129,\n",
    "        verbose: int = -1,\n",
    "        n_jobs: int = 1,\n",
    "        callbacks: List[Any] = [],\n",
    "        **lgb_param_grid,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self._num_boost_round = num_boost_round\n",
    "        self._verbose = verbose\n",
    "        self._n_jobs = n_jobs\n",
    "        self._callbacks = callbacks\n",
    "        self.early_stopping_rounds = early_stopping_rounds\n",
    "\n",
    "        self._lgb_param_grid = {\n",
    "            \"verbose\": verbose,\n",
    "            \"random_state\": random_state,\n",
    "            \"n_jobs\": n_jobs,\n",
    "            **lgb_param_grid,\n",
    "        }\n",
    "\n",
    "    def fit(\n",
    "        self,\n",
    "        X,\n",
    "        y,\n",
    "        validation_set: Optional[Tuple] = None,\n",
    "        weights: Optional[np.ndarray] = None,\n",
    "    ) -> \"LGBMModel\":\n",
    "        if \"objective\" not in self._lgb_param_grid:\n",
    "            task_id = infer_task(y)\n",
    "            self._lgb_param_grid[\"objective\"] = DefaultObjective[task_id].value\n",
    "            if task_id == \"multiclass_classification\":\n",
    "                self._lgb_param_grid[\"num_class\"] = np.unique(y).shape[0]\n",
    "\n",
    "        train_data = lgb.Dataset(X, label=y, weight=weights)\n",
    "        eval_sets = [train_data]\n",
    "        eval_names = [\"train\"]\n",
    "        if validation_set is not None:\n",
    "            X_val, y_val = validation_set\n",
    "            val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)\n",
    "            eval_sets += [val_data]\n",
    "            eval_names += [\"valid\"]\n",
    "            self._lgb_param_grid[\"early_stopping_rounds\"] = self.early_stopping_rounds\n",
    "\n",
    "        train_params = {\n",
    "            \"params\": self._lgb_param_grid,\n",
    "            \"train_set\": train_data,\n",
    "            \"num_boost_round\": self._num_boost_round,\n",
    "            \"valid_sets\": eval_sets,\n",
    "            \"valid_names\": eval_names,\n",
    "            \"callbacks\": self._callbacks,\n",
    "        }\n",
    "\n",
    "        self.model = lgb.train(**train_params)\n",
    "        self._fitted = True\n",
    "        return self\n",
    "\n",
    "    def predict(self, X) -> np.ndarray:\n",
    "        y_pred = self.model.predict(X)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b655e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "class XGBoostModel(BaseKtoolsModel):\n",
    "    \"\"\"XGBoost model wrapper\"\"\"\n",
    "    class DefaultObjective(Enum):\n",
    "        regression = \"reg:squarederror\"\n",
    "        binary_classification = \"binary:logistic\"\n",
    "        multiclass_classification = \"multi:softprob\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        eval_verbosity: bool = False,\n",
    "        num_boost_round: int = 100,\n",
    "        early_stopping_rounds: Union[int, None] = 20,\n",
    "        random_state: int = 129,\n",
    "        verbosity: int = 0,\n",
    "        n_jobs: int = 1,\n",
    "        **xgb_param_grid,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self._eval_verbosity = eval_verbosity\n",
    "        self._num_boost_round = num_boost_round\n",
    "        self._verbosity = verbosity\n",
    "        self._n_jobs = n_jobs\n",
    "        self._early_stopping_rounds = early_stopping_rounds\n",
    "\n",
    "        self._xgb_param_grid = {\n",
    "            \"verbosity\": verbosity,\n",
    "            \"random_state\": random_state,\n",
    "            \"n_jobs\": n_jobs,\n",
    "            **xgb_param_grid,\n",
    "        }\n",
    "\n",
    "    def fit(\n",
    "        self,\n",
    "        X,\n",
    "        y,\n",
    "        validation_set: Optional[Tuple] = None,\n",
    "        weights: Optional[np.ndarray] = None,\n",
    "    ) -> \"XGBoostModel\":\n",
    "        train_params = {}\n",
    "        if \"objective\" not in self._xgb_param_grid:\n",
    "            task_id = infer_task(y)\n",
    "            self._xgb_param_grid[\"objective\"] = self.DefaultObjective[task_id].value\n",
    "            if task_id == \"multiclass_classification\":\n",
    "                self._xgb_param_grid[\"num_class\"] = np.unique(y).shape[0]\n",
    "\n",
    "        train_data = xgb.DMatrix(X, label=y, enable_categorical=True, weight=weights)\n",
    "        eval_data = [(train_data, \"train\")]\n",
    "        if validation_set is not None:\n",
    "            X_val, y_val = validation_set\n",
    "            valid_data = xgb.DMatrix(X_val, label=y_val, enable_categorical=True)\n",
    "            eval_data += [(valid_data, \"eval\")]\n",
    "            train_params[\"early_stopping_rounds\"] = self._early_stopping_rounds\n",
    "\n",
    "        train_params = {\n",
    "            \"params\": self._xgb_param_grid,\n",
    "            \"dtrain\": train_data,\n",
    "            \"evals\": eval_data,\n",
    "            \"num_boost_round\": self._num_boost_round,\n",
    "            \"verbose_eval\": self._eval_verbosity,\n",
    "            **train_params,\n",
    "        }\n",
    "\n",
    "        self.model = xgb.train(**train_params)\n",
    "        self._fitted = True\n",
    "        return self\n",
    "\n",
    "    def predict(self, X) -> np.ndarray:\n",
    "        test_data = xgb.DMatrix(X, enable_categorical=True)\n",
    "        y_pred = self.model.predict(test_data)\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "class CatBoostModel(BaseKtoolsModel):\n",
    "    \"\"\"CatBoost model wrapper\"\"\"\n",
    "    class DefaultObjective(Enum):\n",
    "        regression = \"RMSE\"\n",
    "        binary_classification = \"Logloss\"\n",
    "        multiclass_classification = \"MultiClass\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_boost_round: int = 100,\n",
    "        early_stopping_rounds: Optional[int] = 20,\n",
    "        random_state: int = 129,\n",
    "        verbose: bool = False,\n",
    "        allow_writing_files: bool = False,\n",
    "        **catboost_params,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.model: Union[cat.CatBoost, None] = None\n",
    "        self._task: bool = False\n",
    "        self._num_boost_round = num_boost_round\n",
    "        self._verbose = verbose\n",
    "        self._allow_writing_files = allow_writing_files\n",
    "        self._early_stopping_rounds = early_stopping_rounds\n",
    "\n",
    "        self._catboost_params = {\n",
    "            \"random_seed\": random_state,\n",
    "            \"verbose\": verbose,\n",
    "            \"allow_writing_files\": allow_writing_files,\n",
    "            **catboost_params,\n",
    "        }\n",
    "\n",
    "    def fit(\n",
    "        self,\n",
    "        X,\n",
    "        y,\n",
    "        validation_set: Optional[Tuple] = None,\n",
    "        weights: Optional[np.ndarray] = None,\n",
    "    ) -> \"CatBoostModel\":\n",
    "        task_id = infer_task(y)\n",
    "        self._task = task_id\n",
    "        if \"loss_function\" not in self._catboost_params:\n",
    "            self._catboost_params[\"loss_function\"] = self.DefaultObjective[task_id].value\n",
    "\n",
    "        self.cat_col_names = (\n",
    "            [col for col in X.columns if X[col].dtype == \"category\"]\n",
    "            if isinstance(X, pd.DataFrame)\n",
    "            else []\n",
    "        )\n",
    "        train_params: Dict[Any, Any] = {\"eval_set\": None}\n",
    "        train_pool = Pool(\n",
    "            data=X, label=y, cat_features=self.cat_col_names, weight=weights\n",
    "        )\n",
    "        if validation_set is not None:\n",
    "            X_val, y_val = validation_set\n",
    "            train_params[\"eval_set\"] = Pool(\n",
    "                data=X_val, label=y_val, cat_features=self.cat_col_names\n",
    "            )\n",
    "            train_params[\"early_stopping_rounds\"] = self._early_stopping_rounds\n",
    "\n",
    "        train_params = {\n",
    "            \"params\": self._catboost_params,\n",
    "            \"dtrain\": train_pool,\n",
    "            \"num_boost_round\": self._num_boost_round,\n",
    "            **train_params,\n",
    "        }\n",
    "        self.model = cat.train(**train_params)\n",
    "        self._fitted = True\n",
    "        return self\n",
    "\n",
    "    def predict(self, X) -> np.ndarray:\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Model is not fitted yet. Please call 'fit' first.\")\n",
    "        test_pool = Pool(data=X, cat_features=self.cat_col_names)\n",
    "        if self._task == \"binary_classification\":\n",
    "            y_pred = self.model.predict(test_pool, prediction_type=\"Probability\")[:, 1]\n",
    "        elif self._task == \"multiclass_classification\":\n",
    "            y_pred = self.model.predict(test_pool, prediction_type=\"Probability\")\n",
    "        else:\n",
    "            y_pred = self.model.predict(test_pool)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920f4d1c",
   "metadata": {},
   "source": [
    "## Model Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9e37a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelPipeline:\n",
    "    \"\"\"Pipeline for model training with preprocessing\"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: BaseKtoolsModel,\n",
    "        config: DatasetConfig,\n",
    "        preprocessor: PreprocessingPipeline = PreprocessingPipeline([]),\n",
    "    ) -> None:\n",
    "        self.model = model\n",
    "        self.config = config\n",
    "        self.preprocessor = preprocessor\n",
    "\n",
    "    def fit(\n",
    "        self,\n",
    "        train_data: pd.DataFrame,\n",
    "        validation_data: Optional[pd.DataFrame] = None,\n",
    "        weights: Optional[Union[pd.Series, np.ndarray]] = None,\n",
    "    ) -> \"ModelPipeline\":\n",
    "        train_data = self.preprocessor.train_pipe(train_data)\n",
    "        X_train = train_data.drop(columns=[self.config.target_col_name])\n",
    "        y_train = train_data[self.config.target_col_name]\n",
    "\n",
    "        if validation_data is not None:\n",
    "            validation_data = self.preprocessor.inference_pipe(validation_data)\n",
    "            X_valid = validation_data.drop(columns=[self.config.target_col_name])\n",
    "            y_valid = validation_data[self.config.target_col_name]\n",
    "            validation_data = (X_valid, y_valid)\n",
    "\n",
    "        self.model.fit(\n",
    "            X=X_train, y=y_train, validation_set=validation_data, weights=weights\n",
    "        )\n",
    "        return self\n",
    "\n",
    "    def predict(self, data: pd.DataFrame) -> np.ndarray:\n",
    "        data = self.preprocessor.inference_pipe(data)\n",
    "        X_test = data[self.config.training_col_names]\n",
    "        return self.model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9236cef3",
   "metadata": {},
   "source": [
    "## Optuna Hyperparameter Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e889c2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptunaHyperparameterOptimizer:\n",
    "    \"\"\"\n",
    "    Hyperparameter optimizer using Optuna's TPE sampler.\n",
    "\n",
    "    Args:\n",
    "        model_type: Type of model to optimize (e.g., \"catboost\", \"lightgbm\").\n",
    "        grid_yaml_path: Path to YAML file containing parameter search space.\n",
    "        extra_samplers: Additional tunable parameters as Optuna callables.\n",
    "        timeout: Maximum optimization time in seconds.\n",
    "        direction: Optimization direction (\"maximize\" or \"minimize\").\n",
    "        n_trials: Number of trials to run.\n",
    "        study_name: Name for the Optuna study.\n",
    "        explore_fraction: Fraction of trials for exploration phase.\n",
    "        save_study: Whether to persist the study to SQLite.\n",
    "        load_if_exists: Whether to resume an existing study with the same name.\n",
    "        catch_exceptions: Tuple of exception types to catch during optimization.\n",
    "        verbose: Whether to log progress information.\n",
    "        random_state: Random seed for reproducibility.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_type: str,\n",
    "        grid_yaml_path: str,\n",
    "        extra_samplers: Dict[str, TrialSampler] | None = None,\n",
    "        timeout: int = 3600,\n",
    "        direction: str = \"maximize\",\n",
    "        n_trials: int = 100,\n",
    "        study_name: str = \"ml_experiment\",\n",
    "        explore_fraction: float = 0.1,\n",
    "        save_study: bool = False,\n",
    "        load_if_exists: bool = True,\n",
    "        catch_exceptions: Tuple[Type[Exception], ...] = (),\n",
    "        verbose: bool = False,\n",
    "        random_state: int = 42,\n",
    "    ) -> None:\n",
    "        self._param_space_builder = load_optuna_grid(grid_yaml_path, model_type, extra_samplers=extra_samplers)\n",
    "        self._timeout = timeout\n",
    "        self._direction = direction\n",
    "        self._n_trials = n_trials\n",
    "        self._study_name = study_name\n",
    "        self._explore_fraction = explore_fraction\n",
    "        self._save_study = save_study\n",
    "        self._load_if_exists = load_if_exists\n",
    "        self._catch_exceptions = catch_exceptions\n",
    "        self._verbose = verbose\n",
    "        self._random_state = random_state\n",
    "        self.study: optuna.Study | None = None\n",
    "\n",
    "    def optimize(\n",
    "        self,\n",
    "        *args: Any,\n",
    "        tunable_func: Callable[..., float],\n",
    "    ) -> dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Run hyperparameter optimization.\n",
    "\n",
    "        Args:\n",
    "            *args: Positional arguments passed to tunable_func.\n",
    "            tunable_func: Function that takes (*args, **hyperparameters) and returns a score.\n",
    "\n",
    "        Returns:\n",
    "            Dictionary of best hyperparameters found.\n",
    "        \"\"\"\n",
    "        if self._verbose:\n",
    "            print(\"#\" * 100)\n",
    "            print(\"Starting Optuna Optimizer\")\n",
    "            print(\"#\" * 100)\n",
    "\n",
    "        sampler = TPESampler(\n",
    "            n_startup_trials=int(self._n_trials * self._explore_fraction),\n",
    "            seed=self._random_state,\n",
    "        )\n",
    "\n",
    "        storage_name = f\"sqlite:///{self._study_name}.db\" if self._save_study else None\n",
    "\n",
    "        self.study = optuna.create_study(\n",
    "            sampler=sampler,\n",
    "            study_name=self._study_name,\n",
    "            direction=self._direction,\n",
    "            storage=storage_name,\n",
    "            load_if_exists=self._load_if_exists,\n",
    "        )\n",
    "\n",
    "        def objective(trial: optuna.Trial) -> float:\n",
    "            parameters = self._param_space_builder(trial)\n",
    "            return tunable_func(*args, **parameters)\n",
    "\n",
    "        self.study.optimize(\n",
    "            objective,\n",
    "            n_trials=self._n_trials,\n",
    "            timeout=self._timeout,\n",
    "            catch=self._catch_exceptions,\n",
    "        )\n",
    "\n",
    "        return self.study.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a49da9",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "Load your training and test data. This example uses the diabetes prediction dataset with the cv-experimentation pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307fb3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update these paths to match your dataset location\n",
    "DATA_PATH = Path(\"./data/diabetes_prediction/\")\n",
    "TARGET = \"diagnosed_diabetes\"\n",
    "\n",
    "# ID split for separating data sources\n",
    "split_id = 678000\n",
    "\n",
    "# Load data\n",
    "orig_data = pd.read_csv(DATA_PATH / \"original.csv\")\n",
    "train_data = pd.read_csv(DATA_PATH / \"train.csv\", index_col=0)\n",
    "test_data = pd.read_csv(DATA_PATH / \"test.csv\", index_col=0).assign(data=0)\n",
    "test_data[\"data\"] = test_data[\"data\"].astype(\"category\")\n",
    "\n",
    "print(f\"Original data shape: {orig_data.shape}\")\n",
    "print(f\"Train shape: {train_data.shape}\")\n",
    "print(f\"Test shape: {test_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a42fb0d",
   "metadata": {},
   "source": [
    "## Prepare Data with Source Labels\n",
    "\n",
    "Add data source labels for stratified CV and validation filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750b758f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure column alignment\n",
    "assert (train_data.columns == train_data.columns.intersection(orig_data.columns)).all()\n",
    "\n",
    "# Add data source labels\n",
    "orig_data = orig_data.drop(columns=orig_data.columns.difference(train_data.columns).to_list())\n",
    "orig_data = orig_data.assign(data=2)\n",
    "train_data = train_data.assign(data=np.nan)\n",
    "train_data.iloc[:split_id, -1] = 1\n",
    "train_data.iloc[split_id:, -1] = 0\n",
    "\n",
    "# Create stratification categories (target + data source)\n",
    "categories_of_interest = train_data[TARGET].astype(str) + \"_\" + train_data[\"data\"].astype(str)\n",
    "\n",
    "print(f\"Categories distribution:\\n{categories_of_interest.value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6c13fd",
   "metadata": {},
   "source": [
    "## Configure Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24ed588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify column types\n",
    "training_col_names = train_data.drop(columns=TARGET).columns.tolist()\n",
    "numerical_col_names = (\n",
    "    train_data.drop(columns=TARGET)\n",
    "    .select_dtypes(include=[\"number\"])\n",
    "    .columns.tolist()\n",
    ")\n",
    "categorical_col_names = train_data.select_dtypes(\n",
    "    include=[\"object\"]\n",
    ").columns.tolist()\n",
    "\n",
    "# Create dataset configuration\n",
    "config = DatasetConfig(\n",
    "    training_col_names=training_col_names,\n",
    "    numerical_col_names=numerical_col_names,\n",
    "    categorical_col_names=categorical_col_names,\n",
    "    target_col_name=TARGET,\n",
    ")\n",
    "\n",
    "print(f\"Numerical features ({len(numerical_col_names)}): {numerical_col_names}\")\n",
    "print(f\"\\nCategorical features ({len(categorical_col_names)}): {categorical_col_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c813697a",
   "metadata": {},
   "source": [
    "## Setup Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355b7633",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_tunable_func(\n",
    "    train_data: pd.DataFrame,\n",
    "    test_data: pd.DataFrame,\n",
    "    categories_of_interest: pd.Series,\n",
    "    config: DatasetConfig,\n",
    "    preprocessors: List[BasePreprocessor],\n",
    "    model_class: Type[BaseKtoolsModel],\n",
    "    sample_weight_data0: float = 1.5,  # Tunable weight for data == 0 samples\n",
    "    **model_params,\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Cross-validation function to be tuned by Optuna.\n",
    "    \n",
    "    This function follows the cv-experimentation pattern:\n",
    "    - Stratified K-Fold on (target + data source)\n",
    "    - Validation fold filtered to data == 0.0 only\n",
    "    - Sample weights based on data source (tunable)\n",
    "    \n",
    "    Args:\n",
    "        train_data: Training DataFrame with 'data' column for source labels.\n",
    "        test_data: Test DataFrame (for OOF predictions).\n",
    "        categories_of_interest: Series for stratification (target + data source).\n",
    "        config: DatasetConfig with column information.\n",
    "        preprocessors: List of preprocessors to apply.\n",
    "        model_class: Model class to instantiate (e.g., LGBMModel).\n",
    "        sample_weight_data0: Weight multiplier for samples where data == 0.\n",
    "            Higher values give more importance to these samples.\n",
    "        **model_params: Hyperparameters to pass to the model.\n",
    "        \n",
    "    Returns:\n",
    "        Mean ROC AUC score across folds.\n",
    "    \"\"\"\n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    mean_score: float = 0.0\n",
    "    \n",
    "    for train_index, val_index in kfold.split(train_data, categories_of_interest):\n",
    "        train_fold: pd.DataFrame = train_data.iloc[train_index].copy()\n",
    "        val_fold: pd.DataFrame = train_data.iloc[val_index]\n",
    "        \n",
    "        # Filter validation to data == 0.0 only (matching cv-experimentation pattern)\n",
    "        val_fold = val_fold[val_fold[\"data\"] == 0.0]\n",
    "        \n",
    "        # Convert data column to category\n",
    "        train_fold[\"data\"] = train_fold[\"data\"].astype(\"category\")\n",
    "        \n",
    "        # Sample weights: tunable weight for data == 0\n",
    "        weights = np.where(train_fold[\"data\"] == 0, sample_weight_data0, 1.0)\n",
    "        \n",
    "        # Create fresh preprocessor pipeline for each fold\n",
    "        preprocessor_pipeline = PreprocessingPipeline(\n",
    "            preprocessors=[deepcopy(p) for p in preprocessors]\n",
    "        )\n",
    "        \n",
    "        # Create model pipeline\n",
    "        pipe = ModelPipeline(\n",
    "            model=model_class(**model_params),\n",
    "            config=config,\n",
    "            preprocessor=preprocessor_pipeline,\n",
    "        )\n",
    "        \n",
    "        # Fit and predict\n",
    "        pipe.fit(train_fold, validation_data=val_fold, weights=weights)\n",
    "        y_pred = pipe.predict(val_fold)\n",
    "        \n",
    "        # Calculate score\n",
    "        score = roc_auc_score(val_fold[config.target_col_name], y_pred)\n",
    "        mean_score += score / 5\n",
    "    \n",
    "    return mean_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83330bd",
   "metadata": {},
   "source": [
    "## Run Hyperparameter Optimization\n",
    "\n",
    "Create the optimizer and run optimization with the tunable CV function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed82f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to your parameter grid YAML file\n",
    "GRID_YAML_PATH = \"ktools/hyperopt/grids/lgbm.yml\"  # Update with your grid path\n",
    "MODEL_TYPE = \"base\"  # The key in the YAML file\n",
    "MODEL_CLASS = LGBMModel  # Change to XGBoostModel or CatBoostModel as needed\n",
    "\n",
    "# Extra samplers for tuning non-model parameters (e.g., sample weights)\n",
    "# Range rationale for sample_weight_data0:\n",
    "#   - 0.5: Down-weight data==0 samples (less trust in this data source)\n",
    "#   - 1.0: Equal weight (no preference)\n",
    "#   - 3.0: Strong up-weight (3x importance for data==0 samples)\n",
    "# A log scale helps explore both <1 and >1 ranges effectively\n",
    "extra_samplers = {\n",
    "    \"sample_weight_data0\": lambda t: t.suggest_float(\"sample_weight_data0\", 1.0, 5.0),\n",
    "}\n",
    "\n",
    "# Create optimizer with updated signature\n",
    "optimizer = OptunaHyperparameterOptimizer(\n",
    "    model_type=MODEL_TYPE,\n",
    "    grid_yaml_path=GRID_YAML_PATH,\n",
    "    extra_samplers=extra_samplers,\n",
    "    timeout=42000,  # ~11.5 hours, adjust as needed\n",
    "    direction=\"maximize\",\n",
    "    n_trials=300,  # Increase for better optimization\n",
    "    study_name=\"kaggle_cv_optimizer\",\n",
    "    explore_fraction=0.1,\n",
    "    save_study=False,\n",
    "    load_if_exists=True,\n",
    "    catch_exceptions=(),\n",
    "    verbose=True,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "print(\"Optimizer configured:\")\n",
    "print(f\"  Model type: {MODEL_TYPE}\")\n",
    "print(f\"  Grid path: {GRID_YAML_PATH}\")\n",
    "print(f\"  Max trials: {optimizer._n_trials}\")\n",
    "print(f\"  Timeout: {optimizer._timeout}s\")\n",
    "print(f\"  Extra samplers: {list(extra_samplers.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae63af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run optimization - note: config is now passed explicitly to cv_tunable_func\n",
    "best_params = optimizer.optimize(\n",
    "    train_data,\n",
    "    test_data,\n",
    "    categories_of_interest,\n",
    "    config,  # Pass config explicitly\n",
    "    [CategoricalEncoder(config), StandardScale(config)],\n",
    "    MODEL_CLASS,\n",
    "    tunable_func=cv_tunable_func,\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"OPTIMIZATION COMPLETE!\")\n",
    "print(\"=\" * 100)\n",
    "print(f\"\\nBest Score: {optimizer.study.best_value:.6f}\")\n",
    "print(f\"\\nBest Parameters:\")\n",
    "for key, value in best_params.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eafb1aa",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook provides a complete workflow for hyperparameter optimization using the cv-experimentation pattern:\n",
    "\n",
    "**Key Features:**\n",
    "1. **Stratified K-Fold CV** on combined (target + data source) categories\n",
    "2. **Validation filtering** to only include `data == 0.0` samples\n",
    "3. **Sample weighting** with higher weight for `data == 0` samples\n",
    "4. **Tunable function pattern** for flexible optimization\n",
    "\n",
    "**How It Works:**\n",
    "1. `cv_tunable_func` encapsulates the entire CV loop\n",
    "2. `OptunaHyperparameterOptimizer.optimize()` receives this function via `tunable_func=`\n",
    "3. Optuna suggests hyperparameters which are passed as `**model_params`\n",
    "4. The function returns the mean CV score for Optuna to optimize\n",
    "\n",
    "**Supported Models:**\n",
    "- `LGBMModel` (LightGBM)\n",
    "- `XGBoostModel` (XGBoost)  \n",
    "- `CatBoostModel` (CatBoost)\n",
    "\n",
    "**Parameter Grid YAML Format:**\n",
    "```yaml\n",
    "base:  # or your model_type key\n",
    "  param_name:\n",
    "    type: int  # or float, categorical, fixed\n",
    "    low: 1\n",
    "    high: 10\n",
    "    # For float, add: log: true (optional)\n",
    "    # For categorical, use: choices: [val1, val2, ...]\n",
    "    # For fixed, use: value: some_value\n",
    "```\n",
    "\n",
    "**Extra Samplers (Optional):**\n",
    "For parameters not in the YAML grid, use `extra_samplers`:\n",
    "```python\n",
    "extra_samplers = {\n",
    "    \"weight_power\": lambda t: t.suggest_float(\"weight_power\", 0.5, 2.0),\n",
    "}\n",
    "load_optuna_grid(path, model_type, extra_samplers=extra_samplers)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
