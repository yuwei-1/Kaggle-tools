{"cells":[{"cell_type":"code","execution_count":90,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["import re\n","import numpy as np\n","import pandas as pd\n","import os\n","from hillclimbers import climb_hill\n","from functools import partial\n","from sklearn.metrics import root_mean_squared_error\n","from dataclasses import dataclass\n","from typing import *\n","import pandas as pd\n","import xgboost as xgb"]},{"cell_type":"code","execution_count":2,"metadata":{"trusted":true},"outputs":[],"source":["@dataclass\n","class DataSciencePipelineSettings:\n","    train_csv_path : str\n","    test_csv_path : str\n","    target_col_name : str\n","    sample_submission_path : str = None\n","    training_col_names : List[str] = None\n","    categorical_col_names : List[str] = None\n","    training_data_percentage : float = 0.8\n","    category_occurrence_threshold : int = 300\n","    logged : bool = False\n","\n","    def __post_init__(self):\n","        self.train_df, self.test_df = self._load_csv_paths()\n","        self.training_col_names, self.categorical_col_names = self._get_column_info()\n","        self.combined_df = self._combine_datasets()\n","\n","    def _load_csv_paths(self):\n","        train_df = pd.read_csv(self.train_csv_path, index_col=0)\n","        test_df = pd.read_csv(self.test_csv_path, index_col=0)\n","        return train_df, test_df\n","    \n","    def _get_column_info(self):\n","        cat_col_names = [col_name for col_name in self.train_df.columns if self.train_df[col_name].dtype == 'object']\n","        training_features = list(self.train_df.drop(columns=self.target_col_name).columns)\n","        return training_features, cat_col_names\n","    \n","    def _combine_datasets(self):\n","        combined_df = pd.concat([self.train_df, self.test_df], keys=['train', 'test'])\n","        return combined_df\n","    \n","    def update(self):\n","        self.train_df = self.combined_df.loc['train'].copy()\n","        self.test_df = self.combined_df.loc['test'].copy()\n","        return self.train_df, self.test_df"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-09-23T06:57:19.471779Z","iopub.status.busy":"2024-09-23T06:57:19.470868Z","iopub.status.idle":"2024-09-23T06:57:19.780686Z","shell.execute_reply":"2024-09-23T06:57:19.779619Z","shell.execute_reply.started":"2024-09-23T06:57:19.471737Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/Users/yuwei-1/anaconda3/envs/ktools_2/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["import optuna\n","import joblib\n","import pandas as pd\n","import numpy as np\n","from optuna.samplers import TPESampler\n","from typing import *\n","\n","\n","class OptunaHyperparameterOptimizer:\n","\n","    def __init__(self,\n","                 X_train : pd.DataFrame,\n","                 y_train : pd.DataFrame,\n","                 model,\n","                 param_grid_getter,\n","                 kfold_object,\n","                 metric : callable,\n","                 direction : str = 'maximize',\n","                 n_trials : int = 100,\n","                 study_name : str = \"ml_experiment\",\n","                 explore_fraction : float = 0.1,\n","                 verbose=False\n","                 ) -> None:\n","        \n","        super().__init__()\n","        self._X_train = X_train\n","        self._y_train = y_train\n","        self.model = model\n","        self._metric = metric\n","        self._param_grid_getter = param_grid_getter\n","        self._kfold_object = kfold_object\n","        self._direction = direction\n","        self._n_trials = n_trials\n","        self._study_name = study_name\n","        self._explore_fraction = explore_fraction\n","        self._verbose = verbose\n","\n","    def optimize(self, \n","                 inital_parameters : Dict[str, float] = None,\n","                 initial_distribution : Dict[str, Any] = None,\n","                 timeout : int = 3600\n","                 ):\n","        if self._verbose:\n","            print(\"Starting Optuna trials...........................\")\n","        sampler = TPESampler(seed=int(self._n_trials*self._explore_fraction))\n","        study = optuna.create_study(sampler=sampler,\n","                                    study_name=self._study_name, \n","                                    direction=self._direction)\n","        \n","        if inital_parameters is not None:\n","            fixed_trial = optuna.trial.FixedTrial(inital_parameters)\n","            study.add_trial(optuna.create_trial(\n","                            params=inital_parameters,\n","                            distributions=initial_distribution,\n","                            value=self._objective(fixed_trial)\n","            ))\n","        study.optimize(self._objective, n_trials=self._n_trials, timeout=timeout)\n","        # joblib.dump(study, \"/kaggle/working/study.pkl\")\n","        optimal_params = study.best_params\n","        return optimal_params\n","    \n","    def _objective(self, trial : optuna.Trial):\n","        parameters = self._param_grid_getter.get(trial)\n","        oof_predictions = np.zeros(self._y_train.shape[0])\n","        for train_index, val_index in self._kfold_object.split(self._X_train, self._y_train):\n","            X_train_fold, X_val_fold = self._X_train.iloc[train_index], self._X_train.iloc[val_index]\n","            y_train_fold, _ = self._y_train.iloc[train_index], self._y_train.iloc[val_index]\n","\n","            model = self.model(**parameters)\n","            \n","            model.fit(X_train_fold, \n","                      y_train_fold)\n","\n","            oof_predictions[val_index] = model.predict(X_val_fold)\n","\n","        return self._metric(self._y_train.to_numpy().squeeze(), oof_predictions)"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-09-23T06:57:19.783548Z","iopub.status.busy":"2024-09-23T06:57:19.783169Z","iopub.status.idle":"2024-09-23T06:57:21.440721Z","shell.execute_reply":"2024-09-23T06:57:21.439667Z","shell.execute_reply.started":"2024-09-23T06:57:19.783488Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: user 328 ms, sys: 47.8 ms, total: 376 ms\n","Wall time: 381 ms\n"]}],"source":["%%time\n","\n","sample_sub = pd.read_csv('/Users/yuwei-1/Documents/projects/Kaggle-tools/data/used_car_prices/sample_submission.csv', index_col='id')\n","train = pd.read_csv('/Users/yuwei-1/Documents/projects/Kaggle-tools/data/used_car_prices/train.csv', index_col='id')\n","test = pd.read_csv('/Users/yuwei-1/Documents/projects/Kaggle-tools/data/used_car_prices/test.csv', index_col='id')\n","Original = pd.read_csv('/Users/yuwei-1/Documents/projects/Kaggle-tools/data/used_car_prices/original_dataset.csv')\n","\n","Original[['milage', 'price']] = Original[['milage', 'price']].map(\n","    lambda x: int(''.join(re.findall(r'\\d+', x))))\n","\n","train = pd.concat([train, Original], ignore_index=True)"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-09-23T06:57:21.443135Z","iopub.status.busy":"2024-09-23T06:57:21.442270Z","iopub.status.idle":"2024-09-23T06:57:21.541366Z","shell.execute_reply":"2024-09-23T06:57:21.540403Z","shell.execute_reply.started":"2024-09-23T06:57:21.443095Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th></th>\n","      <th>brand</th>\n","      <th>model</th>\n","      <th>model_year</th>\n","      <th>milage</th>\n","      <th>fuel_type</th>\n","      <th>engine</th>\n","      <th>transmission</th>\n","      <th>ext_col</th>\n","      <th>int_col</th>\n","      <th>accident</th>\n","      <th>clean_title</th>\n","      <th>price</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th rowspan=\"5\" valign=\"top\">train</th>\n","      <th>0</th>\n","      <td>MINI</td>\n","      <td>Cooper S Base</td>\n","      <td>2007</td>\n","      <td>213000</td>\n","      <td>Gasoline</td>\n","      <td>172.0HP 1.6L 4 Cylinder Engine Gasoline Fuel</td>\n","      <td>A/T</td>\n","      <td>Yellow</td>\n","      <td>Gray</td>\n","      <td>None reported</td>\n","      <td>Yes</td>\n","      <td>4200.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Lincoln</td>\n","      <td>LS V8</td>\n","      <td>2002</td>\n","      <td>143250</td>\n","      <td>Gasoline</td>\n","      <td>252.0HP 3.9L 8 Cylinder Engine Gasoline Fuel</td>\n","      <td>A/T</td>\n","      <td>Silver</td>\n","      <td>Beige</td>\n","      <td>At least 1 accident or damage reported</td>\n","      <td>Yes</td>\n","      <td>4999.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Chevrolet</td>\n","      <td>Silverado 2500 LT</td>\n","      <td>2002</td>\n","      <td>136731</td>\n","      <td>E85 Flex Fuel</td>\n","      <td>320.0HP 5.3L 8 Cylinder Engine Flex Fuel Capab...</td>\n","      <td>A/T</td>\n","      <td>Blue</td>\n","      <td>Gray</td>\n","      <td>None reported</td>\n","      <td>Yes</td>\n","      <td>13900.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Genesis</td>\n","      <td>G90 5.0 Ultimate</td>\n","      <td>2017</td>\n","      <td>19500</td>\n","      <td>Gasoline</td>\n","      <td>420.0HP 5.0L 8 Cylinder Engine Gasoline Fuel</td>\n","      <td>Transmission w/Dual Shift Mode</td>\n","      <td>Black</td>\n","      <td>Black</td>\n","      <td>None reported</td>\n","      <td>Yes</td>\n","      <td>45000.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Mercedes-Benz</td>\n","      <td>Metris Base</td>\n","      <td>2021</td>\n","      <td>7388</td>\n","      <td>Gasoline</td>\n","      <td>208.0HP 2.0L 4 Cylinder Engine Gasoline Fuel</td>\n","      <td>7-Speed A/T</td>\n","      <td>Black</td>\n","      <td>Beige</td>\n","      <td>None reported</td>\n","      <td>Yes</td>\n","      <td>97500.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"5\" valign=\"top\">test</th>\n","      <th>314218</th>\n","      <td>Mercedes-Benz</td>\n","      <td>GL-Class GL 450 4MATIC</td>\n","      <td>2014</td>\n","      <td>83315</td>\n","      <td>Gasoline</td>\n","      <td>362.0HP 3.0L V6 Cylinder Engine Gasoline Fuel</td>\n","      <td>7-Speed A/T</td>\n","      <td>Black</td>\n","      <td>Black</td>\n","      <td>None reported</td>\n","      <td>Yes</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>314219</th>\n","      <td>Audi</td>\n","      <td>Q7 55 Prestige</td>\n","      <td>2019</td>\n","      <td>29336</td>\n","      <td>Gasoline</td>\n","      <td>3.0 Liter Turbo</td>\n","      <td>Automatic</td>\n","      <td>White</td>\n","      <td>Black</td>\n","      <td>None reported</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>314220</th>\n","      <td>Audi</td>\n","      <td>A6 3.0T Premium Plus</td>\n","      <td>2012</td>\n","      <td>77634</td>\n","      <td>Gasoline</td>\n","      <td>333.0HP 3.0L V6 Cylinder Engine Gasoline Fuel</td>\n","      <td>A/T</td>\n","      <td>Black</td>\n","      <td>Black</td>\n","      <td>None reported</td>\n","      <td>Yes</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>314221</th>\n","      <td>Audi</td>\n","      <td>Q7 3.0T Premium</td>\n","      <td>2012</td>\n","      <td>112000</td>\n","      <td>Gasoline</td>\n","      <td>333.0HP 3.0L V6 Cylinder Engine Gasoline Fuel</td>\n","      <td>A/T</td>\n","      <td>Black</td>\n","      <td>Black</td>\n","      <td>None reported</td>\n","      <td>Yes</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>314222</th>\n","      <td>Chevrolet</td>\n","      <td>Tahoe LT</td>\n","      <td>2018</td>\n","      <td>66840</td>\n","      <td>Gasoline</td>\n","      <td>355.0HP 5.3L 8 Cylinder Engine Gasoline Fuel</td>\n","      <td>A/T</td>\n","      <td>Silver</td>\n","      <td>Black</td>\n","      <td>None reported</td>\n","      <td>Yes</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>318232 rows × 12 columns</p>\n","</div>"],"text/plain":["                      brand                   model  model_year  milage  \\\n","train 0                MINI           Cooper S Base        2007  213000   \n","      1             Lincoln                   LS V8        2002  143250   \n","      2           Chevrolet       Silverado 2500 LT        2002  136731   \n","      3             Genesis        G90 5.0 Ultimate        2017   19500   \n","      4       Mercedes-Benz             Metris Base        2021    7388   \n","...                     ...                     ...         ...     ...   \n","test  314218  Mercedes-Benz  GL-Class GL 450 4MATIC        2014   83315   \n","      314219           Audi          Q7 55 Prestige        2019   29336   \n","      314220           Audi    A6 3.0T Premium Plus        2012   77634   \n","      314221           Audi         Q7 3.0T Premium        2012  112000   \n","      314222      Chevrolet                Tahoe LT        2018   66840   \n","\n","                  fuel_type  \\\n","train 0            Gasoline   \n","      1            Gasoline   \n","      2       E85 Flex Fuel   \n","      3            Gasoline   \n","      4            Gasoline   \n","...                     ...   \n","test  314218       Gasoline   \n","      314219       Gasoline   \n","      314220       Gasoline   \n","      314221       Gasoline   \n","      314222       Gasoline   \n","\n","                                                         engine  \\\n","train 0            172.0HP 1.6L 4 Cylinder Engine Gasoline Fuel   \n","      1            252.0HP 3.9L 8 Cylinder Engine Gasoline Fuel   \n","      2       320.0HP 5.3L 8 Cylinder Engine Flex Fuel Capab...   \n","      3            420.0HP 5.0L 8 Cylinder Engine Gasoline Fuel   \n","      4            208.0HP 2.0L 4 Cylinder Engine Gasoline Fuel   \n","...                                                         ...   \n","test  314218      362.0HP 3.0L V6 Cylinder Engine Gasoline Fuel   \n","      314219                                    3.0 Liter Turbo   \n","      314220      333.0HP 3.0L V6 Cylinder Engine Gasoline Fuel   \n","      314221      333.0HP 3.0L V6 Cylinder Engine Gasoline Fuel   \n","      314222       355.0HP 5.3L 8 Cylinder Engine Gasoline Fuel   \n","\n","                                transmission ext_col int_col  \\\n","train 0                                  A/T  Yellow    Gray   \n","      1                                  A/T  Silver   Beige   \n","      2                                  A/T    Blue    Gray   \n","      3       Transmission w/Dual Shift Mode   Black   Black   \n","      4                          7-Speed A/T   Black   Beige   \n","...                                      ...     ...     ...   \n","test  314218                     7-Speed A/T   Black   Black   \n","      314219                       Automatic   White   Black   \n","      314220                             A/T   Black   Black   \n","      314221                             A/T   Black   Black   \n","      314222                             A/T  Silver   Black   \n","\n","                                            accident clean_title    price  \n","train 0                                None reported         Yes   4200.0  \n","      1       At least 1 accident or damage reported         Yes   4999.0  \n","      2                                None reported         Yes  13900.0  \n","      3                                None reported         Yes  45000.0  \n","      4                                None reported         Yes  97500.0  \n","...                                              ...         ...      ...  \n","test  314218                           None reported         Yes      NaN  \n","      314219                           None reported         NaN      NaN  \n","      314220                           None reported         Yes      NaN  \n","      314221                           None reported         Yes      NaN  \n","      314222                           None reported         Yes      NaN  \n","\n","[318232 rows x 12 columns]"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["combined = pd.concat([train, test], keys=['train', 'test'])\n","combined"]},{"cell_type":"code","execution_count":310,"metadata":{},"outputs":[],"source":["test = combined[['milage', 'model_year', 'price']]"]},{"cell_type":"code","execution_count":311,"metadata":{},"outputs":[{"data":{"text/plain":["array([31107.6880147 , 69111.16961404, 64190.13576782, ...,\n","       35498.86127536, 22815.45325778, 45733.13820494])"]},"execution_count":311,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.linear_model import LinearRegression\n","\n","train = test.loc['train']\n","\n","lr = LinearRegression()\n","lr.fit(train[['milage', 'model_year']], train['price'])\n","\n","lr.predict(test.loc['test'][['milage', 'model_year']])"]},{"cell_type":"code","execution_count":312,"metadata":{},"outputs":[],"source":["sample_sub['price'] = lr.predict(test.loc['test'][['milage', 'model_year']])"]},{"cell_type":"code","execution_count":314,"metadata":{},"outputs":[],"source":["sample_sub.to_csv(\"/Users/yuwei-1/Documents/projects/Kaggle-tools/submissions/used_cars/used_car_submission_v50.csv\")"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["from ktools.fitting.cross_validation_executor import CrossValidationExecutor\n","from ktools.modelling.models.catboost_model import CatBoostModel\n","from ktools.modelling.models.lgbm_model import LGBMModel\n","from ktools.modelling.models.xgb_model import XGBoostModel"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-09-23T06:58:30.956047Z","iopub.status.busy":"2024-09-23T06:58:30.954875Z","iopub.status.idle":"2024-09-23T06:58:30.968287Z","shell.execute_reply":"2024-09-23T06:58:30.967132Z","shell.execute_reply.started":"2024-09-23T06:58:30.955992Z"},"trusted":true},"outputs":[],"source":["SERIES_PATTERN = re.compile(r'^[A-Za-z0-9\\-]+')\n","VERSION_PATTERN = re.compile(r'([0-9]+\\.[0-9]+[A-Za-z]*)|([A-Z]+[0-9]*)')\n","TRIM_PATTERN = re.compile(r'\\b(Base|Sport|Premium|Ultimate|XLT|LZ|LT|Plus|Touring|SE|LE|Limited|Platinum|Performance|S|V6|GT|EX|SX|XLE|SR|SL|SV|XSE|TRD|RS|GranSport|Signature|Quad Cab|DRW|Cabriolet|Carbon Edition|Trail Boss|Prestige|Essence|Reserve|xDrive|4MATIC|PreRunner|EcoBoost|Scat Pack|Competition|Adventure Package|Laramie|Grand Touring|Long Range)\\b')\n","\n","def extract_car_features(df):\n","\n","    \n","    def extract_features(model):\n","        series = SERIES_PATTERN.search(model)\n","        trim = TRIM_PATTERN.search(model)\n","        \n","        return {\n","            'Series': series.group(0) if series else \"missing\",\n","            'Trim': trim.group(0) if trim else \"missing\"\n","        }\n","    \n","    extracted_features = df['model'].apply(extract_features).apply(pd.Series)\n","    df = pd.concat([df, extracted_features], axis=1)\n","    return df"]},{"cell_type":"code","execution_count":8,"metadata":{"trusted":true},"outputs":[],"source":["from sklearn.metrics import mean_squared_error\n","from sklearn.model_selection import KFold\n","\n","\n","def find_pattern(pattern, text):\n","    match = re.search(pattern, text)\n","    if match:\n","        return match.group(1)\n","    else:\n","        return None\n","\n","def transform(old_df):\n","    numeric_fill = -1\n","    category_fill = \"missing\"\n","    threshold = 200\n","    df = old_df.copy()\n","    \n","    print(\"#\"*100)\n","    print(\"Backpacker extraction\")\n","    print(\"#\"*100)\n","    df = extract_car_features(df)\n","    cat_cols = [col_name for col_name in df.columns if df[col_name].dtype == 'object']\n","\n","    print(\"#\"*100)\n","    print(\"Remove rare cats\")\n","    print(\"#\"*100)\n","    # Convert categories to lower and remove rare categories\n","    for col_name in cat_cols:\n","        df[col_name] = df[col_name].str.lower()\n","        vc = df[col_name].value_counts()\n","        rare_cats = vc.loc[vc<threshold].index.values\n","        df.loc[df[col_name].isin(rare_cats), col_name] = category_fill\n","    \n","    print(\"#\"*100)\n","    print(\"Engine feature extraction\")\n","    print(\"#\"*100)\n","    pattern = r'(\\d*\\.?\\d+)\\s*hp'\n","    df['horsepower'] = df['engine'].apply(lambda x : find_pattern(pattern, x)).astype('float64')\n","    pattern = r'(\\d*\\.?\\d+)\\s*(l|liter)'\n","    df['liters'] = df['engine'].apply(lambda x : find_pattern(pattern, x)).astype('float64')\n","    pattern = r'(\\d*\\.?\\d+)\\s*cylinder'\n","    df['cylinders'] = df['engine'].apply(lambda x : find_pattern(pattern, x)).astype('float64')\n","    \n","    bigrams = [('brand', 'clean_title'), ('brand', 'accident'), ('brand', 'fuel_type'), ('transmission', 'accident')]\n","    \n","    print(\"#\"*100)\n","    print(\"Create bigrams\")\n","    print(\"#\"*100)\n","    for (feature_1, feature_2) in bigrams:\n","        new_feature_name = feature_1 + \"_\" + feature_2\n","        df[new_feature_name] = df[feature_1].astype('str') + \"_\" + df[feature_2].astype('str')\n","        cat_cols += [new_feature_name]\n","    \n","    expensive_int_color = ['dark auburn',\n","                            'hotspur',\n","                            'cobalt blue',\n","                            'beluga hide',\n","                            'linen',\n","                            'beluga',\n","                            'black / brown',\n","                            'nero ade',\n","                            'sahara tan',\n","                            'portland']\n","    \n","    df['expensive_int_col'] = df['int_col'].isin(expensive_int_color).astype(int)\n","    \n","\n","    print(\"#\"*100)\n","    print(\"Fill null values\")\n","    print(\"#\"*100)\n","    # Fill null values\n","    for col_name in df.columns:\n","        if pd.api.types.is_numeric_dtype(df[col_name]):\n","            df[col_name] = df[col_name].fillna(numeric_fill)\n","        else:\n","            df[col_name] = df[col_name].fillna(category_fill)\n","            \n","    df[cat_cols] = df[cat_cols].astype('category')\n","    \n","    ############################################################################################################\n","    X, y = df.loc['train'].drop(columns='price'), df.loc['train', 'price']\n","    print(\"#\"*100)\n","    print(\"MAE LGBM\")\n","    print(\"#\"*100)\n","    params = {\n","            'objective': 'MAE',\n","            'num_boost_round': 1000,\n","        }\n","\n","    model = LGBMModel(**params)\n","    kf = KFold(5, shuffle=True, random_state=42)\n","    mean_cv_score, mae_oof, model_list = CrossValidationExecutor(model,\n","                                                    lambda y, yh : mean_squared_error(y, yh, squared=False),\n","                                                    kf,\n","                                                    ).run(X, y)\n","    df['MAE_feature'] = 0.0\n","    df.loc['train', 'MAE_feature'] = mae_oof\n","    \n","    for model in model_list:        \n","        df.loc['test', 'MAE_feature'] = df.loc['test', 'MAE_feature'].values + model.predict(df.loc['test'].drop(columns=['price',\n","                                                                                    'MAE_feature'])) / len(model_list)\n","        \n","    ############################################################################################################    \n","    \n","    print(\"#\"*100)\n","    print(\"No outlier LGBM\")\n","    print(\"#\"*100)\n","    \n","    X, y = df.loc['train'].drop(columns=['price', 'MAE_feature']), df.loc['train', 'price']\n","    params = {\n","            'objective': 'rmse',\n","            'num_boost_round': 1000,\n","        }\n","\n","    def remove_outliers(train_tuple, threshold=300000):\n","        X, y = train_tuple\n","        mask = (y < threshold)\n","        return X[mask], y[mask]\n","\n","    model = LGBMModel(**params)\n","    kf = KFold(5, shuffle=True, random_state=42)\n","    mean_cv_score, oof, model_list = CrossValidationExecutor(model,\n","                                                    lambda y, yh : mean_squared_error(y, yh, squared=False),\n","                                                    kf,\n","                                                    ).run(X, y, local_transform_list=[remove_outliers])\n","    df['without_outlier_feature'] = 0.0\n","    df.loc['train', 'without_outlier_feature'] = oof\n","    \n","    for model in model_list:\n","        df.loc['test', 'without_outlier_feature'] = df.loc['test', 'without_outlier_feature'].values + model.predict(df.loc['test'].drop(columns=['price',\n","                                                                                                'without_outlier_feature', 'MAE_feature'])) / len(model_list)\n","    \n","    ############################################################################################################\n","    \n","    print(\"#\"*100)\n","    print(\"Regular RMSE LGBM\")\n","    print(\"#\"*100)\n","    \n","    X = df.loc['train'].drop(columns=['price', 'without_outlier_feature'])\n","    y = df.loc['train', 'price']\n","\n","    param = {\n","        'objective': 'MSE',\n","        'num_boost_round': 1000,\n","        'random_state' : 42\n","        }\n","\n","    model = LGBMModel(**param)\n","    kf = KFold(5, shuffle=True, random_state=42)\n","    mean_cv_score, mse_oof, model_list = CrossValidationExecutor(model,\n","                                                    lambda y, yh : mean_squared_error(y, yh, squared=False),\n","                                                    kf,\n","                                                    ).run(X, y)\n","    df['MSE_feature'] = 0.0\n","    df.loc['train', 'MSE_feature'] = mse_oof \n","    for model in model_list:\n","        df.loc['test', 'MSE_feature'] = df.loc['test', 'MSE_feature'].values + model.predict(df.loc['test'].drop(columns=['price',\n","                                                                                    'MSE_feature', 'without_outlier_feature'])) / len(model_list)\n","    \n","    return df"]},{"cell_type":"code","execution_count":9,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["####################################################################################################\n","Backpacker extraction\n","####################################################################################################\n","####################################################################################################\n","Remove rare cats\n","####################################################################################################\n","####################################################################################################\n","Engine feature extraction\n","####################################################################################################\n","####################################################################################################\n","Create bigrams\n","####################################################################################################\n","####################################################################################################\n","Fill null values\n","####################################################################################################\n","####################################################################################################\n","MAE LGBM\n","####################################################################################################\n"]},{"name":"stderr","output_type":"stream","text":["/Users/yuwei-1/anaconda3/envs/ktools_2/lib/python3.10/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n","  warnings.warn(\n","/Users/yuwei-1/anaconda3/envs/ktools_2/lib/python3.10/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n","  warnings.warn(\n","/Users/yuwei-1/anaconda3/envs/ktools_2/lib/python3.10/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n","  warnings.warn(\n","/Users/yuwei-1/anaconda3/envs/ktools_2/lib/python3.10/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n","  warnings.warn(\n","/Users/yuwei-1/anaconda3/envs/ktools_2/lib/python3.10/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n","  warnings.warn(\n","/Users/yuwei-1/anaconda3/envs/ktools_2/lib/python3.10/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["####################################################################################################\n","OOF prediction score :  73603.90072538523\n","Mean 5-cv results : 73532.73766725117 +- 3236.0982318920337\n","####################################################################################################\n","####################################################################################################\n","No outlier LGBM\n","####################################################################################################\n"]},{"name":"stderr","output_type":"stream","text":["/Users/yuwei-1/anaconda3/envs/ktools_2/lib/python3.10/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n","  warnings.warn(\n","/Users/yuwei-1/anaconda3/envs/ktools_2/lib/python3.10/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n","  warnings.warn(\n","/Users/yuwei-1/anaconda3/envs/ktools_2/lib/python3.10/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n","  warnings.warn(\n","/Users/yuwei-1/anaconda3/envs/ktools_2/lib/python3.10/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n","  warnings.warn(\n","/Users/yuwei-1/anaconda3/envs/ktools_2/lib/python3.10/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n","  warnings.warn(\n","/Users/yuwei-1/anaconda3/envs/ktools_2/lib/python3.10/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["####################################################################################################\n","OOF prediction score :  72890.73947157731\n","Mean 5-cv results : 72819.1917996743 +- 3229.035027316773\n","####################################################################################################\n","####################################################################################################\n","Regular RMSE LGBM\n","####################################################################################################\n"]},{"name":"stderr","output_type":"stream","text":["/Users/yuwei-1/anaconda3/envs/ktools_2/lib/python3.10/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n","  warnings.warn(\n","/Users/yuwei-1/anaconda3/envs/ktools_2/lib/python3.10/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n","  warnings.warn(\n","/Users/yuwei-1/anaconda3/envs/ktools_2/lib/python3.10/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n","  warnings.warn(\n","/Users/yuwei-1/anaconda3/envs/ktools_2/lib/python3.10/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["####################################################################################################\n","OOF prediction score :  72940.6699018678\n","Mean 5-cv results : 72875.29006216994 +- 3087.8358733662653\n","####################################################################################################\n"]},{"name":"stderr","output_type":"stream","text":["/Users/yuwei-1/anaconda3/envs/ktools_2/lib/python3.10/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n","  warnings.warn(\n","/Users/yuwei-1/anaconda3/envs/ktools_2/lib/python3.10/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n","  warnings.warn(\n"]}],"source":["new_df = transform(combined)"]},{"cell_type":"code","execution_count":110,"metadata":{},"outputs":[],"source":["new_df.loc['test']\n","\n","\n","laml = pd.read_csv(\"/Users/yuwei-1/Documents/projects/Kaggle-tools/ktools/modelling/Data/used_cars/test_pred_lightautoml.csv\", index_col=0)\n","laml.index = new_df.loc['test'].index"]},{"cell_type":"code","execution_count":112,"metadata":{},"outputs":[],"source":["laml.to_csv(\"/Users/yuwei-1/Documents/projects/Kaggle-tools/ktools/modelling/Data/used_cars/test_pred_lightautoml.csv\")"]},{"cell_type":"code","execution_count":73,"metadata":{"execution":{"iopub.execute_input":"2024-09-22T16:14:31.540681Z","iopub.status.busy":"2024-09-22T16:14:31.539468Z","iopub.status.idle":"2024-09-22T16:18:00.951953Z","shell.execute_reply":"2024-09-22T16:18:00.951045Z","shell.execute_reply.started":"2024-09-22T16:14:31.540627Z"},"trusted":true},"outputs":[],"source":["# lgb_params = {\"num_leaves\": 426,\n","#                      \"max_depth\": 20,\n","#                      \"learning_rate\": 0.011353178352988012,\n","#                      \"n_estimators\": 884,\n","#                      \"subsample\": 0.5772552201954328,\n","#                      \"colsample_bytree\": 0.9164865430101521,\n","#                      \"reg_alpha\": 1.48699088003429e-06,\n","#                      \"reg_lambda\": 0.41539458543414265,\n","#                      \"min_data_in_leaf\": 73,\n","#                      \"feature_fraction\": 0.751673655170548,\n","#                      \"bagging_fraction\": 0.5120415391590843,\n","#                      \"bagging_freq\": 2,\n","#                      \"min_child_weight\": 0.017236362383443497,\n","#                      \"cat_smooth\": 54.81317407769262,\n","#                      \"verbose\" : -1,\n","#                      \"boosting_type\" : \"gbdt\",\n","#                      \"objective\" : \"RMSE\"}\n","\n","from ktools.modelling.create_hill_climber_from_params import CreateHillClimber\n","from ktools.modelling.models.hgb_model import HGBModel\n","from ktools.modelling.models.knn_model import KNNModel\n","from sklearn.metrics import root_mean_squared_error\n","\n","\n","# lgb_params = {'num_leaves': 280, 'max_depth': 14, 'learning_rate': 0.012732203122744722, 'num_boost_round': 910, 'subsample': 0.5433169622728463, 'colsample_bytree': 0.8994654078363041, 'reg_alpha': 0.003365552635560128, 'reg_lambda': 4.86054247720564e-05, 'min_data_in_leaf': 93, 'feature_fraction': 0.8658760205714685, 'bagging_fraction': 0.6263137171449985, 'bagging_freq': 2, 'min_child_weight': 0.1567987880086431, 'cat_smooth': 92.44970425722772}\n","\n","# lgbrf_params = {'boosting_type' : 'rf', 'num_leaves': 416, 'max_depth': 10, 'learning_rate': 0.29878113696134817, 'num_boost_round': 155, 'subsample': 0.5146981782669086, 'colsample_bytree': 0.6802672845290882, 'reg_alpha': 3.72418987215723e-05, 'reg_lambda': 0.09742367812466012, 'min_data_in_leaf': 90, 'feature_fraction': 0.682402778458027, 'bagging_fraction': 0.6199615701114239, 'bagging_freq': 3, 'min_child_weight': 0.00019854426515378276, 'cat_smooth': 72.66846341329637}\n","\n","# lgbxt_params = {'extra_trees' : True, 'num_leaves': 267, 'max_depth': 27, 'learning_rate': 0.013329061769098881, 'num_boost_round': 622, 'subsample': 0.9272129180560263, 'colsample_bytree': 0.9337728578994179, 'reg_alpha': 0.005936172293991621, 'reg_lambda': 2.8308017468852374e-05, 'min_data_in_leaf': 41, 'feature_fraction': 0.6176283288541762, 'bagging_fraction': 0.6619019559714052, 'bagging_freq': 2, 'min_child_weight': 0.007116895677043118, 'cat_smooth': 1.641684346318527}\n","\n","# cat_params = {'max_bin': 343, 'learning_rate': 0.07372402300575284, 'depth': 15, 'iterations': 898, 'bagging_temperature': 31.554515680968088, 'subsample': 0.9229527513355164, 'colsample_bylevel': 0.7888921044832126, 'min_data_in_leaf': 885.7011118582786, 'l2_leaf_reg': 9.941096483417914, 'grow_policy': 'Lossguide', 'leaf_estimation_iterations': 5, 'random_strength': 5.477274239698739, 'leaf_estimation_method': 'Gradient'}\n","\n","# xgb_params = {'max_bin': 453, 'learning_rate': 0.013229210325289916, 'max_depth': 47, 'num_boost_round': 595, 'gamma': 0.33475286711968755, 'min_child_weight': 98.24750756429152, 'subsample': 0.7311246006017413, 'colsample_bytree': 0.9012989030426084, 'colsample_bylevel': 0.7231130661378029, 'colsample_bynode': 0.648159773968677, 'reg_alpha': 0.06132137087526989, 'reg_lambda': 3.0400659248344227e-06, 'max_cat_threshold': 6, 'grow_policy': 'depthwise'}\n","\n","# xgblinear_params = {'booster' : \"gbtree\", 'max_bin': 480, 'learning_rate': 0.1138017877924544, 'max_depth': 41, 'num_boost_round': 973, 'gamma': 4.293240786960842, 'min_child_weight': 0.6644929659535678, 'subsample': 0.7278340503730034, 'colsample_bytree': 0.8692112914095523, 'colsample_bylevel': 0.9854135964777248, 'colsample_bynode': 0.9909843523663984, 'reg_alpha': 0.07408634592366764, 'reg_lambda': 0.007120526354190246, 'max_cat_threshold': 658, 'grow_policy': 'lossguide'}\n","\n","# knn_params = {'smooth': 1760.0224185369043, 'weights': 'distance', 'n_neighbors': 989, 'min_max_scaling': False}\n","\n","# lgb_model = LGBMModel(stopping_rounds=20,\n","#                         **lgb_params)\n","# lgbrf_model = LGBMModel(stopping_rounds=20,\n","#                         **lgbrf_params)\n","# lgbxt_model = LGBMModel(stopping_rounds=20,\n","#                         **lgbxt_params)\n","# cat_model = CatBoostModel(stopping_rounds=20,\n","#                         **cat_params)\n","# xgb_model = XGBoostModel(stopping_rounds=10,\n","#                         **xgb_params)\n","# xgblinear_model = XGBoostModel(stopping_rounds=10,\n","#                         **xgblinear_params)\n","# knn_model = KNNModel([col_name for col_name in new_df.columns if new_df[col_name].dtype == 'category'],\n","#                 **knn_params\n","#                 )\n","\n","lgb_params = {'early_stopping_rounds': 71, 'num_leaves': 427, 'max_depth': 6, 'learning_rate': 0.011102396619119378, 'num_boost_round': 580, 'subsample': 0.911100876838778, 'colsample_bytree': 0.7010108753681068, 'reg_alpha': 2.811645436859309e-06, 'reg_lambda': 2.286027333037273e-05, 'min_data_in_leaf': 78, 'feature_fraction': 0.7159446581182234, 'bagging_fraction': 0.5211025183767474, 'bagging_freq': 1, 'min_child_weight': 0.0020610251574775243, 'cat_smooth': 99.99511889193307}\n","lgb_model = LGBMModel(**lgb_params)\n","\n","cat_params = {'early_stopping_rounds': 23, 'max_bin': 247, 'learning_rate': 0.0850191083887714, 'depth': 8, 'iterations': 963, 'bagging_temperature': 72.31045224497224, 'subsample': 0.7572201482549041, 'colsample_bylevel': 0.9834646446717988, 'min_data_in_leaf': 168.72764807669975, 'l2_leaf_reg': 5.336908669437448, 'grow_policy': 'SymmetricTree', 'leaf_estimation_iterations': 3, 'random_strength': 3.3383149768988236, 'leaf_estimation_method': 'Newton'}\n","cat_model = CatBoostModel(**cat_params)\n","\n","xgb_params = {'early_stopping_rounds': 8, 'max_bin': 149, 'learning_rate': 0.013953743782599707, 'max_depth': 35, 'num_boost_round': 873, 'gamma': 2.6952508860883504, 'min_child_weight': 87.81545615100626, 'subsample': 0.810622785046154, 'colsample_bytree': 0.5376291735243263, 'colsample_bylevel': 0.6492000220599348, 'colsample_bynode': 0.5612689485326161, 'reg_alpha': 0.2277234511369887, 'reg_lambda': 1.6010913241456725e-05, 'max_cat_threshold': 10, 'grow_policy': 'lossguide'}\n","#{'early_stopping_rounds': 41, 'max_bin': 402, 'learning_rate': 0.02609752135980675, 'max_depth': 11, 'num_boost_round': 763, 'gamma': 8.06834739267264, 'min_child_weight': 93.65164840715298, 'subsample': 0.7063088384557132, 'colsample_bytree': 0.6860090428963916, 'colsample_bylevel': 0.8882064803709984, 'colsample_bynode': 0.6704017701265089, 'reg_alpha': 3.275678567945111, 'reg_lambda': 1.0206791961172381, 'max_cat_threshold': 13, 'grow_policy': 'depthwise'}\n","xgb_model = XGBoostModel(**xgb_params)\n","\n","xgblinear_params = {'booster' : 'gblinear', 'early_stopping_rounds': 44, 'max_bin': 42, 'learning_rate': 0.29989740620655875, 'max_depth': 30, 'num_boost_round': 999, 'gamma': 0.846346393753229, 'min_child_weight': 2.193261578959557, 'subsample': 0.7106017628092185, 'colsample_bytree': 0.9183263649918635, 'colsample_bylevel': 0.638109723519647, 'colsample_bynode': 0.8565483038886685, 'reg_alpha': 0.0025476453126042366, 'reg_lambda': 0.0186139740581913, 'max_cat_threshold': 17, 'grow_policy': 'lossguide'}\n","xgblinear_model = XGBoostModel(**xgblinear_params)\n","\n","knn_params = {'smooth': 9882.90118748393, 'weights': 'distance', 'n_neighbors': 799, 'min_max_scaling': False}#{'smooth': 8546.481717439361, 'weights': 'distance', 'n_neighbors': 787, 'min_max_scaling': False}\n","knn_model = KNNModel([col_name for col_name in new_df.columns if new_df[col_name].dtype == 'category'],\n","                **knn_params\n","                )\n","\n","hgb_params = {'max_bins': 254, 'learning_rate': 0.020481174471855185, 'max_depth': 11, 'max_leaf_nodes': 12, 'min_samples_leaf': 328, 'num_boost_round': 381, 'validation_fraction': 0.07730978759573132, 'early_stopping_rounds': 142, 'l2_regularization': 1.7032925441573725e-05, 'max_features': 0.5758526025396319, 'interaction_cst': 'pairwise', 'tol': 0.0002260304766721017, 'smooth': 176.52971404633328}\n","hgb_model = HGBModel(**hgb_params)\n","\n","model_list = [xgblinear_model, lgb_model, cat_model, knn_model, hgb_model]\n","model_names = ['xgblinear', 'lgb', 'cat', 'knn', 'hgb']\n","kf = KFold(n_splits=5, shuffle=True, random_state=42)\n","\n","model_features = {'xgblinear' : None,\n","                  'lgb' : ['brand', 'model_year', 'milage', 'fuel_type', 'transmission', 'ext_col', 'int_col', 'clean_title', 'Trim', 'horsepower', 'liters', 'cylinders', 'brand_clean_title', 'brand_fuel_type', 'transmission_accident', 'expensive_int_col', 'MAE_feature', 'without_outlier_feature'],\n","                  'cat' : None,\n","                  'xgb' : ['model_year', 'milage', 'fuel_type', 'int_col', 'accident', 'clean_title', 'Trim', 'horsepower', 'liters', 'cylinders', 'brand_clean_title', 'brand_accident', 'brand_fuel_type', 'expensive_int_col', 'MAE_feature', 'without_outlier_feature', 'MSE_feature'],\n","                  'knn' : None,\n","                  'hgb' : ['model_year', 'milage', 'fuel_type', 'engine', 'transmission', 'clean_title', 'Series', 'Trim', 'liters', 'cylinders', 'brand_accident', 'brand_fuel_type', 'transmission_accident', 'expensive_int_col', 'MAE_feature', 'without_outlier_feature']}\n","\n","hcobj = CreateHillClimber(new_df.loc['train'],\n","                  new_df.loc['test'],\n","                  model_list,\n","                  model_names,\n","                  model_features,\n","                  root_mean_squared_error,\n","                  target_col_name='price',\n","                  kfold=kf\n","                  )"]},{"cell_type":"code","execution_count":74,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["####################################################################################################\n","OOF prediction score :  72551.02829108576\n","Mean 5-cv results : 72481.06786891664 +- 3185.5748879061334\n","####################################################################################################\n","####################################################################################################\n","OOF prediction score :  72470.95245547841\n","Mean 5-cv results : 72400.80059164886 +- 3188.170941203483\n","####################################################################################################\n","####################################################################################################\n","OOF prediction score :  72504.83670221934\n","Mean 5-cv results : 72438.40147867962 +- 3103.3165881965833\n","####################################################################################################\n","####################################################################################################\n","OOF prediction score :  72610.67614864954\n","Mean 5-cv results : 72540.50569840104 +- 3191.6611339188257\n","####################################################################################################\n","####################################################################################################\n","OOF prediction score :  72494.35635677235\n","Mean 5-cv results : 72423.80412776228 +- 3197.7609753500064\n","####################################################################################################\n"]}],"source":["best_test = hcobj.fit()"]},{"cell_type":"code","execution_count":102,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>xgblinear</th>\n","      <th>lgb</th>\n","      <th>cat</th>\n","      <th>knn</th>\n","      <th>hgb</th>\n","      <th>ag-small</th>\n","      <th>ag-mae</th>\n","      <th>ag-medae</th>\n","      <th>ag-r2</th>\n","      <th>xgb</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>7791.857422</td>\n","      <td>9301.578329</td>\n","      <td>12900.960721</td>\n","      <td>10416.035920</td>\n","      <td>9176.209184</td>\n","      <td>10342.567</td>\n","      <td>10458.298</td>\n","      <td>9348.849</td>\n","      <td>9177.172</td>\n","      <td>9844.610352</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>10493.219727</td>\n","      <td>10062.900269</td>\n","      <td>11873.642439</td>\n","      <td>9681.199646</td>\n","      <td>8963.655699</td>\n","      <td>11722.479</td>\n","      <td>11197.558</td>\n","      <td>9865.589</td>\n","      <td>11193.502</td>\n","      <td>10649.995117</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>11503.007812</td>\n","      <td>12492.703551</td>\n","      <td>13302.887472</td>\n","      <td>10570.905999</td>\n","      <td>11263.642779</td>\n","      <td>12761.601</td>\n","      <td>12845.660</td>\n","      <td>13280.038</td>\n","      <td>13912.339</td>\n","      <td>11737.752930</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>59680.839844</td>\n","      <td>61579.783946</td>\n","      <td>61727.945246</td>\n","      <td>57429.947809</td>\n","      <td>62231.307210</td>\n","      <td>58276.830</td>\n","      <td>60250.570</td>\n","      <td>63282.080</td>\n","      <td>60561.457</td>\n","      <td>58572.082031</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>82862.914062</td>\n","      <td>87924.894214</td>\n","      <td>79915.093247</td>\n","      <td>78864.711878</td>\n","      <td>79457.859979</td>\n","      <td>80555.330</td>\n","      <td>77991.730</td>\n","      <td>74312.980</td>\n","      <td>79113.060</td>\n","      <td>95151.718750</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>192537</th>\n","      <td>230032.375000</td>\n","      <td>259339.669795</td>\n","      <td>222042.273819</td>\n","      <td>208123.580546</td>\n","      <td>227721.631359</td>\n","      <td>228297.640</td>\n","      <td>220334.200</td>\n","      <td>352655.120</td>\n","      <td>225614.520</td>\n","      <td>228661.812500</td>\n","    </tr>\n","    <tr>\n","      <th>192538</th>\n","      <td>68068.546875</td>\n","      <td>70393.622853</td>\n","      <td>64568.022479</td>\n","      <td>67616.907444</td>\n","      <td>67519.280853</td>\n","      <td>70987.530</td>\n","      <td>70757.880</td>\n","      <td>67069.880</td>\n","      <td>69367.290</td>\n","      <td>75833.218750</td>\n","    </tr>\n","    <tr>\n","      <th>192539</th>\n","      <td>98430.218750</td>\n","      <td>95862.287244</td>\n","      <td>90779.444986</td>\n","      <td>103080.155971</td>\n","      <td>95445.232947</td>\n","      <td>97806.040</td>\n","      <td>99846.450</td>\n","      <td>85284.570</td>\n","      <td>97009.560</td>\n","      <td>91634.523438</td>\n","    </tr>\n","    <tr>\n","      <th>192540</th>\n","      <td>67614.664062</td>\n","      <td>62903.473370</td>\n","      <td>66931.690126</td>\n","      <td>63561.634696</td>\n","      <td>64637.186556</td>\n","      <td>63428.140</td>\n","      <td>63703.750</td>\n","      <td>60619.625</td>\n","      <td>60981.164</td>\n","      <td>63584.605469</td>\n","    </tr>\n","    <tr>\n","      <th>192541</th>\n","      <td>37985.113281</td>\n","      <td>37904.313119</td>\n","      <td>37073.189076</td>\n","      <td>36885.481307</td>\n","      <td>37563.579313</td>\n","      <td>38235.637</td>\n","      <td>38646.992</td>\n","      <td>36878.434</td>\n","      <td>38461.594</td>\n","      <td>38879.136719</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>192542 rows × 10 columns</p>\n","</div>"],"text/plain":["            xgblinear            lgb            cat            knn  \\\n","0         7791.857422    9301.578329   12900.960721   10416.035920   \n","1        10493.219727   10062.900269   11873.642439    9681.199646   \n","2        11503.007812   12492.703551   13302.887472   10570.905999   \n","3        59680.839844   61579.783946   61727.945246   57429.947809   \n","4        82862.914062   87924.894214   79915.093247   78864.711878   \n","...               ...            ...            ...            ...   \n","192537  230032.375000  259339.669795  222042.273819  208123.580546   \n","192538   68068.546875   70393.622853   64568.022479   67616.907444   \n","192539   98430.218750   95862.287244   90779.444986  103080.155971   \n","192540   67614.664062   62903.473370   66931.690126   63561.634696   \n","192541   37985.113281   37904.313119   37073.189076   36885.481307   \n","\n","                  hgb    ag-small      ag-mae    ag-medae       ag-r2  \\\n","0         9176.209184   10342.567   10458.298    9348.849    9177.172   \n","1         8963.655699   11722.479   11197.558    9865.589   11193.502   \n","2        11263.642779   12761.601   12845.660   13280.038   13912.339   \n","3        62231.307210   58276.830   60250.570   63282.080   60561.457   \n","4        79457.859979   80555.330   77991.730   74312.980   79113.060   \n","...               ...         ...         ...         ...         ...   \n","192537  227721.631359  228297.640  220334.200  352655.120  225614.520   \n","192538   67519.280853   70987.530   70757.880   67069.880   69367.290   \n","192539   95445.232947   97806.040   99846.450   85284.570   97009.560   \n","192540   64637.186556   63428.140   63703.750   60619.625   60981.164   \n","192541   37563.579313   38235.637   38646.992   36878.434   38461.594   \n","\n","                  xgb  \n","0         9844.610352  \n","1        10649.995117  \n","2        11737.752930  \n","3        58572.082031  \n","4        95151.718750  \n","...               ...  \n","192537  228661.812500  \n","192538   75833.218750  \n","192539   91634.523438  \n","192540   63584.605469  \n","192541   38879.136719  \n","\n","[192542 rows x 10 columns]"]},"execution_count":102,"metadata":{},"output_type":"execute_result"}],"source":["best_test.train_oof_pred"]},{"cell_type":"code","execution_count":304,"metadata":{},"outputs":[],"source":["additional_predictions = {\"ag-small\" : (\"/Users/yuwei-1/Documents/projects/Kaggle-tools/ktools/modelling/Data/used_cars/oof_pred_ag_small.csv\",\n","                                    \"/Users/yuwei-1/Documents/projects/Kaggle-tools/ktools/modelling/Data/used_cars/test_pred_ag_small.csv\"),\n","                        # \"ag-large\" : (\"/Users/yuwei-1/Documents/projects/Kaggle-tools/ktools/modelling/Data/used_cars/oof_pred_ag_large.csv\",\n","                        #             \"/Users/yuwei-1/Documents/projects/Kaggle-tools/ktools/modelling/Data/used_cars/test_pred_ag_large.csv\")\n","                          \"ag-mae\" : (\"/Users/yuwei-1/Documents/projects/Kaggle-tools/ktools/modelling/Data/used_cars/oof_pred_mae.csv\",\n","                                      \"/Users/yuwei-1/Documents/projects/Kaggle-tools/ktools/modelling/Data/used_cars/submission_mae.csv\"),\n","                          \"ag-medae\" : (\"/Users/yuwei-1/Documents/projects/Kaggle-tools/ktools/modelling/Data/used_cars/oof_pred_medae.csv\",\n","                                        \"/Users/yuwei-1/Documents/projects/Kaggle-tools/ktools/modelling/Data/used_cars/submission_medae.csv\"),\n","                          \"ag-r2\" : (\"/Users/yuwei-1/Documents/projects/Kaggle-tools/ktools/modelling/Data/used_cars/oof_pred_r2.csv\",\n","                                     \"/Users/yuwei-1/Documents/projects/Kaggle-tools/ktools/modelling/Data/used_cars/submission_r2.csv\"),\n","                          # \"ag-all\" : (\"/Users/yuwei-1/Documents/projects/Kaggle-tools/ktools/modelling/Data/used_cars/oof_pred_ag_large_all.csv\",\n","                          #             \"/Users/yuwei-1/Documents/projects/Kaggle-tools/ktools/modelling/Data/used_cars/test_pred_ag_large_all.csv\"),\n","                          \"xgb\" : (\"/Users/yuwei-1/Documents/projects/Kaggle-tools/ktools/modelling/Data/used_cars/train_oof_xgb.csv\",\n","                                   \"/Users/yuwei-1/Documents/projects/Kaggle-tools/ktools/modelling/Data/used_cars/test_pred_xgb.csv\"),\n","                          # \"laml\" : (\"/Users/yuwei-1/Documents/projects/Kaggle-tools/ktools/modelling/Data/used_cars/oof_pred_lightautoml.csv\",\n","                          #           \"/Users/yuwei-1/Documents/projects/Kaggle-tools/ktools/modelling/Data/used_cars/test_pred_lightautoml.csv\"),\n","                          \"laml_lgbmonly\" : (\"/Users/yuwei-1/Documents/projects/Kaggle-tools/ktools/modelling/Data/used_cars/lightautoml_lgb_oof_pred.csv\",\n","                                             \"/Users/yuwei-1/Documents/projects/Kaggle-tools/ktools/modelling/Data/used_cars/test_lgb_pred_lightautoml.csv\"),\n","                          # \"laml_lgb_cb\" : (\"/Users/yuwei-1/Documents/projects/Kaggle-tools/ktools/modelling/Data/used_cars/lightautoml_oof_pred_lgbcb.csv\",\n","                          #                  \"/Users/yuwei-1/Documents/projects/Kaggle-tools/ktools/modelling/Data/used_cars/test_pred_lightautoml_lgbcb.csv\"),\n","                          \"laml_lgb_cb_tuned\" : (\"/Users/yuwei-1/Documents/projects/Kaggle-tools/ktools/modelling/Data/used_cars/lightautoml_lgbcbtuned_oof_pred.csv\",\n","                                                 \"/Users/yuwei-1/Documents/projects/Kaggle-tools/ktools/modelling/Data/used_cars/test_lgbcbtuned_pred_lightautoml.csv\"),\n","                          \"laml_catonly\" : (\"/Users/yuwei-1/Documents/projects/Kaggle-tools/ktools/modelling/Data/used_cars/lightautoml_cat_oof_pred.csv\",\n","                                            \"/Users/yuwei-1/Documents/projects/Kaggle-tools/ktools/modelling/Data/used_cars/test_cat_pred_lightautoml.csv\"),\n","                          \"laml_nn_feats\" : (\"/Users/yuwei-1/Documents/projects/Kaggle-tools/ktools/modelling/Data/used_cars/lightautoml_nn_oof_pred.csv\",\n","                                        \"/Users/yuwei-1/Documents/projects/Kaggle-tools/ktools/modelling/Data/used_cars/test_nn_pred_lightautoml.csv\"),\n","                          \"ag-serkanpolat\" : (\"/Users/yuwei-1/Documents/projects/Kaggle-tools/ktools/modelling/Data/used_cars/serkan_polat_oof.csv\",\n","                                              \"/Users/yuwei-1/Documents/projects/Kaggle-tools/ktools/modelling/Data/used_cars/serkan_polat_test_pred.csv\")\n","                        }\n","\n","best_test.load_saved_prediction_files(additional_predictions)"]},{"cell_type":"code","execution_count":305,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>xgblinear</th>\n","      <th>lgb</th>\n","      <th>cat</th>\n","      <th>knn</th>\n","      <th>hgb</th>\n","      <th>ag-small</th>\n","      <th>ag-mae</th>\n","      <th>ag-medae</th>\n","      <th>ag-r2</th>\n","      <th>xgb</th>\n","      <th>laml_catonly</th>\n","      <th>laml_lgb_cb_tuned</th>\n","      <th>laml_lgbmonly</th>\n","      <th>laml_nn_feats</th>\n","      <th>ag-serkanpolat</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>7791.857422</td>\n","      <td>9301.578329</td>\n","      <td>12900.960721</td>\n","      <td>10416.035920</td>\n","      <td>9176.209184</td>\n","      <td>10342.567</td>\n","      <td>10458.298</td>\n","      <td>9348.849</td>\n","      <td>9177.172</td>\n","      <td>9844.610352</td>\n","      <td>16403.156</td>\n","      <td>12540.258</td>\n","      <td>13245.170</td>\n","      <td>17084.3000</td>\n","      <td>9103.4800</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>10493.219727</td>\n","      <td>10062.900269</td>\n","      <td>11873.642439</td>\n","      <td>9681.199646</td>\n","      <td>8963.655699</td>\n","      <td>11722.479</td>\n","      <td>11197.558</td>\n","      <td>9865.589</td>\n","      <td>11193.502</td>\n","      <td>10649.995117</td>\n","      <td>13078.133</td>\n","      <td>14338.642</td>\n","      <td>15150.690</td>\n","      <td>13471.2170</td>\n","      <td>11324.3545</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>11503.007812</td>\n","      <td>12492.703551</td>\n","      <td>13302.887472</td>\n","      <td>10570.905999</td>\n","      <td>11263.642779</td>\n","      <td>12761.601</td>\n","      <td>12845.660</td>\n","      <td>13280.038</td>\n","      <td>13912.339</td>\n","      <td>11737.752930</td>\n","      <td>11352.797</td>\n","      <td>11461.303</td>\n","      <td>11707.585</td>\n","      <td>11870.8955</td>\n","      <td>13360.0660</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>59680.839844</td>\n","      <td>61579.783946</td>\n","      <td>61727.945246</td>\n","      <td>57429.947809</td>\n","      <td>62231.307210</td>\n","      <td>58276.830</td>\n","      <td>60250.570</td>\n","      <td>63282.080</td>\n","      <td>60561.457</td>\n","      <td>58572.082031</td>\n","      <td>63380.370</td>\n","      <td>60433.984</td>\n","      <td>58404.375</td>\n","      <td>61170.4380</td>\n","      <td>62141.0200</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>82862.914062</td>\n","      <td>87924.894214</td>\n","      <td>79915.093247</td>\n","      <td>78864.711878</td>\n","      <td>79457.859979</td>\n","      <td>80555.330</td>\n","      <td>77991.730</td>\n","      <td>74312.980</td>\n","      <td>79113.060</td>\n","      <td>95151.718750</td>\n","      <td>74765.914</td>\n","      <td>76848.240</td>\n","      <td>75356.500</td>\n","      <td>73209.9700</td>\n","      <td>84517.0800</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>192537</th>\n","      <td>230032.375000</td>\n","      <td>259339.669795</td>\n","      <td>222042.273819</td>\n","      <td>208123.580546</td>\n","      <td>227721.631359</td>\n","      <td>228297.640</td>\n","      <td>220334.200</td>\n","      <td>352655.120</td>\n","      <td>225614.520</td>\n","      <td>228661.812500</td>\n","      <td>210993.480</td>\n","      <td>228126.470</td>\n","      <td>244026.550</td>\n","      <td>221102.5600</td>\n","      <td>224295.9400</td>\n","    </tr>\n","    <tr>\n","      <th>192538</th>\n","      <td>68068.546875</td>\n","      <td>70393.622853</td>\n","      <td>64568.022479</td>\n","      <td>67616.907444</td>\n","      <td>67519.280853</td>\n","      <td>70987.530</td>\n","      <td>70757.880</td>\n","      <td>67069.880</td>\n","      <td>69367.290</td>\n","      <td>75833.218750</td>\n","      <td>71071.336</td>\n","      <td>69778.586</td>\n","      <td>69254.414</td>\n","      <td>70156.3400</td>\n","      <td>68766.1400</td>\n","    </tr>\n","    <tr>\n","      <th>192539</th>\n","      <td>98430.218750</td>\n","      <td>95862.287244</td>\n","      <td>90779.444986</td>\n","      <td>103080.155971</td>\n","      <td>95445.232947</td>\n","      <td>97806.040</td>\n","      <td>99846.450</td>\n","      <td>85284.570</td>\n","      <td>97009.560</td>\n","      <td>91634.523438</td>\n","      <td>115406.330</td>\n","      <td>112416.410</td>\n","      <td>112976.970</td>\n","      <td>108147.0100</td>\n","      <td>97416.1400</td>\n","    </tr>\n","    <tr>\n","      <th>192540</th>\n","      <td>67614.664062</td>\n","      <td>62903.473370</td>\n","      <td>66931.690126</td>\n","      <td>63561.634696</td>\n","      <td>64637.186556</td>\n","      <td>63428.140</td>\n","      <td>63703.750</td>\n","      <td>60619.625</td>\n","      <td>60981.164</td>\n","      <td>63584.605469</td>\n","      <td>65879.640</td>\n","      <td>66154.710</td>\n","      <td>65352.695</td>\n","      <td>66512.8400</td>\n","      <td>62253.3900</td>\n","    </tr>\n","    <tr>\n","      <th>192541</th>\n","      <td>37985.113281</td>\n","      <td>37904.313119</td>\n","      <td>37073.189076</td>\n","      <td>36885.481307</td>\n","      <td>37563.579313</td>\n","      <td>38235.637</td>\n","      <td>38646.992</td>\n","      <td>36878.434</td>\n","      <td>38461.594</td>\n","      <td>38879.136719</td>\n","      <td>39219.420</td>\n","      <td>38449.664</td>\n","      <td>37900.617</td>\n","      <td>38118.6640</td>\n","      <td>37450.9730</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>192542 rows × 15 columns</p>\n","</div>"],"text/plain":["            xgblinear            lgb            cat            knn  \\\n","0         7791.857422    9301.578329   12900.960721   10416.035920   \n","1        10493.219727   10062.900269   11873.642439    9681.199646   \n","2        11503.007812   12492.703551   13302.887472   10570.905999   \n","3        59680.839844   61579.783946   61727.945246   57429.947809   \n","4        82862.914062   87924.894214   79915.093247   78864.711878   \n","...               ...            ...            ...            ...   \n","192537  230032.375000  259339.669795  222042.273819  208123.580546   \n","192538   68068.546875   70393.622853   64568.022479   67616.907444   \n","192539   98430.218750   95862.287244   90779.444986  103080.155971   \n","192540   67614.664062   62903.473370   66931.690126   63561.634696   \n","192541   37985.113281   37904.313119   37073.189076   36885.481307   \n","\n","                  hgb    ag-small      ag-mae    ag-medae       ag-r2  \\\n","0         9176.209184   10342.567   10458.298    9348.849    9177.172   \n","1         8963.655699   11722.479   11197.558    9865.589   11193.502   \n","2        11263.642779   12761.601   12845.660   13280.038   13912.339   \n","3        62231.307210   58276.830   60250.570   63282.080   60561.457   \n","4        79457.859979   80555.330   77991.730   74312.980   79113.060   \n","...               ...         ...         ...         ...         ...   \n","192537  227721.631359  228297.640  220334.200  352655.120  225614.520   \n","192538   67519.280853   70987.530   70757.880   67069.880   69367.290   \n","192539   95445.232947   97806.040   99846.450   85284.570   97009.560   \n","192540   64637.186556   63428.140   63703.750   60619.625   60981.164   \n","192541   37563.579313   38235.637   38646.992   36878.434   38461.594   \n","\n","                  xgb  laml_catonly  laml_lgb_cb_tuned  laml_lgbmonly  \\\n","0         9844.610352     16403.156          12540.258      13245.170   \n","1        10649.995117     13078.133          14338.642      15150.690   \n","2        11737.752930     11352.797          11461.303      11707.585   \n","3        58572.082031     63380.370          60433.984      58404.375   \n","4        95151.718750     74765.914          76848.240      75356.500   \n","...               ...           ...                ...            ...   \n","192537  228661.812500    210993.480         228126.470     244026.550   \n","192538   75833.218750     71071.336          69778.586      69254.414   \n","192539   91634.523438    115406.330         112416.410     112976.970   \n","192540   63584.605469     65879.640          66154.710      65352.695   \n","192541   38879.136719     39219.420          38449.664      37900.617   \n","\n","        laml_nn_feats  ag-serkanpolat  \n","0          17084.3000       9103.4800  \n","1          13471.2170      11324.3545  \n","2          11870.8955      13360.0660  \n","3          61170.4380      62141.0200  \n","4          73209.9700      84517.0800  \n","...               ...             ...  \n","192537    221102.5600     224295.9400  \n","192538     70156.3400      68766.1400  \n","192539    108147.0100      97416.1400  \n","192540     66512.8400      62253.3900  \n","192541     38118.6640      37450.9730  \n","\n","[192542 rows x 15 columns]"]},"execution_count":305,"metadata":{},"output_type":"execute_result"}],"source":["# best_test.train_oof_pred = pd.concat([best_test.train_oof_pred, pd.read_csv(\"/Users/yuwei-1/Documents/projects/Kaggle-tools/ktools/modelling/Data/used_cars/OOF_LightAutoMLTestersModels.csv\", index_col=0)['BLEND']], axis=1)\n","# best_test.train_oof_pred = best_test.train_oof_pred.dropna()\n","# best_test.train_oof_pred.drop(columns=['laml'], inplace=True)\n","best_test.train_oof_pred = best_test.train_oof_pred.loc[:,~best_test.train_oof_pred.columns.duplicated()].copy()\n","best_test.train_oof_pred"]},{"cell_type":"code","execution_count":306,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>xgblinear</th>\n","      <th>lgb</th>\n","      <th>cat</th>\n","      <th>knn</th>\n","      <th>hgb</th>\n","      <th>ag-small</th>\n","      <th>ag-mae</th>\n","      <th>ag-medae</th>\n","      <th>ag-r2</th>\n","      <th>xgb</th>\n","      <th>laml_catonly</th>\n","      <th>laml_lgb_cb_tuned</th>\n","      <th>laml_lgbmonly</th>\n","      <th>laml_nn_feats</th>\n","      <th>ag-serkanpolat</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>188533</th>\n","      <td>17311.228516</td>\n","      <td>18779.773692</td>\n","      <td>18967.814599</td>\n","      <td>19771.104609</td>\n","      <td>19032.174313</td>\n","      <td>19343.6070</td>\n","      <td>19219.730</td>\n","      <td>18763.650</td>\n","      <td>19442.900</td>\n","      <td>17913.550049</td>\n","      <td>19092.697</td>\n","      <td>18278.941</td>\n","      <td>18998.316</td>\n","      <td>18981.760</td>\n","      <td>19382.050</td>\n","    </tr>\n","    <tr>\n","      <th>188534</th>\n","      <td>74507.042969</td>\n","      <td>74195.440716</td>\n","      <td>74314.391573</td>\n","      <td>75728.141722</td>\n","      <td>73754.588065</td>\n","      <td>77652.8200</td>\n","      <td>74289.700</td>\n","      <td>80107.360</td>\n","      <td>74688.266</td>\n","      <td>81477.774414</td>\n","      <td>76175.020</td>\n","      <td>77180.840</td>\n","      <td>76242.100</td>\n","      <td>75921.750</td>\n","      <td>75614.820</td>\n","    </tr>\n","    <tr>\n","      <th>188535</th>\n","      <td>61661.458008</td>\n","      <td>59382.773219</td>\n","      <td>60935.759494</td>\n","      <td>57026.678486</td>\n","      <td>58838.155506</td>\n","      <td>58982.0550</td>\n","      <td>59302.730</td>\n","      <td>56502.414</td>\n","      <td>58766.220</td>\n","      <td>56430.732422</td>\n","      <td>57041.520</td>\n","      <td>57490.766</td>\n","      <td>57569.348</td>\n","      <td>56954.203</td>\n","      <td>58655.223</td>\n","    </tr>\n","    <tr>\n","      <th>188536</th>\n","      <td>23579.476562</td>\n","      <td>27096.058210</td>\n","      <td>28791.942974</td>\n","      <td>29145.186469</td>\n","      <td>26347.035218</td>\n","      <td>30070.9550</td>\n","      <td>30788.043</td>\n","      <td>27360.117</td>\n","      <td>29931.508</td>\n","      <td>27002.433594</td>\n","      <td>30448.707</td>\n","      <td>30660.596</td>\n","      <td>29996.790</td>\n","      <td>29893.342</td>\n","      <td>29737.607</td>\n","    </tr>\n","    <tr>\n","      <th>188537</th>\n","      <td>29453.227051</td>\n","      <td>29866.435298</td>\n","      <td>30348.902244</td>\n","      <td>29578.183407</td>\n","      <td>29543.909420</td>\n","      <td>31455.8770</td>\n","      <td>31552.445</td>\n","      <td>30988.547</td>\n","      <td>31781.781</td>\n","      <td>29717.227539</td>\n","      <td>30386.824</td>\n","      <td>30643.406</td>\n","      <td>30786.209</td>\n","      <td>30523.236</td>\n","      <td>31283.656</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>314218</th>\n","      <td>26675.092773</td>\n","      <td>26493.786508</td>\n","      <td>26399.991547</td>\n","      <td>25567.268378</td>\n","      <td>27673.563213</td>\n","      <td>27062.9650</td>\n","      <td>27426.390</td>\n","      <td>27823.740</td>\n","      <td>27656.715</td>\n","      <td>26225.318848</td>\n","      <td>28120.336</td>\n","      <td>28374.504</td>\n","      <td>27910.977</td>\n","      <td>29353.402</td>\n","      <td>27471.865</td>\n","    </tr>\n","    <tr>\n","      <th>314219</th>\n","      <td>50213.050781</td>\n","      <td>48027.577375</td>\n","      <td>49216.172903</td>\n","      <td>47445.388038</td>\n","      <td>48110.006392</td>\n","      <td>54203.1680</td>\n","      <td>52154.210</td>\n","      <td>48417.324</td>\n","      <td>53495.055</td>\n","      <td>49367.322266</td>\n","      <td>49414.367</td>\n","      <td>50381.523</td>\n","      <td>48643.580</td>\n","      <td>49904.330</td>\n","      <td>54557.582</td>\n","    </tr>\n","    <tr>\n","      <th>314220</th>\n","      <td>18222.807373</td>\n","      <td>20110.130845</td>\n","      <td>18917.172384</td>\n","      <td>19693.657082</td>\n","      <td>20437.950962</td>\n","      <td>19474.0860</td>\n","      <td>19164.746</td>\n","      <td>18299.508</td>\n","      <td>19224.037</td>\n","      <td>19731.197021</td>\n","      <td>19272.940</td>\n","      <td>19490.973</td>\n","      <td>19316.730</td>\n","      <td>20229.342</td>\n","      <td>18491.738</td>\n","    </tr>\n","    <tr>\n","      <th>314221</th>\n","      <td>13036.375000</td>\n","      <td>16457.965651</td>\n","      <td>16859.260079</td>\n","      <td>15315.434220</td>\n","      <td>16150.665946</td>\n","      <td>16117.7705</td>\n","      <td>16422.330</td>\n","      <td>16211.982</td>\n","      <td>16250.578</td>\n","      <td>16575.199219</td>\n","      <td>16360.864</td>\n","      <td>16322.670</td>\n","      <td>17216.360</td>\n","      <td>16647.824</td>\n","      <td>16132.244</td>\n","    </tr>\n","    <tr>\n","      <th>314222</th>\n","      <td>42500.701172</td>\n","      <td>39319.411345</td>\n","      <td>39681.477051</td>\n","      <td>38974.634723</td>\n","      <td>38986.234800</td>\n","      <td>41327.5660</td>\n","      <td>42615.445</td>\n","      <td>43711.758</td>\n","      <td>42957.695</td>\n","      <td>38798.145508</td>\n","      <td>36255.570</td>\n","      <td>37254.234</td>\n","      <td>39659.848</td>\n","      <td>37465.500</td>\n","      <td>40578.977</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>125690 rows × 15 columns</p>\n","</div>"],"text/plain":["           xgblinear           lgb           cat           knn           hgb  \\\n","188533  17311.228516  18779.773692  18967.814599  19771.104609  19032.174313   \n","188534  74507.042969  74195.440716  74314.391573  75728.141722  73754.588065   \n","188535  61661.458008  59382.773219  60935.759494  57026.678486  58838.155506   \n","188536  23579.476562  27096.058210  28791.942974  29145.186469  26347.035218   \n","188537  29453.227051  29866.435298  30348.902244  29578.183407  29543.909420   \n","...              ...           ...           ...           ...           ...   \n","314218  26675.092773  26493.786508  26399.991547  25567.268378  27673.563213   \n","314219  50213.050781  48027.577375  49216.172903  47445.388038  48110.006392   \n","314220  18222.807373  20110.130845  18917.172384  19693.657082  20437.950962   \n","314221  13036.375000  16457.965651  16859.260079  15315.434220  16150.665946   \n","314222  42500.701172  39319.411345  39681.477051  38974.634723  38986.234800   \n","\n","          ag-small     ag-mae   ag-medae      ag-r2           xgb  \\\n","188533  19343.6070  19219.730  18763.650  19442.900  17913.550049   \n","188534  77652.8200  74289.700  80107.360  74688.266  81477.774414   \n","188535  58982.0550  59302.730  56502.414  58766.220  56430.732422   \n","188536  30070.9550  30788.043  27360.117  29931.508  27002.433594   \n","188537  31455.8770  31552.445  30988.547  31781.781  29717.227539   \n","...            ...        ...        ...        ...           ...   \n","314218  27062.9650  27426.390  27823.740  27656.715  26225.318848   \n","314219  54203.1680  52154.210  48417.324  53495.055  49367.322266   \n","314220  19474.0860  19164.746  18299.508  19224.037  19731.197021   \n","314221  16117.7705  16422.330  16211.982  16250.578  16575.199219   \n","314222  41327.5660  42615.445  43711.758  42957.695  38798.145508   \n","\n","        laml_catonly  laml_lgb_cb_tuned  laml_lgbmonly  laml_nn_feats  \\\n","188533     19092.697          18278.941      18998.316      18981.760   \n","188534     76175.020          77180.840      76242.100      75921.750   \n","188535     57041.520          57490.766      57569.348      56954.203   \n","188536     30448.707          30660.596      29996.790      29893.342   \n","188537     30386.824          30643.406      30786.209      30523.236   \n","...              ...                ...            ...            ...   \n","314218     28120.336          28374.504      27910.977      29353.402   \n","314219     49414.367          50381.523      48643.580      49904.330   \n","314220     19272.940          19490.973      19316.730      20229.342   \n","314221     16360.864          16322.670      17216.360      16647.824   \n","314222     36255.570          37254.234      39659.848      37465.500   \n","\n","        ag-serkanpolat  \n","188533       19382.050  \n","188534       75614.820  \n","188535       58655.223  \n","188536       29737.607  \n","188537       31283.656  \n","...                ...  \n","314218       27471.865  \n","314219       54557.582  \n","314220       18491.738  \n","314221       16132.244  \n","314222       40578.977  \n","\n","[125690 rows x 15 columns]"]},"execution_count":306,"metadata":{},"output_type":"execute_result"}],"source":["# best_test.test_pred = pd.concat([best_test.test_pred, pd.read_csv(\"/Users/yuwei-1/Documents/projects/Kaggle-tools/ktools/modelling/Data/used_cars/PRED_LightAutoMLTestersModels.csv\", index_col=0)['BLEND']], axis=1)\n","# best_test.test_pred.drop(columns=['laml'], inplace=True)\n","best_test.test_pred = best_test.test_pred.loc[:,~best_test.test_pred.columns.duplicated()].copy()\n","# best_test.test_pred.drop(columns=['laml_catonly'], inplace=True)\n","# best_test.test_pred = best_test.test_pred.dropna()\n","best_test.test_pred"]},{"cell_type":"code","execution_count":301,"metadata":{},"outputs":[{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAaYAAAGQCAYAAADlUsSzAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA3EElEQVR4nO3dfVBUV5438G/TSsMQmgQnNnYJ2kZnxDcCMbpodgITNl0sYZLdSrLJY0pW15lxBpMAz0Rldn2ZMUrMLlFHCESdlaQmxlCTyGTFyENUpKhgFKGzMRPfVkYYA20yG2lBbLH7Pn8wXOyAQnNP04fm+6m6ZfXpe3/31/Ly45x77rk6RVEUEBERSSLI3wkQERHdioWJiIikwsJERERSYWEiIiKpsDAREZFUWJiIiEgqLExERCSVMf5OgIhotLt+/Tpu3LihOU5wcDBCQkIEZORfLExERH50/fp1WCwWtLa2ao4VFRWFxsbGEV+cWJiIiPzoxo0baG1txcWTk2EMH/rVFcdVNyY98CfcuHGDhYmIiLS7K1yHu8J1Qz7ejaEfKxsWJiIiCbgUN1waVi51KW5xyfgZZ+UREZFU2GMiIpKAGwrcGHqXScuxsmFhIiKSgBtuaBmM03a0XDiUR0REUmGPiYhIAi5FgUvDc1u1HCsbFiYiIgnwGlMvDuUREZFU2GMiIpKAGwpc7DEBYGEiIpICh/J6cSiPiIikwh4TEZEEOCuv14jtMRUWFmLy5MkICQnB/Pnzcfz4cX+n1EdeXh4efPBBhIeHY/z48XjiiSdw5swZf6c1oFdeeQU6nQ5ZWVn+TqVfly5dwnPPPYdx48YhNDQUs2fPRl1dnb/T6sPlcmHNmjWwWCwIDQ3Ffffdhw0bNkDx8y+Q6upqpKenw2w2Q6fToayszON9RVGwdu1aTJgwAaGhoUhJScG5c+eky7WrqwurVq3C7NmzERYWBrPZjMWLF+PLL7/0S65auQVsgWJEFqZ3330XOTk5WLduHerr6xEXFwer1YrLly/7OzUPR48eRWZmJo4dO4bKykp0dXXh0UcfRUdHh79Tu60TJ07gjTfewJw5c/ydSr+++eYbLFy4EGPHjsWHH36IP/7xj8jPz8c999zj79T62Lx5M4qKilBQUIAvvvgCmzdvxquvvort27f7Na+Ojg7ExcWhsLCw3/dfffVV/OY3v0FxcTE++eQThIWFwWq14vr168Oc6Z1zvXbtGurr67FmzRrU19fj/fffx5kzZ/CjH/1o2PMUwfXXyQ9atoChjEDz5s1TMjMz1dcul0sxm81KXl6eH7Ma2OXLlxUAytGjR/2dSr+uXr2qTJs2TamsrFQefvhh5cUXX/R3Sn2sWrVKeeihh/ydxqCkpaUpS5cu9Wj7x3/8R2XRokV+yqgvAMq+ffvU1263W4mKilL+/d//XW27cuWKYjAYlHfeeccPGfb6dq79OX78uAJAuXjx4vAkJUBbW5sCQPn8i/FK05+jhrx9/sV4BYDS1tbm74+k2YjrMd24cQMnT55ESkqK2hYUFISUlBTU1tb6MbOBtbW1AQAiIyP9nEn/MjMzkZaW5vF/K5sPPvgAc+fOxVNPPYXx48cjPj4eO3fu9Hda/VqwYAEOHTqEs2fPAgA+/fRT1NTUIDU11c+Z3V5jYyNaW1s9vgciIiIwf/586X++gO6fMZ1Oh7vvvtvfqXjNpWjfAsWIm/zw9ddfw+VywWQyebSbTCacPn3aT1kNzO12IysrCwsXLsSsWbP8nU4fe/fuRX19PU6cOOHvVO7owoULKCoqQk5ODn75y1/ixIkTeOGFFxAcHIyMjAx/p+dh9erVcDgcmD59OvR6PVwuFzZu3IhFixb5O7Xb6nm8d38/XyIe/e1L169fx6pVq/Dss8/CaDT6Ox2vab1OFEjXmEZcYRqpMjMzcerUKdTU1Pg7lT6am5vx4osvorKyUvpHMrvdbsydOxebNm0CAMTHx+PUqVMoLi6WrjCVlpbi7bffxp49ezBz5kzYbDZkZWXBbDZLl+tI19XVhaeffhqKoqCoqMjf6ZBGI64wffe734Ver4fdbvdot9vtiIqK8lNWd7ZixQrs378f1dXVmDhxor/T6ePkyZO4fPkyEhIS1DaXy4Xq6moUFBTA6XRCr9f7McNeEyZMwIwZMzzaYmNj8d577/kpo9t76aWXsHr1ajzzzDMAgNmzZ+PixYvIy8uTtjD1/AzZ7XZMmDBBbbfb7bj//vv9lNWd9RSlixcv4vDhwyOytwR0PxrdpeHx6IH0aPURd40pODgYDzzwAA4dOqS2ud1uHDp0CImJiX7MrC9FUbBixQrs27cPhw8fhsVi8XdK/XrkkUfw2WefwWazqdvcuXOxaNEi2Gw2aYoSACxcuLDPlPuzZ89i0qRJfsro9q5du4agIM8fMb1eD7db3kEXi8WCqKgoj58vh8OBTz75RLqfL6C3KJ07dw4fffQRxo0b5++UhsytaN8CxYjrMQFATk4OMjIyMHfuXMybNw9bt25FR0cHlixZ4u/UPGRmZmLPnj34wx/+gPDwcHWMPiIiAqGhoX7Orld4eHif615hYWEYN26cdNfDsrOzsWDBAmzatAlPP/00jh8/jh07dmDHjh3+Tq2P9PR0bNy4ETExMZg5cyYaGhrw2muvYenSpX7Nq729HefPn1dfNzY2wmazITIyEjExMcjKysLLL7+MadOmwWKxYM2aNTCbzXjiiSekynXChAl48sknUV9fj/3798Plcqk/Y5GRkQgODh72fEkQf08LHKrt27crMTExSnBwsDJv3jzl2LFj/k6pDwD9brt37/Z3agOSdbq4oijKf/3XfymzZs1SDAaDMn36dGXHjh3+TqlfDodDefHFF5WYmBglJCREmTJlivKv//qvitPp9GteR44c6ff7MiMjQ1GU7inja9asUUwmk2IwGJRHHnlEOXPmjHS5NjY23vZn7MiRI37Jdyh6pot/8nmU8nmTecjbJ59HBcx0cZ2iBNA6FkREI4zD4UBERAQ+/nwC7gof+tWV9qtuLJjZgra2thF7na3HiLvGREREgW1EXmMiIgo0bkUHt6JhVp6GY2XDwkREJAGXxuniWo6VDYfyiIhIKuwxERFJwIUguDT0FVwCc/E3FiYiIgkoGq8xKbzGREREIvEaU68RfY3J6XRi/fr1cDqd/k7ljkZKngBz9YWRkicwcnIdKXnS0IzoG2x7bkyT/YaykZInwFx9YaTkCYycXEdKnoPR81k+/G8LwjTcYNtx1Y3UOY0B8X8yontMRESBwg0d3AjSsHk3lFddXY309HSYzWbodDqUlZUNeExVVRUSEhJgMBgwdepUlJSUeLzvcrmwZs0aWCwWhIaG4r777sOGDRvgbf+HhYmIaBTq6OhAXFwcCgsLB7V/Y2Mj0tLSkJycrD5bbNmyZaioqFD32bx5M4qKilBQUIAvvvgCmzdvxquvvort27d7lZt0kx/cbje+/PJLhIeHQ6e7818ADofD419ZjZQ8AebqCyMlT2Dk5OrvPBVFwdWrV2E2m/s82mSohnvyQ2pqKlJTUwe9f3FxMSwWC/Lz8wF0PwetpqYGW7ZsgdVqBQB8/PHHePzxx5GWlgYAmDx5Mt555x0cP37cq9ykK0xffvkloqOjvTrG2/39ZaTkCTBXXxgpeQIjJ1d/59nc3Czs4Z8uJQguRcN9TH8dLvt2sTYYDDAYDJpyA4Da2lqkpKR4tFmtVmRlZamvFyxYgB07duDs2bP43ve+h08//RQ1NTV47bXXvDqXdIUpPDwcAPAQ/h5jMFZYXF1crLBYt9J/9Y34oGN88GA+QX/V3erqzPHCYwKAK1j8tNeilwuEx8xcvUJ4TAAIa+oQHtP+N+Ivhru0/67rI/KHLeKDArj+rtinW7u6ruO/f79B/X0lk28X63Xr1mH9+vWa47a2tsJkMnm0mUwmOBwOdHZ2IjQ0FKtXr4bD4cD06dOh1+vhcrmwceNGLFq0yKtzSVeYeobvxmAsxugEFia9D36KAOiDfBA3aGQUpjFjQ4THBADdWPGFScvjBG7HV59/jP6m8Jh6gw9y9cG3/pgwH/2cBvvoe3WAyw3e6J78oP3R6s3NzR6z8kT0lgartLQUb7/9Nvbs2YOZM2eq16LMZjMyMjIGHUe6wkRENBq5NS5J5Eb3UJ7RaPTJdPGoqCjY7XaPNrvdDqPRqD6R+6WXXsLq1avxzDPPAABmz56NixcvIi8vz6vCxFl5REQ0oMTERBw6dMijrbKyEomJierra9eu9ZkMotfr4Xa7vToXe0xERBIQNflhsNrb23H+/Hn1dWNjI2w2GyIjIxETE4Pc3FxcunQJb731FgBg+fLlKCgowMqVK7F06VIcPnwYpaWlKC8vV2Okp6dj48aNiImJwcyZM9HQ0IDXXnsNS5cu9So3n/WYCgsLMXnyZISEhGD+/PleTxckIhpNtN1c2715o66uDvHx8YiPjwcA5OTkID4+HmvXrgUAtLS0oKmpSd3fYrGgvLwclZWViIuLQ35+Pnbt2qVOFQeA7du348knn8TPf/5zxMbG4he/+AV++tOfYsOGDV7l5pMe07vvvoucnBwUFxdj/vz52Lp1K6xWK86cOYPx430zk4uIiAYvKSnpjisyfHtVh55jGhoabntMeHg4tm7diq1bt2rKzSc9ptdeew0//vGPsWTJEsyYMQPFxcX4zne+g//8z//0xemIiEY8l6LTvAUK4T2mGzdu4OTJk8jNzVXbgoKCkJKSgtra2j77O51OjxWCZb/jnIjIF7Q/KHDErsfdh/Ae09dffw2Xy9XvjVitra199s/Ly0NERIS6+ftObiIif3ArQZq3QOH3T5Kbm4u2tjZ1a25u9ndKRETkR8KH8r773e9Cr9f3eyNWVFTfZUFEreNERDSScSivl/AeU3BwMB544AGPG7HcbjcOHTrkcSMWERH1ckPbBAjvbmGVm0+mi+fk5CAjIwNz587FvHnzsHXrVnR0dGDJkiW+OB0REQUQnxSmf/qnf8JXX32FtWvXorW1Fffffz8OHjzYZ0IEERF1G8pNst8+PlD4bEmiFStWYMUK3zwWgIgo0GhfkihwClPgfBIiIgoIXMSViEgCop7HFAhYmIiIJMChvF7SFiZdXKzQp84qDZ8Li+VhymThIV2RdwmPqf+qTXjMsVddwmMCgD5Y/A/Y79sShMc0XOkSHhMA9P8rflmuYIf4B8e5ffDb48u/RIgPCsDULnYy9c2uQJqcLR9pCxMR0Wii/QZb9piIiEggt6KDW8MK4VqOlU3glFgiIgoI7DEREUnArXEojzfYEhGRUFofXRFIj71gYSIikoALOrg03Iuk5VjZBE6JJSKigMAeExGRBDiU14uFiYhIAi5oG47zze3u/hE4JZaIiAICe0xERBLgUF4vFiYiIglwEddegfNJiIgoILDHREQkAUXj85iUALqPiYWJiEgCHMrrFTifhIiIAgJ7TEREEuBjL3qxMBERSYAPCuwVOJ+EiIgGrbq6Gunp6TCbzdDpdCgrKxvwmKqqKiQkJMBgMGDq1KkoKSnxeH/y5MnQ6XR9tszMTK9yY2EiIpJAz1Cels0bHR0diIuLQ2Fh4aD2b2xsRFpaGpKTk2Gz2ZCVlYVly5ahoqJC3efEiRNoaWlRt8rKSgDAU0895VVuHMojIpKAG0GaHvbn7bGpqalITU0d9P7FxcWwWCzIz88HAMTGxqKmpgZbtmyB1WoFANx7770ex7zyyiu477778PDDD3uVm7SFSf/VN9AHGcQFnDJZXKxb3LzwJ+Exx3RNFB4TXV3CQ+qdvlk2UudWhMecYrgsPOaRLrfwmACgBI8VHjO4XXyuXWHiB1x0QeK/9gAw5prgz++Dr71L0cGlYQJDz7EOh8Oj3WAwwGDQ/ru0trYWKSkpHm1WqxVZWVn97n/jxg387ne/Q05ODnQ67z4Xh/KIiAJIdHQ0IiIi1C0vL09I3NbWVphMJo82k8kEh8OBzs7OPvuXlZXhypUr+Od//mevzyVtj4mIaDQRNV28ubkZRqNRbRfRWxqK3/72t0hNTYXZbPb6WBYmIiIJKBpXF1f+eqzRaPQoTKJERUXBbrd7tNntdhiNRoSGhnq0X7x4ER999BHef//9IZ2LQ3lERDSgxMREHDp0yKOtsrISiYmJffbdvXs3xo8fj7S0tCGdi4WJiEgCLug0b95ob2+HzWaDzWYD0D0d3GazoampCQCQm5uLxYsXq/svX74cFy5cwMqVK3H69Gm8/vrrKC0tRXZ2tkdct9uN3bt3IyMjA2PGDG1QjkN5REQScCvalhXydjJrXV0dkpOT1dc5OTkAgIyMDJSUlKClpUUtUgBgsVhQXl6O7OxsbNu2DRMnTsSuXbvUqeI9PvroIzQ1NWHp0qVD/izCC1NeXh7ef/99nD59GqGhoViwYAE2b96M73//+6JPRUREQ5SUlARFuX01+/aqDj3HNDQ03DHuo48+ese4gyF8KO/o0aPIzMzEsWPHUFlZia6uLjz66KPo6OgQfSoiooDR82h1LVugEN5jOnjwoMfrkpISjB8/HidPnsQPfvAD0acjIgoIbo0PCtRyrGx8fo2pra0NABAZGdnv+06nE06nU3397buWiYhodPFp38/tdiMrKwsLFy7ErFmz+t0nLy/P4y7l6OhoX6ZERCSlniWJtGyBwqeFKTMzE6dOncLevXtvu09ubi7a2trUrbm52ZcpERFJideYevlsKG/FihXYv38/qqurMXHi7RclFbXAIBERBQbhhUlRFDz//PPYt28fqqqqYLFYRJ+CiCjguKFxrTxOfri9zMxM7NmzB3/4wx8QHh6O1tZWAEBERESf9ZSIiKibonFWnsLCdHtFRUUAum/EutXu3buHtPw5EdFoIGp18UDgk6E8IiKioeJaeUREEtA6s46z8oiISCgO5fUKnBJLREQBQd4e0xg9EKQXFs4VeZewWLca03X7e7SG6mbzn4XH1E+bIjzmDeNY4TEBwG0Q/5ffglDxN24XR/jm8+udYcJjXr9H/N+grhDxX6eIuzqFxwSAG8bvCI13s0vc76YeXCuvl7yFiYhoFOFQXi8O5RERkVTYYyIikgB7TL1YmIiIJMDC1ItDeUREJBX2mIiIJMAeUy8WJiIiCSjQNuU7kBaDY2EiIpIAe0y9eI2JiIikwh4TEZEE2GPqxcJERCQBFqZeHMojIiKpsMdERCQB9ph6sTAREUlAUXRQNBQXLcfKhkN5REQkFfaYiIgkwOcx9WKPiYhIAj3XmLRs3qiurkZ6ejrMZjN0Oh3KysoGPKaqqgoJCQkwGAyYOnUqSkpK+uxz6dIlPPfccxg3bhxCQ0Mxe/Zs1NXVeZUbCxMR0SjU0dGBuLg4FBYWDmr/xsZGpKWlITk5GTabDVlZWVi2bBkqKirUfb755hssXLgQY8eOxYcffog//vGPyM/Pxz333ONVbhzKIyKSwHBPfkhNTUVqauqg9y8uLobFYkF+fj4AIDY2FjU1NdiyZQusVisAYPPmzYiOjsbu3bvV4ywWi1d5AewxERFJQdRQnsPh8NicTqeQ/Gpra5GSkuLRZrVaUVtbq77+4IMPMHfuXDz11FMYP3484uPjsXPnTq/PJW+PKSioexNE/1WbsFgeurqEh9RPmyI8puvcBeExgyZ51z0fLJ0i/u+lVpdBeMygLt+s5xzUIeYXya3GdIYJj6lzCQ+JK1dDxQcFYO4Qm6yuywcfXpDo6GiP1+vWrcP69es1x21tbYXJZPJoM5lMcDgc6OzsRGhoKC5cuICioiLk5OTgl7/8JU6cOIEXXngBwcHByMjIGPS55C1MRESjiKihvObmZhiNRrXdYBD/R9ntuN1uzJ07F5s2bQIAxMfH49SpUyguLmZhIiIaaRSNKz/0FCaj0ehRmESJioqC3W73aLPb7TAajQgN7e7pTpgwATNmzPDYJzY2Fu+9955X52JhIiKSgAJA0TA67OsHBSYmJuLAgQMebZWVlUhMTFRfL1y4EGfOnPHY5+zZs5g0aZJX5+LkByKiUai9vR02mw02mw1A93Rwm82GpqYmAEBubi4WL16s7r98+XJcuHABK1euxOnTp/H666+jtLQU2dnZ6j7Z2dk4duwYNm3ahPPnz2PPnj3YsWMHMjMzvcqNhYmISAI9Kz9o2bxRV1eH+Ph4xMfHAwBycnIQHx+PtWvXAgBaWlrUIgV0T/suLy9HZWUl4uLikJ+fj127dqlTxQHgwQcfxL59+/DOO+9g1qxZ2LBhA7Zu3YpFixZ5lRuH8oiIJDDc9zElJSVBucPYYX+rOiQlJaGhoeGOcR977DE89thjXuXybT7vMb3yyivQ6XTIysry9amIiCgA+LTHdOLECbzxxhuYM2eOL09DRDTiuRUddHweEwAf9pja29uxaNEi7Ny50+t1koiIRhtF0b4FCp8VpszMTKSlpfVZwuLbnE5nnyU0iIho9PLJUN7evXtRX1+PEydODLhvXl4efvWrX/kiDSKiEYNPsO0lvMfU3NyMF198EW+//TZCQkIG3D83NxdtbW3q1tzcLDolIiLp9RQmLVugEN5jOnnyJC5fvoyEhAS1zeVyobq6GgUFBXA6ndDr9ep7BoNhWNdyIiIiuQkvTI888gg+++wzj7YlS5Zg+vTpWLVqlUdRIiKibpyV10t4YQoPD8esWbM82sLCwjBu3Lg+7URE1E3rzDrOyiMiIvKRYVmSqKqqajhOQ0Q0YnX3mLTMyhOYjJ9xrTwiIglwungvFiYiIgko0PZMpQDqMPEaExERyUXaHtPVmeMxZuzAN+gO1tirLmGxbqV3io97wzhWeMygSeLXKxz70UnhMQFAf3eE8Jj/p/bHwmNOq/mj8JgAcO3hmcJj3n36qvCYyljxt360T7pLeEwA+M6Fr4TGu+lyCo0HcCjvVtIWJiKiUYVjeSoO5RERkVTYYyIikoHW9e44lEdERCJx5YdeHMojIiKpsMdERCQBzsrrxcJERCQDRaftOlEAFSYO5RERkVTYYyIikgAnP/RiYSIikgFvsFVxKI+IiKTCHhMRkQQ4K68XCxMRkSwCaDhOCxYmIiIJsMfUi9eYiIhIKuwxERHJgLPyVOwxERFJQSdgG7zq6mqkp6fDbDZDp9OhrKxswGOqqqqQkJAAg8GAqVOnoqSkxOP99evXQ6fTeWzTp0/3Ki+AhYmIaFTq6OhAXFwcCgsLB7V/Y2Mj0tLSkJycDJvNhqysLCxbtgwVFRUe+82cORMtLS3qVlNT43VuHMojIpLBMA/lpaamIjU1ddD7FxcXw2KxID8/HwAQGxuLmpoabNmyBVarVd1vzJgxiIqK8i6Zb2GPiYhIBoqADYDD4fDYnE6nkPRqa2uRkpLi0Wa1WlFbW+vRdu7cOZjNZkyZMgWLFi1CU1OT1+diYSIiCiDR0dGIiIhQt7y8PCFxW1tbYTKZPNpMJhMcDgc6OzsBAPPnz0dJSQkOHjyIoqIiNDY24m//9m9x9epVr84l7VCeK1gH3Vhx8/L1wb6pwTq3+KkwboP4+xF0ivjPr787QnhMAHBdaRMfs1P8t7r7upi/RPvE9cHXH0Hiv/6KbuTcN6OM1YuNFyQ2XndQMY+9aG5uhtFoVJsNBoPWzAbt1qHBOXPmYP78+Zg0aRJKS0vxL//yL4OOI21hIiIaTUStLm40Gj0KkyhRUVGw2+0ebXa7HUajEaGhof0ec/fdd+N73/sezp8/79W5OJRHREQDSkxMxKFDhzzaKisrkZiYeNtj2tvb8T//8z+YMGGCV+diYSIikoGgyQ+D1d7eDpvNBpvNBqB7OrjNZlMnK+Tm5mLx4sXq/suXL8eFCxewcuVKnD59Gq+//jpKS0uRnZ2t7vOLX/wCR48exZ/+9Cd8/PHH+Id/+Afo9Xo8++yzXuXGoTwiIhkM86PV6+rqkJycrL7OyckBAGRkZKCkpAQtLS0eM+osFgvKy8uRnZ2Nbdu2YeLEidi1a5fHVPE///nPePbZZ/GXv/wF9957Lx566CEcO3YM9957r1e5sTAREY1CSUlJUO5wUevbqzr0HNPQ0HDbY/bu3SsiNRYmIiIZ6JTuTcvxgcIn15guXbqE5557DuPGjUNoaChmz56Nuro6X5yKiCgwDPM1JpkJ7zF98803WLhwIZKTk/Hhhx/i3nvvxblz53DPPfeIPhURUeAY5mtMMhNemDZv3ozo6Gjs3r1bbbNYLKJPQ0REAUr4UN4HH3yAuXPn4qmnnsL48eMRHx+PnTt33nZ/p9PZZ20nIqJRh0N5KuGF6cKFCygqKsK0adNQUVGBn/3sZ3jhhRfw5ptv9rt/Xl6ex7pO0dHRolMiIpIfC5NKeGFyu91ISEjApk2bEB8fj5/85Cf48Y9/jOLi4n73z83NRVtbm7o1NzeLTomIiEYQ4deYJkyYgBkzZni0xcbG4r333ut3f4PBMKyLDBIRSYmPVlcJL0wLFy7EmTNnPNrOnj2LSZMmiT4VEVHg4Kw8lfChvOzsbBw7dgybNm3C+fPnsWfPHuzYsQOZmZmiT0VERAFIeGF68MEHsW/fPrzzzjuYNWsWNmzYgK1bt2LRokWiT0VEFDB6Vn7QsgUKnyxJ9Nhjj+Gxxx7zRWgiosDEa0wqPvaCiIikwsJERERS4eriREQS0EHj6uLCMvE/aQtT0csFuCtcXIfu920JwmLdaorhsvCYC0LF32Tc6hJ/r9j/qf2x8JgA4OoU/235vX8Rv7r92aJ5wmMCQG7SfuExuxS98JgXOr17+Ntg/L8J9cJjAsD/TRf78+9s78LhHwgNyenit+BQHhERSUXaHhMR0ajCWXkqFiYiIhmwMKk4lEdERFJhj4mISAJaV2/gyg9ERCQWh/JUHMojIiKpsMdERCQD9phULExERBLgNaZeHMojIiKpsMdERCQDLkmkYmEiIpIBrzGpOJRHRERSYY+JiEgCnPzQi4WJiEgGHMpTcSiPiEgGSm+vaSibt4Wpuroa6enpMJvN0Ol0KCsrG/CYqqoqJCQkwGAwYOrUqSgpKbntvq+88gp0Oh2ysrK8SwwsTEREo1JHRwfi4uJQWFg4qP0bGxuRlpaG5ORk2Gw2ZGVlYdmyZaioqOiz74kTJ/DGG29gzpw5Q8qNQ3lERDIY5qG81NRUpKamDnr/4uJiWCwW5OfnAwBiY2NRU1ODLVu2wGq1qvu1t7dj0aJF2LlzJ15++WXvkvor9piIiGSgCNgAOBwOj83pdApJr7a2FikpKR5tVqsVtbW1Hm2ZmZlIS0vrs683WJiIiAJIdHQ0IiIi1C0vL09I3NbWVphMJo82k8kEh8OBzs5OAMDevXtRX1+v+ZzSDuVlrl6BMWNDhMUzXOkSFutWR7rcwmMWR4wVHjOoS/yUnWk1fxQeEwDc18X8hXers0XzhMf83s+OC48JAHtS04THDPmqU3hMJUj8SgMzrH8jPCYATH7va6HxbrrEf4+Kmi7e3NwMo9GothsMBo2ZDU5zczNefPFFVFZWIiRE2+9uaQsTERF5z2g0ehQmUaKiomC32z3a7HY7jEYjQkNDcfLkSVy+fBkJCQnq+y6XC9XV1SgoKIDT6YRerx/UuViYiIhoQImJiThw4IBHW2VlJRITEwEAjzzyCD777DOP95csWYLp06dj1apVgy5KAAsTEZEchnlWXnt7O86fP6++bmxshM1mQ2RkJGJiYpCbm4tLly7hrbfeAgAsX74cBQUFWLlyJZYuXYrDhw+jtLQU5eXlAIDw8HDMmjXL4xxhYWEYN25cn/aBsDAREUlguJckqqurQ3Jysvo6JycHAJCRkYGSkhK0tLSgqalJfd9isaC8vBzZ2dnYtm0bJk6ciF27dnlMFReFhYmIaBRKSkqCoty+mvW3qkNSUhIaGhoGfY6qqqohZMbCREQkjwBa704L4fcxuVwurFmzBhaLBaGhobjvvvuwYcOGO1ZmIqJRT9ANtoFAeI9p8+bNKCoqwptvvomZM2eirq4OS5YsQUREBF544QXRpyMiogAjvDB9/PHHePzxx5GW1n2T4OTJk/HOO+/g+HHf3IxIRBQI+DymXsKH8hYsWIBDhw7h7NmzAIBPP/0UNTU1t10s0Ol09lnbiYho1OFQnkp4j2n16tVwOByYPn069Ho9XC4XNm7ciEWLFvW7f15eHn71q1+JToOIaERhj6mX8B5TaWkp3n77bezZswf19fV488038R//8R948803+90/NzcXbW1t6tbc3Cw6JSIiGkGE95heeuklrF69Gs888wwAYPbs2bh48SLy8vKQkZHRZ3+DwTBsiwwSEUmLj1ZXCS9M165dQ1CQZ0dMr9fD7Ra/CjcRUcBgYVIJL0zp6enYuHEjYmJiMHPmTDQ0NOC1117D0qVLRZ+KiIgCkPDCtH37dqxZswY///nPcfnyZZjNZvz0pz/F2rVrRZ+KiChgcPJDL+GFKTw8HFu3bsXWrVtFhyYiClwcylPx0epERCQVLuJKRCQD9phULExERBLgNaZeHMojIiKpSNtjCmvqwBj9TWHx9P/rmzX4lOCxwmPqnWHCYwZ1OIXHvPbwTOExAcBt0AmPmZu0X3jMPalpwmMCgOHDE8Jj2n++QHhMt/hvfYTN/1p8UAD/eyFSaDzXjevAaaEhOZR3C2kLExHRaMKhvF4cyiMiIqmwx0REJAMO5alYmIiIZMDCpGJhIiKSgO6vm5bjAwWvMRERkVTYYyIikgGH8lQsTEREEuB08V4cyiMiIqmwx0REJAMO5alYmIiIZBFAxUULDuUREZFU2GMiIpIAJz/0Yo+JiEgGioDNC9XV1UhPT4fZbIZOp0NZWdmAx1RVVSEhIQEGgwFTp05FSUmJx/tFRUWYM2cOjEYjjEYjEhMT8eGHH3qXGFiYiIhGpY6ODsTFxaGwsHBQ+zc2NiItLQ3Jycmw2WzIysrCsmXLUFFRoe4zceJEvPLKKzh58iTq6urwwx/+EI8//jg+//xzr3LjUB4RkQSGeygvNTUVqampg96/uLgYFosF+fn5AIDY2FjU1NRgy5YtsFqtAID09HSPYzZu3IiioiIcO3YMM2cO/vlt7DEREclA0FCew+Hw2JxOMQ8Jra2tRUpKikeb1WpFbW1tv/u7XC7s3bsXHR0dSExM9OpcLExERAEkOjoaERER6paXlyckbmtrK0wmk0ebyWSCw+FAZ2en2vbZZ5/hrrvugsFgwPLly7Fv3z7MmDHDq3NxKI+ISAKihvKam5thNBrVdoPBoDEz73z/+9+HzWZDW1sbfv/73yMjIwNHjx71qjixMBERyUDQyg89M+JEi4qKgt1u92iz2+0wGo0IDQ1V24KDgzF16lQAwAMPPIATJ05g27ZteOONNwZ9LmkLk/1vjNAbQoTFC3aI/0IBQHC7W3jM6/eIH2Ed0xkmPObdp68KjwkACBL/+bsUvfCYIV91DrzTENh/vkB4zPGvfyw8pn7aFOExG++OEh4TACwHvhAa76ZyQ2g8ANIvSZSYmIgDBw54tFVWVg54/cjtdnt9nUvawkRERL7T3t6O8+fPq68bGxths9kQGRmJmJgY5Obm4tKlS3jrrbcAAMuXL0dBQQFWrlyJpUuX4vDhwygtLUV5ebkaIzc3F6mpqYiJicHVq1exZ88eVFVVeUwpHwwWJiIiCQz3dPG6ujokJyerr3NycgAAGRkZKCkpQUtLC5qamtT3LRYLysvLkZ2djW3btmHixInYtWuXOlUcAC5fvozFixejpaUFERERmDNnDioqKvB3f/d3XuXGwkREJINhHspLSkqCotz+oG+v6tBzTENDw22P+e1vf+tdErfB6eJERCQV9piIiCSgUxTo7tCDGczxgYKFiYhIBpLPyhtOXg/lDbQiraIoWLt2LSZMmIDQ0FCkpKTg3LlzovIlIqIA53VhGmhF2ldffRW/+c1vUFxcjE8++QRhYWGwWq24fv265mSJiAJVz6w8LVug8Hoo704r0iqKgq1bt+Lf/u3f8PjjjwMA3nrrLZhMJpSVleGZZ57Rli0RUaDiUJ5K6Ky8xsZGtLa2eqxAGxERgfnz5992BVqn09lnNVwiIhq9hBam1tZWAOh3Bdqe974tLy/PYyXc6OhokSkREY0IHMrr5ff7mHJzc9HW1qZuzc3N/k6JiGj4DfOj1WUmtDBFRXUvwNjfCrQ9732bwWBQV8P11aq4REQ0cggtTBaLBVFRUTh06JDa5nA48Mknn3j9BEMiotGEQ3m9vJ6VN9CKtFlZWXj55Zcxbdo0WCwWrFmzBmazGU888YTIvImIAgtn5am8LkwDrUi7cuVKdHR04Cc/+QmuXLmChx56CAcPHkRIiLhnKxERBaJA6vVo4XVhGmhFWp1Oh1//+tf49a9/rSkxIiIanbhWHhGRDBSle9NyfIBgYSIiksBwPyhQZn6/j4mIiOhW0vaYXAYABnHx3D76pF1h4mu7K0QnPKbOJTwklLF68UEBKDrxn/9C573CYypB4vMEAPdY8TH106YIj+k6d0F4zJiKu4THBACMEfwLwO0WGw/grLxbSFuYiIhGE527e9NyfKDgUB4REUmFPSYiIhlwKE/FwkREJAHOyuvFoTwiIpIKe0xERDLgDbYqFiYiIglwKK8Xh/KIiEgq7DEREcmAs/JULExERBLgUF4vFiYiIhlw8oOK15iIiEgq7DEREUmAQ3m92GMiIpKBImDzQnV1NdLT02E2m6HT6VBWVjbgMVVVVUhISIDBYMDUqVNRUlLi8X5eXh4efPBBhIeHY/z48XjiiSdw5swZ7xIDCxMR0ajU0dGBuLg4FBYWDmr/xsZGpKWlITk5GTabDVlZWVi2bBkqKirUfY4ePYrMzEwcO3YMlZWV6OrqwqOPPoqOjg6vcuNQHhGRBIZ7KC81NRWpqamD3r+4uBgWiwX5+fkAgNjYWNTU1GDLli2wWq0AgIMHD3ocU1JSgvHjx+PkyZP4wQ9+MOhzscdERCQDt6J9A+BwODw2p9MpJL3a2lqkpKR4tFmtVtTW1t72mLa2NgBAZGSkV+diYSIiCiDR0dGIiIhQt7y8PCFxW1tbYTKZPNpMJhMcDgc6Ozv77O92u5GVlYWFCxdi1qxZXp2LQ3lERDIQtPJDc3MzjEaj2mwwGDSlNVSZmZk4deoUampqvD6WhYmISAI6aLzG9Nd/jUajR2ESJSoqCna73aPNbrfDaDQiNDTUo33FihXYv38/qqurMXHiRK/PJW1hivxhC8aEiav0X/4lQlisW+mCxN88EHFX326xVleuhg68k5faJ90lPKav/L8J9cJjzrD+jfCYABA2/2vhMRvvjhIeM6bCB1//Y/8tPiaAr5YkCo3nunEd+J3QkNJLTEzEgQMHPNoqKyuRmNj7f6soCp5//nns27cPVVVVsFgsQzoXrzEREcmgZ0kiLZsX2tvbYbPZYLPZAHRPB7fZbGhqagIA5ObmYvHixer+y5cvx4ULF7By5UqcPn0ar7/+OkpLS5Gdna3uk5mZid/97nfYs2cPwsPD0draitbW1n6vQd0JCxMRkQR6potr2bxRV1eH+Ph4xMfHAwBycnIQHx+PtWvXAgBaWlrUIgUAFosF5eXlqKysRFxcHPLz87Fr1y51qjgAFBUVoa2tDUlJSZgwYYK6vfvuu17lJu1QHhHRqDLMj71ISkqCcode1rdXdeg5pqGh4fYpCFpIlj0mIiKSCntMREQS0CkKdBp6HFqOlQ0LExGRDNx/3bQcHyC8Hsq704q0XV1dWLVqFWbPno2wsDCYzWYsXrwYX375pciciYgogHldmO60Iu21a9dQX1+PNWvWoL6+Hu+//z7OnDmDH/3oR0KSJSIKVD1DeVq2QOH1UN6dVqSNiIhAZWWlR1tBQQHmzZuHpqYmxMTEDC1LIqJAN8yz8mTm82tMbW1t0Ol0uPvuu/t93+l0eqx+63A4fJ0SERFJzKfTxa9fv45Vq1bh2Wefve3aTXl5eR4r4UZHR/syJSIiOQ3zyg8y81lh6urqwtNPPw1FUVBUVHTb/XJzc9HW1qZuzc3NvkqJiEhaw73yg8x8MpTXU5QuXryIw4cP33GlW4PB4Ldl2YmISD7CC1NPUTp37hyOHDmCcePGiT4FEVHg0TocF0BDeV4Xpvb2dpw/f1593bMibWRkJCZMmIAnn3wS9fX12L9/P1wuF1pbWwF0P1o3ODhYXOZERAFE5+7etBwfKLwuTHV1dUhOTlZf5+TkAAAyMjKwfv16fPDBBwCA+++/3+O4I0eOICkpaeiZEhHRqOB1YRpoRVpRq8sSEY0qHMpTca08IiIZ8AZbFQsTEZEEuLp4Lz6PiYiIpMIeExGRDHiNSSVtYbr+bhT0wSHC4pnafTOXcsw18XFvGL8jPKa5wyU85ncufCU8JgAoY/XCY/7f9AThMSe/97XwmADwvxcihce0HPhCeEyMEf/r46slicJjAkDk7lqh8W4qXULjAei+RqTl10ng1CUO5RERkVyk7TEREY0mnPzQi4WJiEgGCjReYxKWid9xKI+IiKTCHhMRkQw4K0/FwkREJAM3AJ3G4wMEh/KIiEgq7DEREUmAs/J6sTAREcmA15hUHMojIiKpsMdERCQD9phULExERDJgYVJxKI+ISAZuAZsXqqurkZ6eDrPZDJ1Oh7KysgGPqaqqQkJCAgwGA6ZOnYqSkhLNMfvDwkRENAp1dHQgLi4OhYWFg9q/sbERaWlpSE5Ohs1mQ1ZWFpYtW4aKioohx7wdDuUREUlguKeLp6amIjU1ddD7FxcXw2KxID8/HwAQGxuLmpoabNmyBVardUgxb4c9JiIiGfRcY9KyAXA4HB6b0+kUkl5tbS1SUlI82qxWK2prxT7rCmBhIiIKKNHR0YiIiFC3vLw8IXFbW1thMpk82kwmExwOBzo7O4WcoweH8oiIZOBWAJ2GmXXu7mObm5thNBrVZoPBoDWzYcfCREQkA0HTxY1Go0dhEiUqKgp2u92jzW63w2g0IjQ0VOi5pCtMyl//c11d14XGvdnlo6V3fRD3ZpdeeExdl0t4zJsuMWPX36YEif/8zvYu4TF99fldN8R+7wPATeWG8Jhwi//e98VnB4Cbitiv/010x1MC6N6hgSQmJuLAgQMebZWVlUhMTBR+LukK09WrVwEA//37DX7OhALJ4R/4OwMvnPZ3An70O38n4J2rV68iIiJCUDSNPSYvH2Hb3t6O8+fPq68bGxths9kQGRmJmJgY5Obm4tKlS3jrrbcAAMuXL0dBQQFWrlyJpUuX4vDhwygtLUV5efmgYw6WdIXJbDajubkZ4eHh0Onu/HASh8OB6OjoPmOqshkpeQLM1RdGSp7AyMnV33kqioKrV6/CbDaLDDqsKz/U1dUhOTlZfZ2TkwMAyMjIQElJCVpaWtDU1KS+b7FYUF5ejuzsbGzbtg0TJ07Erl271Knig4k5WNIVpqCgIEycONGrY3w1piraSMkTYK6+MFLyBEZOrv7MU1xPyT+SkpLuOBTZXyFJSkpCQ0PDkGMOlnSFiYhoVHIr8HY4ru/xgYGFiYhIBoq7e9NyfIAY0TfYGgwGrFu3Tvp5+iMlT4C5+sJIyRMYObmOlDxpaHTKaJrvSEQkGYfDgYiICKRE/wxjgoZeaG+6nfiouQhtbW0j4vrgnXAoj4hIBrzGpGJhIiKSAR8UqBrR15iIiCjwsMdERCQDBRp7TMIy8TsWJiIiGXAoT8WhPCIikgp7TEREMnC7AWi4SdYHq737CwsTEZEMOJSn4lAeERFJhT0mIiIZsMekYmEiIpIBV35QcSiPiIikwh4TEZEEFMUNRcOjK7QcKxsWJiIiGSiKtuG4ALrGxKE8IiKSCntMREQyUDROfgigHhMLExGRDNxuQMdHqwMsTEREcmCPScVrTEREJBX2mIiIJKC43VA0DOVxujgREYnFoTwVh/KIiEgq7DEREcnArQA69pgAFiYiIjkoCjQ9KDCAChOH8oiISCrsMRERSUBxK1A0DOUpAdRjYmEiIpKB4oa2obzAmS7OoTwiolGouroa6enpMJvN0Ol0KCsrG/CYqqoqJCQkwGAwYOrUqSgpKemzT2FhISZPnoyQkBDMnz8fx48f9zo3FiYiIgkobkXz5o2Ojg7ExcWhsLBwUPs3NjYiLS0NycnJsNlsyMrKwrJly1BRUaHu8+677yInJwfr1q1DfX094uLiYLVacfnyZa9y0ymBNDBJRDTCOBwORERE4CH8PcZg7JDj3EQXanAAbW1tMBqNXh2r0+mwb98+PPHEE7fdZ9WqVSgvL8epU6fUtmeeeQZXrlzBwYMHAQDz58/Hgw8+iIKCAgCA2+1GdHQ0nn/+eaxevXrQ+fAaExGRHwUHByMqKgo1rQc0x4qKisL169c92gwGAwwGg+bYtbW1SElJ8WizWq3IysoCANy4cQMnT55Ebm6u+n5QUBBSUlJQW1vr1blYmIiI/CgkJASNjY24ceOG5livvvoqTCaTR9u6deuwfv16zbFbW1v7xDaZTHA4HOjs7MQ333wDl8vV7z6nT5/26lwsTEREfhYSEoKQkBDNcdasWYOVK1d6tInoLQ03FiYiogAhatiuP1FRUbDb7R5tdrsdRqMRoaGh0Ov10Ov1/e4TFRXl1bk4K4+IiAaUmJiIQ4cOebRVVlYiMTERQPe1sgceeMBjH7fbjUOHDqn7DBYLExHRKNTe3g6bzQabzQagezq4zWZDU1MTACA3NxeLFy9W91++fDkuXLiAlStX4vTp03j99ddRWlqK7OxsdZ+cnBzs3LkTb775Jr744gv87Gc/Q0dHB5YsWeJdcgoREY06R44c6XkAlMeWkZGhKIqiZGRkKA8//HCfY+6//34lODhYmTJlirJ79+4+cbdv367ExMQowcHByrx585Rjx455nRvvYyIiIqlwKI+IiKTCwkRERFJhYSIiIqmwMBERkVRYmIiISCosTEREJBUWJiIikgoLExERSYWFiYiIpMLCREREUmFhIiIiqfx/cj+02+XR+ckAAAAASUVORK5CYII=","text/plain":["<Figure size 480x480 with 2 Axes>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/Users/yuwei-1/anaconda3/envs/ktools_2/lib/python3.10/site-packages/sklearn/cluster/_spectral.py:701: UserWarning: The spectral clustering API has changed. ``fit``now constructs an affinity matrix from data. To use a custom affinity matrix, set ``affinity=precomputed``.\n","  warnings.warn(\n"]}],"source":["import matplotlib.pyplot as plt\n","inverse_similarity = (1/best_test.test_pred.corr()).to_numpy()\n","\n","# np.fill_diagonal(inverse_similarity, 0)\n","from sklearn.cluster import SpectralClustering\n","\n","plt.matshow(inverse_similarity)\n","plt.colorbar()\n","plt.show()\n","\n","sc = SpectralClustering(n_clusters=3)\n","labels = sc.fit_predict(inverse_similarity)"]},{"cell_type":"code","execution_count":256,"metadata":{},"outputs":[],"source":["# best_test.test_pred.drop(columns=['laml_lgbmonly', 'laml_lgb_cb'], inplace=True)\n","# best_test.train_oof_pred.drop(columns=['laml_lgbmonly', 'laml_lgb_cb'], inplace=True)\n"]},{"cell_type":"code","execution_count":302,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>xgblinear</th>\n","      <th>lgb</th>\n","      <th>cat</th>\n","      <th>knn</th>\n","      <th>hgb</th>\n","      <th>ag-small</th>\n","      <th>ag-mae</th>\n","      <th>ag-medae</th>\n","      <th>ag-r2</th>\n","      <th>xgb</th>\n","      <th>laml_catonly</th>\n","      <th>laml_lgb_cb_tuned</th>\n","      <th>laml_lgbmonly</th>\n","      <th>laml_nn_feats</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>188533</th>\n","      <td>17311.228516</td>\n","      <td>18779.773692</td>\n","      <td>18967.814599</td>\n","      <td>19771.104609</td>\n","      <td>19032.174313</td>\n","      <td>19343.6070</td>\n","      <td>19219.730</td>\n","      <td>18763.650</td>\n","      <td>19442.900</td>\n","      <td>17913.550049</td>\n","      <td>19092.697</td>\n","      <td>18278.941</td>\n","      <td>18998.316</td>\n","      <td>18981.760</td>\n","    </tr>\n","    <tr>\n","      <th>188534</th>\n","      <td>74507.042969</td>\n","      <td>74195.440716</td>\n","      <td>74314.391573</td>\n","      <td>75728.141722</td>\n","      <td>73754.588065</td>\n","      <td>77652.8200</td>\n","      <td>74289.700</td>\n","      <td>80107.360</td>\n","      <td>74688.266</td>\n","      <td>81477.774414</td>\n","      <td>76175.020</td>\n","      <td>77180.840</td>\n","      <td>76242.100</td>\n","      <td>75921.750</td>\n","    </tr>\n","    <tr>\n","      <th>188535</th>\n","      <td>61661.458008</td>\n","      <td>59382.773219</td>\n","      <td>60935.759494</td>\n","      <td>57026.678486</td>\n","      <td>58838.155506</td>\n","      <td>58982.0550</td>\n","      <td>59302.730</td>\n","      <td>56502.414</td>\n","      <td>58766.220</td>\n","      <td>56430.732422</td>\n","      <td>57041.520</td>\n","      <td>57490.766</td>\n","      <td>57569.348</td>\n","      <td>56954.203</td>\n","    </tr>\n","    <tr>\n","      <th>188536</th>\n","      <td>23579.476562</td>\n","      <td>27096.058210</td>\n","      <td>28791.942974</td>\n","      <td>29145.186469</td>\n","      <td>26347.035218</td>\n","      <td>30070.9550</td>\n","      <td>30788.043</td>\n","      <td>27360.117</td>\n","      <td>29931.508</td>\n","      <td>27002.433594</td>\n","      <td>30448.707</td>\n","      <td>30660.596</td>\n","      <td>29996.790</td>\n","      <td>29893.342</td>\n","    </tr>\n","    <tr>\n","      <th>188537</th>\n","      <td>29453.227051</td>\n","      <td>29866.435298</td>\n","      <td>30348.902244</td>\n","      <td>29578.183407</td>\n","      <td>29543.909420</td>\n","      <td>31455.8770</td>\n","      <td>31552.445</td>\n","      <td>30988.547</td>\n","      <td>31781.781</td>\n","      <td>29717.227539</td>\n","      <td>30386.824</td>\n","      <td>30643.406</td>\n","      <td>30786.209</td>\n","      <td>30523.236</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>314218</th>\n","      <td>26675.092773</td>\n","      <td>26493.786508</td>\n","      <td>26399.991547</td>\n","      <td>25567.268378</td>\n","      <td>27673.563213</td>\n","      <td>27062.9650</td>\n","      <td>27426.390</td>\n","      <td>27823.740</td>\n","      <td>27656.715</td>\n","      <td>26225.318848</td>\n","      <td>28120.336</td>\n","      <td>28374.504</td>\n","      <td>27910.977</td>\n","      <td>29353.402</td>\n","    </tr>\n","    <tr>\n","      <th>314219</th>\n","      <td>50213.050781</td>\n","      <td>48027.577375</td>\n","      <td>49216.172903</td>\n","      <td>47445.388038</td>\n","      <td>48110.006392</td>\n","      <td>54203.1680</td>\n","      <td>52154.210</td>\n","      <td>48417.324</td>\n","      <td>53495.055</td>\n","      <td>49367.322266</td>\n","      <td>49414.367</td>\n","      <td>50381.523</td>\n","      <td>48643.580</td>\n","      <td>49904.330</td>\n","    </tr>\n","    <tr>\n","      <th>314220</th>\n","      <td>18222.807373</td>\n","      <td>20110.130845</td>\n","      <td>18917.172384</td>\n","      <td>19693.657082</td>\n","      <td>20437.950962</td>\n","      <td>19474.0860</td>\n","      <td>19164.746</td>\n","      <td>18299.508</td>\n","      <td>19224.037</td>\n","      <td>19731.197021</td>\n","      <td>19272.940</td>\n","      <td>19490.973</td>\n","      <td>19316.730</td>\n","      <td>20229.342</td>\n","    </tr>\n","    <tr>\n","      <th>314221</th>\n","      <td>13036.375000</td>\n","      <td>16457.965651</td>\n","      <td>16859.260079</td>\n","      <td>15315.434220</td>\n","      <td>16150.665946</td>\n","      <td>16117.7705</td>\n","      <td>16422.330</td>\n","      <td>16211.982</td>\n","      <td>16250.578</td>\n","      <td>16575.199219</td>\n","      <td>16360.864</td>\n","      <td>16322.670</td>\n","      <td>17216.360</td>\n","      <td>16647.824</td>\n","    </tr>\n","    <tr>\n","      <th>314222</th>\n","      <td>42500.701172</td>\n","      <td>39319.411345</td>\n","      <td>39681.477051</td>\n","      <td>38974.634723</td>\n","      <td>38986.234800</td>\n","      <td>41327.5660</td>\n","      <td>42615.445</td>\n","      <td>43711.758</td>\n","      <td>42957.695</td>\n","      <td>38798.145508</td>\n","      <td>36255.570</td>\n","      <td>37254.234</td>\n","      <td>39659.848</td>\n","      <td>37465.500</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>125690 rows × 14 columns</p>\n","</div>"],"text/plain":["           xgblinear           lgb           cat           knn           hgb  \\\n","188533  17311.228516  18779.773692  18967.814599  19771.104609  19032.174313   \n","188534  74507.042969  74195.440716  74314.391573  75728.141722  73754.588065   \n","188535  61661.458008  59382.773219  60935.759494  57026.678486  58838.155506   \n","188536  23579.476562  27096.058210  28791.942974  29145.186469  26347.035218   \n","188537  29453.227051  29866.435298  30348.902244  29578.183407  29543.909420   \n","...              ...           ...           ...           ...           ...   \n","314218  26675.092773  26493.786508  26399.991547  25567.268378  27673.563213   \n","314219  50213.050781  48027.577375  49216.172903  47445.388038  48110.006392   \n","314220  18222.807373  20110.130845  18917.172384  19693.657082  20437.950962   \n","314221  13036.375000  16457.965651  16859.260079  15315.434220  16150.665946   \n","314222  42500.701172  39319.411345  39681.477051  38974.634723  38986.234800   \n","\n","          ag-small     ag-mae   ag-medae      ag-r2           xgb  \\\n","188533  19343.6070  19219.730  18763.650  19442.900  17913.550049   \n","188534  77652.8200  74289.700  80107.360  74688.266  81477.774414   \n","188535  58982.0550  59302.730  56502.414  58766.220  56430.732422   \n","188536  30070.9550  30788.043  27360.117  29931.508  27002.433594   \n","188537  31455.8770  31552.445  30988.547  31781.781  29717.227539   \n","...            ...        ...        ...        ...           ...   \n","314218  27062.9650  27426.390  27823.740  27656.715  26225.318848   \n","314219  54203.1680  52154.210  48417.324  53495.055  49367.322266   \n","314220  19474.0860  19164.746  18299.508  19224.037  19731.197021   \n","314221  16117.7705  16422.330  16211.982  16250.578  16575.199219   \n","314222  41327.5660  42615.445  43711.758  42957.695  38798.145508   \n","\n","        laml_catonly  laml_lgb_cb_tuned  laml_lgbmonly  laml_nn_feats  \n","188533     19092.697          18278.941      18998.316      18981.760  \n","188534     76175.020          77180.840      76242.100      75921.750  \n","188535     57041.520          57490.766      57569.348      56954.203  \n","188536     30448.707          30660.596      29996.790      29893.342  \n","188537     30386.824          30643.406      30786.209      30523.236  \n","...              ...                ...            ...            ...  \n","314218     28120.336          28374.504      27910.977      29353.402  \n","314219     49414.367          50381.523      48643.580      49904.330  \n","314220     19272.940          19490.973      19316.730      20229.342  \n","314221     16360.864          16322.670      17216.360      16647.824  \n","314222     36255.570          37254.234      39659.848      37465.500  \n","\n","[125690 rows x 14 columns]"]},"execution_count":302,"metadata":{},"output_type":"execute_result"}],"source":["best_test.test_pred"]},{"cell_type":"code","execution_count":307,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1m\u001b[34m   /\\  \n","  /__\\  hillclimbers\u001b[0m\u001b[1m \n"," /    \\\n","/______\\ \n","\u001b[0m\n","\u001b[1m\u001b[33mModels to be ensembled | (15 total):\u001b[0m \n","\n","\u001b[1m\u001b[32mlaml_lgb_cb_tuned: 72411.94180 (best solo model)\u001b[0m\n","\u001b[1mag-serkanpolat:    72420.05430\u001b[0m\n","\u001b[1mlgb:               72470.95246\u001b[0m\n","\u001b[1mxgb:               72476.62274\u001b[0m\n","\u001b[1mag-r2:             72478.77829\u001b[0m\n","\u001b[1mhgb:               72494.35636\u001b[0m\n","\u001b[1mlaml_nn_feats:     72498.15458\u001b[0m\n","\u001b[1mcat:               72504.83670\u001b[0m\n","\u001b[1mag-small:          72514.40154\u001b[0m\n","\u001b[1mag-mae:            72532.80220\u001b[0m\n","\u001b[1mlaml_catonly:      72548.16018\u001b[0m\n","\u001b[1mxgblinear:         72551.02829\u001b[0m\n","\u001b[1mknn:               72610.67615\u001b[0m\n","\u001b[1mlaml_lgbmonly:     72631.15652\u001b[0m\n","\u001b[1mag-medae:          73727.01435\u001b[0m\n","\n","\u001b[1m\u001b[33m[Data preparation completed successfully] - [Initiate hill climbing]\u001b[0m \n","\n","\u001b[1m\u001b[32mIteration: 1 | Model added: xgb | Best weight: 0.43 | Best root_mean_squared_error: 72330.85470\u001b[0m\n","\u001b[1m\u001b[32mIteration: 2 | Model added: ag-medae | Best weight: 0.10 | Best root_mean_squared_error: 72311.84743\u001b[0m\n","\u001b[1m\u001b[32mIteration: 3 | Model added: ag-serkanpolat | Best weight: 0.17 | Best root_mean_squared_error: 72307.35096\u001b[0m\n","\u001b[1m\u001b[32mIteration: 4 | Model added: laml_lgbmonly | Best weight: 0.06 | Best root_mean_squared_error: 72305.83165\u001b[0m\n","\u001b[1m\u001b[32mIteration: 5 | Model added: hgb | Best weight: 0.09 | Best root_mean_squared_error: 72304.01865\u001b[0m\n","\u001b[1m\u001b[32mIteration: 6 | Model added: laml_catonly | Best weight: 0.03 | Best root_mean_squared_error: 72303.77051\u001b[0m\n","\u001b[1m\u001b[32mIteration: 7 | Model added: lgb | Best weight: 0.02 | Best root_mean_squared_error: 72303.69705\u001b[0m\n"]}],"source":["best_prediction = best_test.naive_hill_climb()"]},{"cell_type":"code","execution_count":235,"metadata":{},"outputs":[],"source":["np.random.seed(2)\n","mix = np.random.permutation(best_test.test_pred.shape[1])\n","first = mix[:6]\n","second = mix[6:]\n","\n","all_preds = np.array(best_test.test_pred.columns)"]},{"cell_type":"code","execution_count":236,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1m\u001b[34m   /\\  \n","  /__\\  hillclimbers\u001b[0m\u001b[1m \n"," /    \\\n","/______\\ \n","\u001b[0m\n","\u001b[1m\u001b[33mModels to be ensembled | (6 total):\u001b[0m \n","\n","\u001b[1m\u001b[32mlaml:      72359.42274 (best solo model)\u001b[0m\n","\u001b[1mlgb:       72470.95246\u001b[0m\n","\u001b[1mhgb:       72494.35636\u001b[0m\n","\u001b[1mag-small:  72514.40154\u001b[0m\n","\u001b[1mxgblinear: 72551.02829\u001b[0m\n","\u001b[1mknn:       72610.67615\u001b[0m\n","\n","\u001b[1m\u001b[33m[Data preparation completed successfully] - [Initiate hill climbing]\u001b[0m \n","\n","\u001b[1m\u001b[32mIteration: 1 | Model added: lgb | Best weight: 0.34 | Best root_mean_squared_error: 72318.84458\u001b[0m\n","\u001b[1m\u001b[32mIteration: 2 | Model added: hgb | Best weight: 0.06 | Best root_mean_squared_error: 72317.99935\u001b[0m\n","\u001b[1m\u001b[34m   /\\  \n","  /__\\  hillclimbers\u001b[0m\u001b[1m \n"," /    \\\n","/______\\ \n","\u001b[0m\n","\u001b[1m\u001b[33mModels to be ensembled | (7 total):\u001b[0m \n","\n","\u001b[1m\u001b[32mlaml_lgb_cb:   72295.94734 (best solo model)\u001b[0m\n","\u001b[1mlaml_lgbmonly: 72309.01888\u001b[0m\n","\u001b[1mxgb:           72476.62274\u001b[0m\n","\u001b[1mag-r2:         72478.77829\u001b[0m\n","\u001b[1mcat:           72504.83670\u001b[0m\n","\u001b[1mag-mae:        72532.80220\u001b[0m\n","\u001b[1mag-medae:      73727.01435\u001b[0m\n","\n","\u001b[1m\u001b[33m[Data preparation completed successfully] - [Initiate hill climbing]\u001b[0m \n","\n","\u001b[1m\u001b[32mIteration: 1 | Model added: xgb | Best weight: 0.27 | Best root_mean_squared_error: 72268.46945\u001b[0m\n","\u001b[1m\u001b[32mIteration: 2 | Model added: laml_lgbmonly | Best weight: 0.32 | Best root_mean_squared_error: 72257.52809\u001b[0m\n","\u001b[1m\u001b[32mIteration: 3 | Model added: ag-medae | Best weight: 0.07 | Best root_mean_squared_error: 72250.09241\u001b[0m\n","\u001b[1m\u001b[32mIteration: 4 | Model added: cat | Best weight: 0.06 | Best root_mean_squared_error: 72248.92323\u001b[0m\n"]}],"source":["level_1_oof = []\n","level_1_test = []\n","\n","new_test, new_oof = climb_hill(train=new_df.loc['train'],\n","                            oof_pred_df=best_test.train_oof_pred[list(all_preds[first])],\n","                            test_pred_df=best_test.test_pred[list(all_preds[first])],\n","                            target='price',\n","                            objective=\"minimize\",\n","                            eval_metric=partial(root_mean_squared_error),\n","                            negative_weights=False,\n","                            plot_hill=False,\n","                            return_oof_preds=True)\n","\n","level_1_oof += [pd.Series(new_oof, name=\"lvl1_1\", index=best_test.train_oof_pred.index)]\n","level_1_test += [pd.Series(new_test, name=\"lvl1_1\", index=best_test.test_pred.index)]\n","\n","new_test, new_oof = climb_hill(train=new_df.loc['train'],\n","                            oof_pred_df=best_test.train_oof_pred[list(all_preds[second])],\n","                            test_pred_df=best_test.test_pred[list(all_preds[second])],\n","                            target='price',\n","                            objective=\"minimize\",\n","                            eval_metric=partial(root_mean_squared_error),\n","                            negative_weights=False,\n","                            plot_hill=False,\n","                            return_oof_preds=True)\n","\n","level_1_oof += [pd.Series(new_oof, name=\"lvl1_2\", index=best_test.train_oof_pred.index)]\n","level_1_test += [pd.Series(new_test, name=\"lvl1_2\", index=best_test.test_pred.index)]\n","\n","\n","# new_test, new_oof = climb_hill(train=new_df.loc['train'],\n","#                             oof_pred_df=best_test.train_oof_pred[list(all_preds[third])],\n","#                             test_pred_df=best_test.test_pred[list(all_preds[third])],\n","#                             target='price',\n","#                             objective=\"minimize\",\n","#                             eval_metric=partial(root_mean_squared_error),\n","#                             negative_weights=False,\n","#                             plot_hill=False,\n","#                             return_oof_preds=True)\n","\n","# level_1_oof += [pd.Series(new_oof, name=\"lvl1_3\", index=best_test.train_oof_pred.index)]\n","# level_1_test += [pd.Series(new_test, name=\"lvl1_3\", index=best_test.test_pred.index)]"]},{"cell_type":"code","execution_count":237,"metadata":{},"outputs":[],"source":["level1oof = pd.concat(level_1_oof, axis=1)\n","level1test = pd.concat(level_1_test, axis=1)"]},{"cell_type":"code","execution_count":238,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1m\u001b[34m   /\\  \n","  /__\\  hillclimbers\u001b[0m\u001b[1m \n"," /    \\\n","/______\\ \n","\u001b[0m\n","\u001b[1m\u001b[33mModels to be ensembled | (2 total):\u001b[0m \n","\n","\u001b[1m\u001b[32mlvl1_2: 72248.92323 (best solo model)\u001b[0m\n","\u001b[1mlvl1_1: 72317.99935\u001b[0m\n","\n","\u001b[1m\u001b[33m[Data preparation completed successfully] - [Initiate hill climbing]\u001b[0m \n","\n","\u001b[1m\u001b[32mIteration: 1 | Model added: lvl1_1 | Best weight: 0.06 | Best root_mean_squared_error: 72248.63972\u001b[0m\n"]}],"source":["new_test, new_oof = climb_hill(train=new_df.loc['train'],\n","                            oof_pred_df=level1oof,\n","                            test_pred_df=level1test,\n","                            target='price',\n","                            objective=\"minimize\",\n","                            eval_metric=partial(root_mean_squared_error),\n","                            negative_weights=False,\n","                            plot_hill=False,\n","                            return_oof_preds=True)"]},{"cell_type":"code","execution_count":308,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>price</th>\n","    </tr>\n","    <tr>\n","      <th>id</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>188533</th>\n","      <td>18504.426381</td>\n","    </tr>\n","    <tr>\n","      <th>188534</th>\n","      <td>77853.059012</td>\n","    </tr>\n","    <tr>\n","      <th>188535</th>\n","      <td>57452.144804</td>\n","    </tr>\n","    <tr>\n","      <th>188536</th>\n","      <td>28873.764430</td>\n","    </tr>\n","    <tr>\n","      <th>188537</th>\n","      <td>30403.558719</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>314218</th>\n","      <td>27522.098113</td>\n","    </tr>\n","    <tr>\n","      <th>314219</th>\n","      <td>50201.278773</td>\n","    </tr>\n","    <tr>\n","      <th>314220</th>\n","      <td>19413.122463</td>\n","    </tr>\n","    <tr>\n","      <th>314221</th>\n","      <td>16390.332354</td>\n","    </tr>\n","    <tr>\n","      <th>314222</th>\n","      <td>38837.885998</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>125690 rows × 1 columns</p>\n","</div>"],"text/plain":["               price\n","id                  \n","188533  18504.426381\n","188534  77853.059012\n","188535  57452.144804\n","188536  28873.764430\n","188537  30403.558719\n","...              ...\n","314218  27522.098113\n","314219  50201.278773\n","314220  19413.122463\n","314221  16390.332354\n","314222  38837.885998\n","\n","[125690 rows x 1 columns]"]},"execution_count":308,"metadata":{},"output_type":"execute_result"}],"source":["sample_sub['price'] = best_prediction\n","sample_sub"]},{"cell_type":"code","execution_count":309,"metadata":{},"outputs":[],"source":["sample_sub.to_csv(\"/Users/yuwei-1/Documents/projects/Kaggle-tools/submissions/used_cars/used_car_submission_v48.csv\")"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["pd.Series(best, index=X_test.index, name=\"price\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-22T16:22:15.669840Z","iopub.status.busy":"2024-09-22T16:22:15.669390Z","iopub.status.idle":"2024-09-22T16:22:15.682593Z","shell.execute_reply":"2024-09-22T16:22:15.681384Z","shell.execute_reply.started":"2024-09-22T16:22:15.669799Z"},"trusted":true},"outputs":[],"source":["class BaseLGBMParamGrid():\n","    @staticmethod\n","    def get(trial : optuna.Trial, n_estimators=1000):\n","        if isinstance(trial, optuna.trial.FixedTrial):\n","            params = initparams\n","        else:\n","            params = {\n","                # \"boosting_type\" : \"gbdt\",\n","                \"num_leaves\" : trial.suggest_int(\"num_leaves\", 2, 500),\n","                \"max_depth\" : trial.suggest_int(\"max_depth\", 0, 50),\n","                \"learning_rate\" : trial.suggest_float(\"learning_rate\", 1e-2, 1.0, log=True),\n","                \"num_boost_round\" : trial.suggest_int(\"num_boost_round\", 50, 1000),\n","                \"subsample\" : trial.suggest_float(\"subsample\", 0.5, 1.0),\n","                \"colsample_bytree\" : trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n","                \"reg_alpha\" : trial.suggest_float(\"reg_alpha\", 1e-6, 10, log=True),\n","                \"reg_lambda\" : trial.suggest_float(\"reg_lambda\", 1e-6, 10, log=True),\n","                \"min_data_in_leaf\" : trial.suggest_int(\"min_data_in_leaf\", 1, 100),\n","                \"feature_fraction\" : trial.suggest_float(\"feature_fraction\", 0.5, 1.0),\n","                \"bagging_fraction\" : trial.suggest_float(\"bagging_fraction\", 0.5, 1.0),\n","                \"bagging_freq\" : trial.suggest_int(\"bagging_freq\", 1, 5),\n","                \"data_sample_strategy\" : \"bagging\",\n","                'min_child_weight': trial.suggest_float('min_child_weight', 1e-4, 100, log=True),\n","                'cat_smooth': trial.suggest_float('cat_smooth', 1, 100, log=True),\n","                \"verbose_eval\" : False,\n","                \"log_period\" : 1000,\n","                \"random_state\" : 129,\n","                \"verbose\" : -1}\n","        return params"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class BaseXGBoostParamGrid():\n","    @staticmethod\n","    def get(trial : optuna.Trial):\n","        params = {\n","            # \"booster\": trial.suggest_categorical(\"booster\", [\"gbtree\", \"dart\"]),\n","            \"max_bin\" : trial.suggest_int(\"max_bin\", 2, 500),\n","            \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.3, log=True),\n","            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 50),\n","            \"num_boost_round\" : trial.suggest_int(\"num_boost_round\", 50, 1000),\n","            \"gamma\" : trial.suggest_float(\"gamma\", 0, 10),\n","            \"min_child_weight\" : trial.suggest_float(\"min_child_weight\", 0.1, 100, log=True),\n","            \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n","            \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n","            \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.5, 1.0),\n","            \"colsample_bynode\": trial.suggest_float(\"colsample_bynode\", 0.5, 1.0),\n","            \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-6, 10.0, log=True),\n","            \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-6, 10.0, log=True),\n","            \"max_cat_threshold\" : trial.suggest_int(\"max_cat_threshold\", 1, 1000, log=True),\n","            \"sampling_method\" : \"uniform\",\n","            \"grow_policy\" : trial.suggest_categorical(\"grow_policy\", [\"lossguide\", \"depthwise\"]),\n","            \"random_state\": 129,\n","            \"verbosity\": 0\n","        }\n","        return params"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class BaseCatBoostParamGrid():\n","    @staticmethod\n","    def get(trial : optuna.Trial):\n","        params = {\n","            # \"booster\": trial.suggest_categorical(\"booster\", [\"gbtree\", \"dart\"]),\n","            \"max_bin\" : trial.suggest_int(\"max_bin\", 2, 500),\n","            \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-2, 0.3, log=True),\n","            \"depth\": trial.suggest_int(\"depth\", 3, 16),\n","            \"iterations\" : trial.suggest_int(\"iterations\", 50, 1000),\n","            \"bagging_temperature\" : trial.suggest_float(\"bagging_temperature\", 1, 100, log=True),\n","            \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n","            \"colsample_bylevel\" : trial.suggest_float(\"colsample_bylevel\", 0.5, 1.0),\n","            \"min_data_in_leaf\" : trial.suggest_float(\"min_data_in_leaf\", 1, 1000, log=True),\n","            \"l2_leaf_reg\": trial.suggest_float(\"l2_leaf_reg\", 1e-6, 10.0, log=True),\n","            \"grow_policy\" : trial.suggest_categorical(\"grow_policy\", [\"Lossguide\", \"Depthwise\", \"SymmetricTree\"]),\n","            \"leaf_estimation_iterations\" : trial.suggest_int(\"leaf_estimation_iterations\", 1, 5),\n","            \"random_strength\" : trial.suggest_float(\"random_strength\", 1, 10),\n","            \"leaf_estimation_method\" : trial.suggest_categorical(\"leaf_estimation_method\", [\"Newton\", \"Gradient\"]),\n","            \"loss_function\" : \"RMSE\",\n","            \"use_best_model\" : True,\n","            \"random_seed\": 129,\n","            \"verbose\": False\n","        }\n","        return params"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-09-22T16:22:47.906739Z","iopub.status.busy":"2024-09-22T16:22:47.906297Z","iopub.status.idle":"2024-09-22T16:22:47.975458Z","shell.execute_reply":"2024-09-22T16:22:47.974084Z","shell.execute_reply.started":"2024-09-22T16:22:47.906696Z"},"trusted":true},"outputs":[],"source":["train_df = new_df.loc['train']"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2024-09-22T16:23:37.396543Z","iopub.status.busy":"2024-09-22T16:23:37.396078Z","iopub.status.idle":"2024-09-22T16:24:35.478573Z","shell.execute_reply":"2024-09-22T16:24:35.476810Z","shell.execute_reply.started":"2024-09-22T16:23:37.396502Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["####################################################################################################\n","OOF prediction score :  72494.75623134684\n","Mean 5-cv results : 72424.37381876513 +- 3193.920049509081\n","####################################################################################################\n"]},{"data":{"text/plain":["((72494.75623134684, 72424.37381876513),\n"," array([ 8682.37304688, 10177.59863281, 12761.01757812, ...,\n","        92261.9296875 , 64097.63671875, 39175.29296875]),\n"," [<ktools.modelling.models.xgb_model.XGBoostModel at 0x31e34e470>,\n","  <ktools.modelling.models.xgb_model.XGBoostModel at 0x31e34f1f0>,\n","  <ktools.modelling.models.xgb_model.XGBoostModel at 0x31e34fc70>,\n","  <ktools.modelling.models.xgb_model.XGBoostModel at 0x31e34f1c0>,\n","  <ktools.modelling.models.xgb_model.XGBoostModel at 0x31e34fca0>])"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["xgb_params = {'early_stopping_rounds': 8, 'max_bin': 149, 'learning_rate': 0.013953743782599707, 'max_depth': 35, 'num_boost_round': 873, 'gamma': 2.6952508860883504, 'min_child_weight': 87.81545615100626, 'subsample': 0.810622785046154, 'colsample_bytree': 0.5376291735243263, 'colsample_bylevel': 0.6492000220599348, 'colsample_bynode': 0.5612689485326161, 'reg_alpha': 0.2277234511369887, 'reg_lambda': 1.6010913241456725e-05, 'max_cat_threshold': 10, 'grow_policy': 'lossguide'}\n","model = XGBoostModel(**xgb_params)\n","kf = KFold(n_splits=5, shuffle=True, random_state=42)\n","\n","cve = CrossValidationExecutor(xgb_model,\n","                              root_mean_squared_error,\n","                              kf,\n","                              use_test_as_valid=True,\n","                              verbose=1\n","                              )\n","_ = cve.run(train_df[['model_year', 'milage', 'fuel_type', 'int_col', 'accident', 'clean_title', 'Trim', 'horsepower', 'liters', 'cylinders', 'brand_clean_title', 'brand_accident', 'brand_fuel_type', 'expensive_int_col', 'MAE_feature', 'without_outlier_feature', 'MSE_feature']], train_df['price'])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":9057646,"sourceId":76728,"sourceType":"competition"},{"datasetId":3742543,"sourceId":6478229,"sourceType":"datasetVersion"}],"dockerImageVersionId":30761,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
