{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from functools import reduce\n",
    "import unittest\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from ktools.modelling.ktools_models.pytorch_nns.ffn_pytorch_embedding_model import FFNPytorchEmbeddingModel\n",
    "import functools\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "from torch.optim.lr_scheduler import LambdaLR, ReduceLROnPlateau, CosineAnnealingWarmRestarts\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from ktools.fitting.cross_validation_executor import CrossValidationExecutor\n",
    "from ktools.modelling.ktools_models.pytorch_embedding_model import PytorchEmbeddingModel\n",
    "from ktools.modelling.model_transform_wrappers.survival_model_wrapper import SupportedSurvivalTransformation\n",
    "from ktools.preprocessing.basic_feature_transformers import *\n",
    "from ktools.utils.data_science_pipeline_settings import DataSciencePipelineSettings\n",
    "from post_HCT_survival_notebooks.hct_utils import score\n",
    "from ktools.modelling.ktools_models.pytorch_nns.odst_pytorch_embedding_model import ODSTPytorchEmbeddingModel\n",
    "import math\n",
    "from torch.optim.lr_scheduler import SequentialLR, CosineAnnealingLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv_path = \"../data/post_hct_survival/train.csv\"\n",
    "test_csv_path = \"../data/post_hct_survival/test.csv\"\n",
    "target_col_name = ['efs', 'efs_time']\n",
    "\n",
    "def scci_metric(y_test, y_pred, id_col_name : str = \"ID\",\n",
    "        survived_col_name : str = \"efs\",\n",
    "        survival_time_col_name : str = \"efs_time\",\n",
    "        stratify_col_name : str = \"race_group\"):\n",
    "    idcs = y_test.index\n",
    "    og_train = pd.read_csv(train_csv_path)\n",
    "    \n",
    "    y_true = og_train.loc[idcs, [id_col_name, survived_col_name, survival_time_col_name, stratify_col_name]].copy()\n",
    "    y_pred_df = og_train.loc[idcs, [id_col_name]].copy()\n",
    "    y_pred_df[\"prediction\"] = y_pred\n",
    "    scci = score(y_true.copy(), y_pred_df.copy(), id_col_name)\n",
    "    return scci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nunq = pd.read_csv(train_csv_path, index_col=0).drop(columns=['efs', 'efs_time']).nunique()\n",
    "categoricals = nunq[nunq.values < 30].index.tolist()\n",
    "standardize = lambda df, col : (df[col].values - df[col].mean())/df[col].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "\n",
    "def create_dataloader(X : pd.DataFrame, y : pd.DataFrame, shuffle : bool = False):\n",
    "\n",
    "    data = TensorDataset(\n",
    "            # torch.tensor(X.to_numpy()[:, categorical_idcs], dtype=torch.long),\n",
    "            torch.tensor(X.index, dtype=torch.long),\n",
    "            torch.tensor(X.to_numpy(), dtype=torch.float32),\n",
    "            torch.tensor(y['efs'].to_numpy(), dtype=torch.int),\n",
    "            torch.tensor(standardize(y, 'efs_time'), dtype=torch.float32)\n",
    "        )\n",
    "\n",
    "    dataloader = DataLoader(data, batch_size=2048, shuffle=shuffle)\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@functools.lru_cache\n",
    "def combinations(N):\n",
    "    ind = torch.arange(N)\n",
    "    comb = torch.combinations(ind, r=2)\n",
    "    return comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x1 = np.arange(20)\n",
    "x2 = np.arange(20)\n",
    "X1, X2 = np.meshgrid(x1, x2)\n",
    "X1, X2 = X1.flatten(), X2.flatten()\n",
    "\n",
    "# If y=1 then it assumed the first input should be ranked higher (have a larger value) than the second input, and vice-versa for y=−1.\n",
    "y = 1\n",
    "\n",
    "margin = 2\n",
    "\n",
    "xs = []\n",
    "ys = []\n",
    "\n",
    "for n in X1:\n",
    "    for m in X2:\n",
    "        diff = n-m\n",
    "        loss = max(0, -y*(n - m) + margin)\n",
    "\n",
    "        xs += [diff]\n",
    "        ys += [loss]\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(xs, ys, s=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_loss(X, event, event_time, risk, margin=0.2):\n",
    "    n = X.shape[0]\n",
    "    pairwise_combinations = combinations(n)\n",
    "\n",
    "    # Find mask\n",
    "    first_of_pair, second_of_pair = pairwise_combinations.T\n",
    "    valid_mask = False\n",
    "    valid_mask |= ((event[first_of_pair] == 1) & (event[second_of_pair] == 1))\n",
    "    valid_mask |= ((event[first_of_pair] == 1) & (event_time[first_of_pair] < event_time[second_of_pair]))\n",
    "    valid_mask |= ((event[second_of_pair] == 1) & (event_time[second_of_pair] < event_time[first_of_pair]))\n",
    "\n",
    "    # pariwise hinge loss\n",
    "    direction = 2*(event_time[first_of_pair] > event_time[second_of_pair]).int() - 1\n",
    "    margin_loss = F.relu(direction*(risk[first_of_pair] - risk[second_of_pair]).squeeze() + margin)\n",
    "    return margin_loss[valid_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "class PairwiseRankingNeuralNetwork(pl.LightningModule):\n",
    "\n",
    "    def __init__(self,\n",
    "                 margin):\n",
    "        \n",
    "        super().__init__()\n",
    "        self._margin = margin\n",
    "        self.model = ODSTPytorchEmbeddingModel(INPUT_DIM,\n",
    "                                               OUTPUT_DIM,\n",
    "                                               categorical_idcs,\n",
    "                                               cat_sizes,\n",
    "                                               cat_emb,\n",
    "                                               'none',\n",
    "                                               hidden_dim=64,\n",
    "                                               dropout=0.05)\n",
    "        self.targets = []\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "        \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        idx, X, event, event_time = batch\n",
    "        risk_score = self(X)\n",
    "        loss = pairwise_loss(X, event, event_time, risk_score).sum()/X.shape[0]\n",
    "        self.log('train_pairwise_loss', loss, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        idx, X, event, event_time = batch\n",
    "        risk_score = self(X)\n",
    "        self.targets.append([event_time, risk_score.detach(), event, idx])\n",
    "        loss = pairwise_loss(X, event, event_time, risk_score).sum()/X.shape[0]\n",
    "        self.log('val_pairwise_loss', loss, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        \"\"\"\n",
    "        At the end of the validation epoch, it computes and logs the concordance index\n",
    "        \"\"\"\n",
    "        scci = self._calc_cindex()\n",
    "        self.log(\"cindex\", scci, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.targets.clear()\n",
    "\n",
    "    def _calc_cindex(self):\n",
    "        \"\"\"\n",
    "        Calculate c-index accounting for each race_group or global.\n",
    "        \"\"\"\n",
    "        y = torch.cat([t[0] for t in self.targets]).cpu().numpy()\n",
    "        y_hat = torch.cat([t[1] for t in self.targets]).cpu().numpy()\n",
    "        efs = torch.cat([t[2] for t in self.targets]).cpu().numpy()\n",
    "        idx = torch.cat([t[3] for t in self.targets]).cpu().numpy()\n",
    "        val_idcs = pd.Series(idx, index=idx)\n",
    "        scci = scci_metric(val_idcs, y_hat)\n",
    "        return scci\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-2, weight_decay=1e-4)\n",
    "        WARMUP = 10\n",
    "        \n",
    "        def exp_warm_up(epoch):\n",
    "            \n",
    "            if epoch < WARMUP:\n",
    "                return 1.0 - math.exp(-(epoch+1) / WARMUP)\n",
    "            return 1\n",
    "        \n",
    "        lambda_scheduler = LambdaLR(optimizer, lr_lambda=exp_warm_up)\n",
    "        annealing_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "                            optimizer,\n",
    "                            T_max=45,\n",
    "                            eta_min=6e-4\n",
    "                        )\n",
    "        scheduler = SequentialLR(optimizer, schedulers=[lambda_scheduler, annealing_scheduler], milestones=[WARMUP])\n",
    "\n",
    "        scheduler_config = {\n",
    "            \"scheduler\": scheduler,\n",
    "            \"interval\": \"epoch\",\n",
    "            \"frequency\": 1,\n",
    "            \"strict\": False,\n",
    "        }\n",
    "\n",
    "        return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler_config}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import LearningRateMonitor, TQDMProgressBar, StochasticWeightAveraging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddFeatures(IFeatureTransformer):\n",
    "    @staticmethod\n",
    "    def transform(original_settings : DataSciencePipelineSettings):\n",
    "        settings = deepcopy(original_settings)\n",
    "        settings.combined_df['is_cyto_score_same'] = (settings.combined_df['cyto_score'] == settings.combined_df['cyto_score_detail']).astype(int)\n",
    "        settings.categorical_col_names += ['is_cyto_score_same']\n",
    "        settings.training_col_names += ['is_cyto_score_same']\n",
    "        settings.combined_df['year_hct'] -= 2000\n",
    "        return settings\n",
    "    \n",
    "    \n",
    "settings = DataSciencePipelineSettings(train_csv_path,\n",
    "                                        test_csv_path,\n",
    "                                        target_col_name,\n",
    "                                        categorical_col_names=categoricals\n",
    "                                        )\n",
    "transforms = [\n",
    "            AddFeatures.transform,\n",
    "            StandardScaleNumerical.transform,\n",
    "            FillNullMeanValues.transform,\n",
    "            OrdinalEncode.transform,\n",
    "            ConvertObjectToCategorical.transform,\n",
    "            # GenerateSurvivalTarget('kaplanmeier').transform\n",
    "            ]\n",
    "\n",
    "settings = reduce(lambda acc, func: func(acc), transforms, settings)\n",
    "settings.update()\n",
    "\n",
    "train, test_df = settings.update()\n",
    "# test_df.drop(columns=settings.target_col, inplace=True)\n",
    "X, y = train.drop(columns=settings.target_col_name), train[settings.target_col_name]\n",
    "\n",
    "INPUT_DIM = len(settings.training_col_names)\n",
    "OUTPUT_DIM = 1\n",
    "\n",
    "cat_names = settings.categorical_col_names\n",
    "cat_sizes = [int(x) for x in X[cat_names].nunique().values]\n",
    "# cat_emb = cat_sizes#[int(np.ceil(np.sqrt(x+1))) for x in cat_sizes]\n",
    "cat_emb = [16] * len(cat_sizes)\n",
    "categorical_idcs = [X.columns.get_loc(col) for col in cat_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 30\n",
    "MAX_LR = 6e-2\n",
    "WARMUP = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)  # Python random module\n",
    "    np.random.seed(seed)  # NumPy\n",
    "    torch.manual_seed(seed)  # PyTorch CPU\n",
    "    torch.cuda.manual_seed_all(seed)  # PyTorch GPU (all devices)\n",
    "    torch.backends.cudnn.deterministic = True  # Ensures deterministic behavior\n",
    "    torch.backends.cudnn.benchmark = False  # Disables auto-tuning for convolutions\n",
    "\n",
    "set_seed(42)  # Call this before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1, epoch: 1 Epoch 1: Learning Rate = [0.010876154815321091]\n",
      "stratified concordance:  0.5699778588984244\n",
      "Fold 1, epoch: 2 Epoch 2: Learning Rate = [0.015550906759096927]\n",
      "stratified concordance:  0.573266736147124\n",
      "Fold 1, epoch: 3 Epoch 3: Learning Rate = [0.01978079723786164]\n",
      "stratified concordance:  0.6202671673250658\n",
      "Fold 1, epoch: 4 Epoch 4: Learning Rate = [0.023608160417241994]\n",
      "stratified concordance:  0.6438797688409764\n",
      "Fold 1, epoch: 5 Epoch 5: Learning Rate = [0.027071301834358415]\n",
      "stratified concordance:  0.6482830107868618\n",
      "Fold 1, epoch: 6 Epoch 6: Learning Rate = [0.030204881772515426]\n",
      "stratified concordance:  0.6425292748698563\n",
      "Fold 1, epoch: 7 Epoch 7: Learning Rate = [0.0330402621529667]\n",
      "stratified concordance:  0.6445962081913171\n",
      "Fold 1, epoch: 8 Epoch 8: Learning Rate = [0.03560582041556405]\n",
      "stratified concordance:  0.6328376217963438\n",
      "Fold 1, epoch: 9 Epoch 9: Learning Rate = [0.03792723352971346]\n",
      "stratified concordance:  0.6523889313413689\n",
      "Fold 1, epoch: 10 Epoch 10: Learning Rate = [0.06]\n",
      "stratified concordance:  0.658967264446827\n",
      "Fold 1, epoch: 11 Epoch 11: Learning Rate = [0.05983839591336406]\n",
      "stratified concordance:  0.6592013081210635\n",
      "Fold 1, epoch: 12 Epoch 12: Learning Rate = [0.05935535422164727]\n",
      "stratified concordance:  0.6455564857822036\n",
      "Fold 1, epoch: 13 Epoch 13: Learning Rate = [0.05855616723070703]\n",
      "stratified concordance:  0.6405624463818033\n",
      "Fold 1, epoch: 14 Epoch 14: Learning Rate = [0.05744959100045672]\n",
      "stratified concordance:  0.6449935165029538\n",
      "Fold 1, epoch: 15 Epoch 15: Learning Rate = [0.056047749411640944]\n",
      "stratified concordance:  0.6461113125827324\n",
      "Fold 1, epoch: 16 Epoch 16: Learning Rate = [0.05436600133406095]\n",
      "stratified concordance:  0.6252752382083415\n",
      "Fold 1, epoch: 17 Epoch 17: Learning Rate = [0.05242277235158313]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 109\u001b[0m\n\u001b[1;32m    107\u001b[0m     pred_risk \u001b[38;5;241m=\u001b[39m model(torch\u001b[38;5;241m.\u001b[39mtensor(X_test\u001b[38;5;241m.\u001b[39mto_numpy(), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32))\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;66;03m# print(y_pred.detach().numpy())\u001b[39;00m\n\u001b[0;32m--> 109\u001b[0m     eval_metric \u001b[38;5;241m=\u001b[39m \u001b[43mscci_metric\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred_risk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstratified concordance: \u001b[39m\u001b[38;5;124m\"\u001b[39m, eval_metric)\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;66;03m# writer.add_scalar(\"Loss/Train\", total_train_loss, e)\u001b[39;00m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;66;03m# writer.add_scalar(\"Loss/Validation\", val_loss, epoch)\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;66;03m#     torch.tensor(X_test.to_numpy(), dtype=torch.long)\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[2], line 15\u001b[0m, in \u001b[0;36mscci_metric\u001b[0;34m(y_test, y_pred, id_col_name, survived_col_name, survival_time_col_name, stratify_col_name)\u001b[0m\n\u001b[1;32m     13\u001b[0m y_pred_df \u001b[38;5;241m=\u001b[39m og_train\u001b[38;5;241m.\u001b[39mloc[idcs, [id_col_name]]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m     14\u001b[0m y_pred_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m y_pred\n\u001b[0;32m---> 15\u001b[0m scci \u001b[38;5;241m=\u001b[39m \u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mid_col_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m scci\n",
      "File \u001b[0;32m~/Documents/projects/Kaggle-tools/post_HCT_survival_notebooks/../post_HCT_survival_notebooks/hct_utils.py:39\u001b[0m, in \u001b[0;36mscore\u001b[0;34m(solution, submission, row_id_column_name)\u001b[0m\n\u001b[1;32m     37\u001b[0m     merged_df_race \u001b[38;5;241m=\u001b[39m merged_df\u001b[38;5;241m.\u001b[39miloc[indices]\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;66;03m# Calculate the concordance index\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m     c_index_race \u001b[38;5;241m=\u001b[39m \u001b[43mconcordance_index\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mmerged_df_race\u001b[49m\u001b[43m[\u001b[49m\u001b[43minterval_label\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mmerged_df_race\u001b[49m\u001b[43m[\u001b[49m\u001b[43mprediction_label\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mmerged_df_race\u001b[49m\u001b[43m[\u001b[49m\u001b[43mevent_label\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m     metric_list\u001b[38;5;241m.\u001b[39mappend(c_index_race)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(np\u001b[38;5;241m.\u001b[39mmean(metric_list)\u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39msqrt(np\u001b[38;5;241m.\u001b[39mvar(metric_list)))\n",
      "File \u001b[0;32m~/anaconda3/envs/ktools/lib/python3.12/site-packages/lifelines/utils/concordance.py:92\u001b[0m, in \u001b[0;36mconcordance_index\u001b[0;34m(event_times, predicted_scores, event_observed)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;124;03mCalculates the concordance index (C-index) between a series\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;124;03mof event times and a predicted score. The first is the real survival times from\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     89\u001b[0m \n\u001b[1;32m     90\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     91\u001b[0m event_times, predicted_scores, event_observed \u001b[38;5;241m=\u001b[39m _preprocess_scoring_data(event_times, predicted_scores, event_observed)\n\u001b[0;32m---> 92\u001b[0m num_correct, num_tied, num_pairs \u001b[38;5;241m=\u001b[39m \u001b[43m_concordance_summary_statistics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevent_times\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredicted_scores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent_observed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _concordance_ratio(num_correct, num_tied, num_pairs)\n",
      "File \u001b[0;32m~/anaconda3/envs/ktools/lib/python3.12/site-packages/lifelines/utils/concordance.py:176\u001b[0m, in \u001b[0;36m_concordance_summary_statistics\u001b[0;34m(event_times, predicted_event_times, event_observed)\u001b[0m\n\u001b[1;32m    174\u001b[0m     censored_ix \u001b[38;5;241m=\u001b[39m next_ix\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m has_more_died \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m has_more_censored \u001b[38;5;129;01mor\u001b[39;00m died_truth[died_ix] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m censored_truth[censored_ix]):\n\u001b[0;32m--> 176\u001b[0m     pairs, correct, tied, next_ix \u001b[38;5;241m=\u001b[39m \u001b[43m_handle_pairs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdied_truth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdied_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdied_ix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimes_to_compare\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m pred \u001b[38;5;129;01min\u001b[39;00m died_pred[died_ix:next_ix]:\n\u001b[1;32m    178\u001b[0m         times_to_compare\u001b[38;5;241m.\u001b[39minsert(pred)\n",
      "File \u001b[0;32m~/anaconda3/envs/ktools/lib/python3.12/site-packages/lifelines/utils/concordance.py:209\u001b[0m, in \u001b[0;36m_handle_pairs\u001b[0;34m(truth, pred, first_ix, times_to_compare)\u001b[0m\n\u001b[1;32m    207\u001b[0m tied \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mint64(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(first_ix, next_ix):\n\u001b[0;32m--> 209\u001b[0m     rank, count \u001b[38;5;241m=\u001b[39m \u001b[43mtimes_to_compare\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrank\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    210\u001b[0m     correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m rank\n\u001b[1;32m    211\u001b[0m     tied \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m count\n",
      "File \u001b[0;32m~/anaconda3/envs/ktools/lib/python3.12/site-packages/lifelines/utils/btree.py:103\u001b[0m, in \u001b[0;36m_BTree.rank\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    101\u001b[0m     rank \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_counts[nexti]\n\u001b[1;32m    102\u001b[0m     i \u001b[38;5;241m=\u001b[39m nexti\n\u001b[0;32m--> 103\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (rank, count)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "kf = StratifiedKFold(5, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "for i, (train_idx, test_idx) in enumerate(kf.split(X, X['race_group'])):\n",
    "    X_train, y_train = X.loc[train_idx], y.loc[train_idx]\n",
    "    X_test, y_test = X.loc[test_idx], y.loc[test_idx]\n",
    "\n",
    "    dl_train = create_dataloader(X_train, y_train, shuffle=True)\n",
    "    dl_test = create_dataloader(X_test, y_test)\n",
    "\n",
    "            \n",
    "    model = ODSTPytorchEmbeddingModel(INPUT_DIM,\n",
    "                                    OUTPUT_DIM,\n",
    "                                    categorical_idcs,\n",
    "                                    cat_sizes,\n",
    "                                    cat_emb,\n",
    "                                    'none',\n",
    "                                    hidden_dim=64,\n",
    "                                    dropout=0.05)\n",
    "\n",
    "\n",
    "    # checkpoint_callback = pl.callbacks.ModelCheckpoint(monitor=\"val_pairwise_loss\", save_top_k=1)\n",
    "\n",
    "    # trainer = pl.Trainer(\n",
    "    #     accelerator='cpu',\n",
    "    #     max_epochs=5,\n",
    "    #     log_every_n_steps=1,\n",
    "    #     callbacks=[\n",
    "    #         checkpoint_callback,\n",
    "    #         LearningRateMonitor(logging_interval='epoch'),\n",
    "    #         TQDMProgressBar(),\n",
    "    #         StochasticWeightAveraging(swa_lrs=1e-5, swa_epoch_start=40, annealing_epochs=15)\n",
    "    #     ],\n",
    "    # )\n",
    "\n",
    "    # model = PairwiseRankingNeuralNetwork(margin=0.2)\n",
    "    # trainer.fit(model=model, train_dataloaders=dl_train, val_dataloaders=dl_test)\n",
    "\n",
    "    # pred_risk = model.eval()(\n",
    "    #     torch.tensor(X_test.to_numpy(), dtype=torch.float32)\n",
    "    # )\n",
    "\n",
    "    # val_metric = scci_metric(X_test, pred_risk.detach().numpy())\n",
    "\n",
    "    def warm_up(epoch):\n",
    "        if epoch < WARMUP:\n",
    "            return (epoch+1)/WARMUP\n",
    "        return 1\n",
    "    \n",
    "    def exp_warm_up(epoch):\n",
    "        if epoch < WARMUP:\n",
    "            return 1.0 - math.exp(-(epoch+1) / WARMUP)\n",
    "        return 1\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=MAX_LR, weight_decay = 0.0003)\n",
    "    lambda_scheduler = LambdaLR(optimizer, lr_lambda=exp_warm_up)\n",
    "    \n",
    "    annealing_scheduler = CosineAnnealingWarmRestarts(optimizer, 30, 1, 1e-3, last_epoch=EPOCHS)\n",
    "    scheduler = SequentialLR(optimizer, schedulers=[lambda_scheduler, annealing_scheduler], milestones=[WARMUP])\n",
    "    \n",
    "    print()\n",
    "    writer = SummaryWriter()\n",
    "\n",
    "    for e in range(EPOCHS):\n",
    "        \n",
    "        total_train_loss = 0\n",
    "        print(f\"Fold {i+1}, epoch: {e+1}\", end=\" \")\n",
    "        model.train()\n",
    "        for (idx, X_, event, event_time) in dl_train:\n",
    "            risk_pred = model(X_)\n",
    "            all_loss = pairwise_loss(X_, event, event_time, risk_pred)\n",
    "            loss = all_loss.sum()/X_.shape[0]\n",
    "            total_train_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        scheduler.step()        \n",
    "        print(f\"Epoch {e+1}: Learning Rate = {scheduler.get_last_lr()}\")\n",
    "\n",
    "        model.eval()\n",
    "        pred_risk = model(torch.tensor(X_test.to_numpy(), dtype=torch.float32))\n",
    "        eval_metric = scci_metric(X_test, pred_risk.detach().numpy())\n",
    "\n",
    "        print(f\"stratified concordance: \", eval_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ktools",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
