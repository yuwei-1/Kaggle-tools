{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e666164",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pytest\n",
    "from ktools.models import LGBMModel\n",
    "from ktools.preprocessing.categorical import CategoricalEncoder\n",
    "from ktools.preprocessing.numerical import StandardScale\n",
    "from ktools.preprocessing.pipe import PreprocessingPipeline\n",
    "from ktools.config.dataset import DatasetConfig\n",
    "from ktools.fitting.pipe import ModelPipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49443588",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(\"./data/diabetes_prediction/\")\n",
    "TARGET = \"diagnosed_diabetes\"\n",
    "\n",
    "# id split\n",
    "split_id = 678000\n",
    "\n",
    "orig_data = pd.read_csv(DATA_PATH / \"original.csv\")\n",
    "train_data = pd.read_csv(DATA_PATH / \"train.csv\", index_col=0)\n",
    "test_data = pd.read_csv(DATA_PATH / \"test.csv\", index_col=0).assign(data=0)\n",
    "\n",
    "test_data[\"data\"] = test_data[\"data\"].astype(\"category\")\n",
    "# orig_data.drop(columns=[\"physical_activity_minutes_per_week\"], inplace=True)\n",
    "# train_data.drop(columns=[\"physical_activity_minutes_per_week\"], inplace=True)\n",
    "# test_data.drop(columns=[\"physical_activity_minutes_per_week\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa7e9584",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (train_data.columns == train_data.columns.intersection(orig_data.columns)).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "368e6614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "diabetes_risk_score     float64\n",
       "diabetes_stage           object\n",
       "glucose_fasting           int64\n",
       "glucose_postprandial      int64\n",
       "hba1c                   float64\n",
       "insulin_level           float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_data[orig_data.columns.difference(train_data.columns)].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06bb1eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# orig_data = orig_data.drop(columns=orig_data.columns.difference(train_data.columns).to_list())\n",
    "# orig_data = orig_data.assign(data=2)\n",
    "train_data = train_data.assign(data=np.nan)\n",
    "train_data.iloc[:split_id, -1] = 1\n",
    "train_data.iloc[split_id:, -1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d556cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 Base Features:['age', 'alcohol_consumption_per_week', 'physical_activity_minutes_per_week', 'diet_score', 'sleep_hours_per_day', 'screen_time_hours_per_day', 'bmi', 'waist_to_hip_ratio', 'systolic_bp', 'diastolic_bp', 'heart_rate', 'cholesterol_total', 'hdl_cholesterol', 'ldl_cholesterol', 'triglycerides', 'gender', 'ethnicity', 'education_level', 'income_level', 'smoking_status', 'employment_status', 'family_history_diabetes', 'hypertension_history', 'cardiovascular_history']\n"
     ]
    }
   ],
   "source": [
    "TARGET = 'diagnosed_diabetes'\n",
    "BASE = [col for col in train_data.columns if col not in ['id', TARGET, 'data']]\n",
    "\n",
    "\n",
    "ORIG = []\n",
    "\n",
    "for col in BASE:\n",
    "    # MEAN\n",
    "\n",
    "    for tgt in [TARGET, 'glucose_fasting','glucose_postprandial', 'hba1c']: #TARGET, 'glucose_fasting','glucose_postprandial', 'hba1c'\n",
    "        \n",
    "        mean_map = orig_data.groupby(col)[tgt].mean()\n",
    "        new_mean_col_name = f\"orig_mean_{tgt}_grouped_by_{col}\"\n",
    "        mean_map.name = new_mean_col_name\n",
    "        \n",
    "        print(col, tgt)\n",
    "        train_data = train_data.merge(mean_map, on=col, how='left')\n",
    "        test_data = test_data.merge(mean_map, on=col, how='left')\n",
    "        ORIG.append(new_mean_col_name)\n",
    "\n",
    "    # COUNT\n",
    "    # new_count_col_name = f\"orig_count_{col}\"\n",
    "    # count_map = orig_data.groupby(col).size().reset_index(name=new_count_col_name)\n",
    "    \n",
    "    # train_data = train_data.merge(count_map, on=col, how='left')\n",
    "    # test_data = test_data.merge(count_map, on=col, how='left')\n",
    "    # ORIG.append(new_count_col_name)\n",
    "\n",
    "print(len(ORIG), 'Orig Features Created!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3575ad2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_col_names = train_data.drop(columns=TARGET).columns.tolist()\n",
    "\n",
    "numerical_col_names = (\n",
    "    train_data.drop(columns=TARGET)\n",
    "    .select_dtypes(include=[\"number\"])\n",
    "    .columns.tolist()\n",
    ")\n",
    "categorical_col_names = train_data.select_dtypes(\n",
    "    include=[\"object\"]\n",
    ").columns.tolist()\n",
    "\n",
    "config = DatasetConfig(\n",
    "    training_col_names=training_col_names,\n",
    "    numerical_col_names=numerical_col_names + ORIG,\n",
    "    categorical_col_names=categorical_col_names,\n",
    "    target_col_name=TARGET,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a90be512",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_of_interest  = train_data[\"diagnosed_diabetes\"].astype(str) + \"_\" + train_data[\"data\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d7b9d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[12-26 23:48:10][WARNING] ktools: Target contains two unique values. Inferring binary classification task.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold ROC AUC Score: 0.7063007245707997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[12-26 23:48:35][WARNING] ktools: Target contains two unique values. Inferring binary classification task.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold ROC AUC Score: 0.7031573724177882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[12-26 23:49:03][WARNING] ktools: Target contains two unique values. Inferring binary classification task.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold ROC AUC Score: 0.700027425220127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[12-26 23:49:30][WARNING] ktools: Target contains two unique values. Inferring binary classification task.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold ROC AUC Score: 0.709197733200075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[12-26 23:49:56][WARNING] ktools: Target contains two unique values. Inferring binary classification task.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold ROC AUC Score: 0.6968453964746286\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "preprocessors = [StandardScale(config), CategoricalEncoder(config)]\n",
    "\n",
    "train_oof_preds = np.empty(train_data.shape[0])\n",
    "test_oof_preds = np.zeros(test_data.shape[0])\n",
    "\n",
    "mean_score: float = 0.0\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "for train_index, val_index in kfold.split(\n",
    "    train_data, categories_of_interest\n",
    "):\n",
    "    train_fold: pd.DataFrame = train_data.iloc[train_index].copy()\n",
    "    val_fold: pd.DataFrame = train_data.iloc[val_index]\n",
    "    subsetval_fold = val_fold[val_fold[\"data\"] == 0.0]\n",
    "    # weights = np.array([1.0] * train_fold.shape[0] + [1.0] * val_data.shape[0])\n",
    "    train_fold[\"data\"] = train_fold[\"data\"].astype(\"category\")\n",
    "\n",
    "    weights = np.where(train_fold[\"data\"] == 0, 1.0, 1.0)\n",
    "    # assert train_fold.shape[0] == weights.shape[0], f\"train_fold shape: {train_fold.shape[0]}, weights shape: {weights.shape[0]}\"\n",
    "\n",
    "    pipe = ModelPipeline(\n",
    "        model=LGBMModel(),\n",
    "        config=config,\n",
    "        preprocessor=PreprocessingPipeline(preprocessors=preprocessors),\n",
    "    )\n",
    "\n",
    "    pipe.fit(train_fold, validation_data=subsetval_fold, weights=weights)\n",
    "    y_pred = pipe.predict(subsetval_fold)\n",
    "    test_pred = pipe.predict(test_data)\n",
    "    oof_pred = pipe.predict(val_fold)\n",
    "\n",
    "    score = roc_auc_score(subsetval_fold[TARGET], y_pred)\n",
    "    train_oof_preds[val_index] = oof_pred\n",
    "    test_oof_preds += test_pred / kfold.n_splits\n",
    "    mean_score += score / kfold.n_splits\n",
    "    print(f\"Fold ROC AUC Score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9ffa4aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7a337b63-612f-4a11-968a-7028bbb182c7\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "# Generate a random UUID\n",
    "guid = uuid.uuid4()\n",
    "print(guid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f7f981d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7031057303766837"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6554a122",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = Path(\"./data/diabetes_prediction/\")\n",
    "\n",
    "pd.DataFrame({\n",
    "    f\"{guid}\" : train_oof_preds,\n",
    "}).to_csv(save_path / \"oofs\" / f\"oof_preds_{guid}.csv\")\n",
    "\n",
    "pd.DataFrame({\n",
    "    f\"{guid}\" : test_oof_preds,\n",
    "}).to_csv(save_path / \"test_preds\" / f\"test_preds_{guid}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1436431b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub_name = f\"submissions/diabetes_submission.csv\"\n",
    "import pandas as pd\n",
    "pred = pd.read_csv(\"/workspaces/Kaggle-tools/submission (49).csv\")[\"diagnosed_diabetes\"]\n",
    "sample_sub = pd.read_csv(\"data/diabetes_prediction/sample_submission.csv\", index_col=0)\n",
    "sample_sub[\"diagnosed_diabetes\"] = pred.to_numpy()\n",
    "sample_sub.to_csv(\"mikhail->ktools_notrain.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5d37a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined OOF shape: (700000,)\n",
      "Averaged test shape: (300000,)\n",
      "Combined predictions GUID: ef225044-04a9-4761-83b3-eb7bb507da92\n",
      "Saved OOF predictions to: oofs/oof_preds_ef225044-04a9-4761-83b3-eb7bb507da92.csv\n",
      "Saved test predictions to: test_preds/test_preds_ef225044-04a9-4761-83b3-eb7bb507da92.csv\n"
     ]
    }
   ],
   "source": [
    "# Combine fold-level predictions into single OOF and averaged test predictions\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import uuid\n",
    "\n",
    "save_path = Path(\"./data/diabetes_prediction/\")\n",
    "n_folds = 5\n",
    "\n",
    "# Get total number of training samples from train_data\n",
    "n_train_samples = train_data.shape[0]\n",
    "\n",
    "# Initialize array to hold OOF predictions in correct order\n",
    "combined_oof = np.empty(n_train_samples)\n",
    "\n",
    "# Load OOF predictions and place them at the correct indices\n",
    "for i in range(n_folds):\n",
    "    fold_df = pd.read_csv(save_path / \"oofs\" / f\"oof_preds_fold_{i}.csv\", index_col=0)\n",
    "    # The index column contains the original row indices from the CV split\n",
    "    indices = fold_df.index.values\n",
    "    predictions = fold_df.iloc[:, 0].values\n",
    "    combined_oof[indices] = predictions\n",
    "\n",
    "print(f\"Combined OOF shape: {combined_oof.shape}\")\n",
    "\n",
    "# Load and average test predictions\n",
    "test_dfs = []\n",
    "for i in range(n_folds):\n",
    "    fold_df = pd.read_csv(save_path / \"test_preds\" / f\"test_preds_fold_{i}.csv\")\n",
    "    test_dfs.append(fold_df.values.flatten())\n",
    "\n",
    "# Average across folds\n",
    "averaged_test = np.mean(test_dfs, axis=0)\n",
    "print(f\"Averaged test shape: {averaged_test.shape}\")\n",
    "\n",
    "# Generate a unique ID for this combined prediction set\n",
    "combined_guid = uuid.uuid4()\n",
    "print(f\"Combined predictions GUID: {combined_guid}\")\n",
    "\n",
    "# Save combined OOF predictions\n",
    "pd.DataFrame({\n",
    "    f\"{combined_guid}\": combined_oof,\n",
    "}).to_csv(save_path / \"oofs\" / f\"oof_preds_{combined_guid}.csv\")\n",
    "\n",
    "# Save averaged test predictions  \n",
    "pd.DataFrame({\n",
    "    f\"{combined_guid}\": averaged_test,\n",
    "}).to_csv(save_path / \"test_preds\" / f\"test_preds_{combined_guid}.csv\")\n",
    "\n",
    "print(f\"Saved OOF predictions to: oofs/oof_preds_{combined_guid}.csv\")\n",
    "print(f\"Saved test predictions to: test_preds/test_preds_{combined_guid}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a82224",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle-tools",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
